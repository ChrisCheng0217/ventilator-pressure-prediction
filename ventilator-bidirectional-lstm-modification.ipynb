{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 84.777097,
      "end_time": "2021-10-07T13:44:01.547476",
      "environment_variables": {},
      "exception": true,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-10-07T13:42:36.770379",
      "version": "2.3.3"
    },
    "colab": {
      "name": "ventilator-bidirectional-lstm-modification.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bobbercheng/ventilator-pressure-prediction/blob/master/ventilator-bidirectional-lstm-modification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q909wXBOb8qy",
        "outputId": "4eebcf15-e887-4b5a-d099-87f56ca843ac"
      },
      "source": [
        "!pip install kaggle"
      ],
      "id": "Q909wXBOb8qy",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "kBq8qD3McMEW",
        "outputId": "cc778a56-b0da-40d4-a21e-c9fe366a0119"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "id": "kBq8qD3McMEW",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-64ed7d11-7eab-4dcd-9aaf-2dcc0667f662\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-64ed7d11-7eab-4dcd-9aaf-2dcc0667f662\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 62 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS6sJpCacRlx",
        "outputId": "85c587fd-3844-4e72-bd33-41d180f0e0ea"
      },
      "source": [
        "!mkdir /root/.kaggle\n",
        "!cp kaggle.json /root/.kaggle\n",
        "!kaggle competitions download -c ventilator-pressure-prediction\n",
        "!mkdir -p /kaggle/input/ventilator-pressure-prediction\n",
        "!unzip '*.zip' -d /kaggle/input/ventilator-pressure-prediction\n",
        "!ls /kaggle/input/ventilator-pressure-prediction"
      ],
      "id": "RS6sJpCacRlx",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading train.csv.zip to /content\n",
            " 91% 127M/139M [00:00<00:00, 105MB/s] \n",
            "100% 139M/139M [00:00<00:00, 159MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            " 99% 75.0M/75.4M [00:01<00:00, 41.2MB/s]\n",
            "100% 75.4M/75.4M [00:01<00:00, 46.0MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/8.50M [00:00<?, ?B/s]\n",
            "100% 8.50M/8.50M [00:00<00:00, 78.1MB/s]\n",
            "Archive:  sample_submission.csv.zip\n",
            "  inflating: /kaggle/input/ventilator-pressure-prediction/sample_submission.csv  \n",
            "\n",
            "Archive:  train.csv.zip\n",
            "  inflating: /kaggle/input/ventilator-pressure-prediction/train.csv  \n",
            "\n",
            "Archive:  test.csv.zip\n",
            "  inflating: /kaggle/input/ventilator-pressure-prediction/test.csv  \n",
            "\n",
            "3 archives were successfully processed.\n",
            "sample_submission.csv  test.csv  train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNgzsUxrcRte",
        "outputId": "41016b5c-b0a6-429b-a639-c529015ec75c"
      },
      "source": [
        "!pip install optuna"
      ],
      "id": "RNgzsUxrcRte",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.25)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.4-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 63.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.5.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.9.0-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 8.3 MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.8.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.5-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.2.2)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.4.0-py3-none-any.whl (20 kB)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.2.0-py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 69.1 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.6.0-py2.py3-none-any.whl (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 71.3 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.4.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.2.1)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.7.4.3)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=da17c2dd9c52473aa07c26ed102e0bf391982f1f3f2bf44414f453a8ceb5aa7f\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, colorama, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.1.5 alembic-1.7.4 autopage-0.4.0 cliff-3.9.0 cmaes-0.8.2 cmd2-2.2.0 colorama-0.4.4 colorlog-6.5.0 optuna-2.10.0 pbr-5.6.0 pyperclip-1.8.2 stevedore-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "3e5a0bd1-3e22-4b2c-a565-68985e55f95e",
        "_uuid": "e331dbcc-0346-4019-9ff6-b890154a878b",
        "execution": {
          "iopub.execute_input": "2021-10-07T13:42:44.091398Z",
          "iopub.status.busy": "2021-10-07T13:42:44.090045Z",
          "iopub.status.idle": "2021-10-07T13:42:51.274417Z",
          "shell.execute_reply": "2021-10-07T13:42:51.273780Z",
          "shell.execute_reply.started": "2021-10-06T07:27:20.229376Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "papermill": {
          "duration": 7.197728,
          "end_time": "2021-10-07T13:42:51.274629",
          "exception": false,
          "start_time": "2021-10-07T13:42:44.076901",
          "status": "completed"
        },
        "tags": [],
        "id": "08c38ea9"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import optuna\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.preprocessing import RobustScaler, normalize\n",
        "from sklearn.model_selection import train_test_split, GroupKFold, KFold\n",
        "\n",
        "from IPython.display import display"
      ],
      "id": "08c38ea9",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "89eb257e-0ed2-4f8b-94d6-462a5e995eb1",
        "_uuid": "ca71d87d-6594-4f31-906d-0b53cd4c1374",
        "execution": {
          "iopub.execute_input": "2021-10-07T13:42:51.298700Z",
          "iopub.status.busy": "2021-10-07T13:42:51.297870Z",
          "iopub.status.idle": "2021-10-07T13:43:04.843622Z",
          "shell.execute_reply": "2021-10-07T13:43:04.844111Z",
          "shell.execute_reply.started": "2021-10-06T07:27:20.23849Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "papermill": {
          "duration": 13.56036,
          "end_time": "2021-10-07T13:43:04.844301",
          "exception": false,
          "start_time": "2021-10-07T13:42:51.283941",
          "status": "completed"
        },
        "tags": [],
        "id": "735fbfa4"
      },
      "source": [
        "DEBUG = False\n",
        "\n",
        "train = pd.read_csv('/kaggle/input/ventilator-pressure-prediction/train.csv')\n",
        "test = pd.read_csv('/kaggle/input/ventilator-pressure-prediction/test.csv')\n",
        "submission = pd.read_csv('/kaggle/input/ventilator-pressure-prediction/sample_submission.csv')\n",
        "\n",
        "if DEBUG:\n",
        "    train = train[:80*1000]"
      ],
      "id": "735fbfa4",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.00769,
          "end_time": "2021-10-07T13:43:04.860045",
          "exception": false,
          "start_time": "2021-10-07T13:43:04.852355",
          "status": "completed"
        },
        "tags": [],
        "id": "af1eb95c"
      },
      "source": [
        "## Engineer Features"
      ],
      "id": "af1eb95c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.007522,
          "end_time": "2021-10-07T13:43:04.875490",
          "exception": false,
          "start_time": "2021-10-07T13:43:04.867968",
          "status": "completed"
        },
        "tags": [],
        "id": "db48a273"
      },
      "source": [
        "## From [Ventilator: Feature engineering](https://www.kaggle.com/mistag/ventilator-feature-engineering)"
      ],
      "id": "db48a273"
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "13a36b46-7067-4b29-aad3-7e3b15e8415b",
        "_uuid": "dc41dbf2-f199-4b9d-bbd9-bf6084162b47",
        "execution": {
          "iopub.execute_input": "2021-10-07T13:43:04.917023Z",
          "iopub.status.busy": "2021-10-07T13:43:04.911085Z",
          "iopub.status.idle": "2021-10-07T13:43:43.661039Z",
          "shell.execute_reply": "2021-10-07T13:43:43.661484Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "papermill": {
          "duration": 38.778258,
          "end_time": "2021-10-07T13:43:43.661678",
          "exception": false,
          "start_time": "2021-10-07T13:43:04.883420",
          "status": "completed"
        },
        "tags": [],
        "id": "34bf48a7"
      },
      "source": [
        "#Feature engineering\n",
        "def add_features(df):\n",
        "    df['area'] = df['time_step'] * df['u_in']\n",
        "    df['area'] = df.groupby('breath_id')['area'].cumsum()\n",
        "    \n",
        "    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n",
        "    \n",
        "    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n",
        "    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n",
        "    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n",
        "    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n",
        "    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n",
        "    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n",
        "    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n",
        "    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n",
        "    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n",
        "    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n",
        "    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n",
        "    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n",
        "    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n",
        "    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n",
        "    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n",
        "    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n",
        "    df = df.fillna(0)\n",
        "    \n",
        "    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n",
        "    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n",
        "    \n",
        "    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n",
        "    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n",
        "    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n",
        "    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n",
        "    \n",
        "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
        "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
        "    \n",
        "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
        "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
        "    \n",
        "    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n",
        "    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n",
        "    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n",
        "    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n",
        "    df['cross']= df['u_in']*df['u_out']\n",
        "    df['cross2']= df['time_step']*df['u_out']\n",
        "    \n",
        "    df['R'] = df['R'].astype(str)\n",
        "    df['C'] = df['C'].astype(str)\n",
        "    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n",
        "    df = pd.get_dummies(df)\n",
        "    return df\n",
        "\n",
        "train = add_features(train)\n",
        "test = add_features(test)"
      ],
      "id": "34bf48a7",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-07T13:43:43.684700Z",
          "iopub.status.busy": "2021-10-07T13:43:43.684073Z",
          "iopub.status.idle": "2021-10-07T13:43:43.688031Z",
          "shell.execute_reply": "2021-10-07T13:43:43.688508Z"
        },
        "papermill": {
          "duration": 0.018945,
          "end_time": "2021-10-07T13:43:43.688688",
          "exception": false,
          "start_time": "2021-10-07T13:43:43.669743",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9bc5ccf",
        "outputId": "15d2c271-9129-4e20-a32d-73c4d1aa46cb"
      },
      "source": [
        "train.shape\n",
        "test.shape"
      ],
      "id": "f9bc5ccf",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4024000, 52)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "01328860-fa2a-421c-9e5f-ea0048246f98",
        "_uuid": "346bf2c0-96d2-4da5-8837-c0f820294a85",
        "execution": {
          "iopub.execute_input": "2021-10-07T13:43:43.709994Z",
          "iopub.status.busy": "2021-10-07T13:43:43.709306Z",
          "iopub.status.idle": "2021-10-07T13:43:47.135372Z",
          "shell.execute_reply": "2021-10-07T13:43:47.134816Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "papermill": {
          "duration": 3.437871,
          "end_time": "2021-10-07T13:43:47.135523",
          "exception": false,
          "start_time": "2021-10-07T13:43:43.697652",
          "status": "completed"
        },
        "tags": [],
        "id": "72bad96f"
      },
      "source": [
        "targets = train[['pressure']].to_numpy().reshape(-1, 80)\n",
        "train.drop(['pressure', 'id', 'breath_id'], axis=1, inplace=True)\n",
        "test = test.drop(['id', 'breath_id'], axis=1)"
      ],
      "id": "72bad96f",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-07T13:43:47.161397Z",
          "iopub.status.busy": "2021-10-07T13:43:47.160008Z",
          "iopub.status.idle": "2021-10-07T13:43:57.821082Z",
          "shell.execute_reply": "2021-10-07T13:43:57.820564Z"
        },
        "papermill": {
          "duration": 10.676832,
          "end_time": "2021-10-07T13:43:57.821233",
          "exception": false,
          "start_time": "2021-10-07T13:43:47.144401",
          "status": "completed"
        },
        "tags": [],
        "id": "e18e67ff"
      },
      "source": [
        "#Normalise the dataset\n",
        "RS = RobustScaler()\n",
        "train = RS.fit_transform(train)\n",
        "test = RS.transform(test)"
      ],
      "id": "e18e67ff",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-07T13:43:57.844046Z",
          "iopub.status.busy": "2021-10-07T13:43:57.843150Z",
          "iopub.status.idle": "2021-10-07T13:43:57.846063Z",
          "shell.execute_reply": "2021-10-07T13:43:57.845508Z"
        },
        "papermill": {
          "duration": 0.016185,
          "end_time": "2021-10-07T13:43:57.846195",
          "exception": false,
          "start_time": "2021-10-07T13:43:57.830010",
          "status": "completed"
        },
        "tags": [],
        "id": "0174b86a"
      },
      "source": [
        "#Reshape group to 80 timesteps for each breath ID\n",
        "train = train.reshape(-1, 80, train.shape[-1])\n",
        "test = test.reshape(-1, 80, train.shape[-1])"
      ],
      "id": "0174b86a",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.00825,
          "end_time": "2021-10-07T13:43:57.863196",
          "exception": false,
          "start_time": "2021-10-07T13:43:57.854946",
          "status": "completed"
        },
        "tags": [],
        "id": "54d2fb01"
      },
      "source": [
        "## Model"
      ],
      "id": "54d2fb01"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-07T13:43:57.892905Z",
          "iopub.status.busy": "2021-10-07T13:43:57.892246Z",
          "iopub.status.idle": "2021-10-07T13:43:58.199913Z",
          "shell.execute_reply": "2021-10-07T13:43:58.199263Z",
          "shell.execute_reply.started": "2021-10-06T07:28:39.357315Z"
        },
        "papermill": {
          "duration": 0.328414,
          "end_time": "2021-10-07T13:43:58.200201",
          "exception": true,
          "start_time": "2021-10-07T13:43:57.871787",
          "status": "failed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dcf75dc",
        "outputId": "c71da7d6-29db-4dce-bbaa-9b86454f6b83"
      },
      "source": [
        "EPOCH = 300\n",
        "BATCH_SIZE = 1024\n",
        "NUM_FOLDS = 10\n",
        "\n",
        "# detect and init the TPU\n",
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
        "\n",
        "# instantiate a distribution strategy\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "#GPU init\n",
        "#gpu_strategy = tf.distribute.get_strategy()\n",
        "\n",
        "#with gpu_strategy.scope():\n",
        "with tpu_strategy.scope():\n",
        "    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=2021)\n",
        "    test_preds = []\n",
        "    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n",
        "        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n",
        "        X_train, X_valid = train[train_idx], train[test_idx]\n",
        "        y_train, y_valid = targets[train_idx], targets[test_idx]\n",
        "        model = keras.models.Sequential([\n",
        "            keras.layers.Input(shape=train.shape[-2:]),\n",
        "            #bidirectional LSTM 1024->512->256->128\n",
        "            keras.layers.Bidirectional(keras.layers.LSTM(1024, return_sequences=True)),\n",
        "            keras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True)),\n",
        "            keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True)),\n",
        "            keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),\n",
        "\n",
        "            keras.layers.Dense(128, activation='selu'),\n",
        "          # keras.layers.Dropout(0.1),\n",
        "            keras.layers.Dense(1),\n",
        "        ])\n",
        "        model.compile(optimizer=\"adam\", loss=\"mae\")\n",
        "\n",
        "        scheduler = ExponentialDecay(1e-3, 40*((len(train)*0.8)/BATCH_SIZE), 1e-5)\n",
        "        lr = LearningRateScheduler(scheduler, verbose=1)\n",
        "        \n",
        "        #lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1)\n",
        "        #lr = WarmupExponentialDecay(lr_base=1e-3, decay=1e-5, warmup_epochs=30)\n",
        "        es = EarlyStopping(monitor=\"val_loss\", patience=60, verbose=1, mode=\"min\", restore_best_weights=True)\n",
        "    \n",
        "        checkpoint_filepath = f\"folds{fold}.hdf5\"\n",
        "        sv = keras.callbacks.ModelCheckpoint(\n",
        "            checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n",
        "            save_weights_only=False, mode='auto', save_freq='epoch',\n",
        "            options=None\n",
        "        )\n",
        "\n",
        "        model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr, es, sv])\n",
        "        #model.save(f'Fold{fold+1} RNN Weights')\n",
        "        test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())"
      ],
      "id": "2dcf75dc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.3.219.42:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.3.219.42:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1094 - val_loss: 0.1765\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.17501\n",
            "Epoch 148/300\n",
            "\n",
            "Epoch 00148: LearningRateScheduler setting learning rate to tf.Tensor(0.00048783212, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1107 - val_loss: 0.1800\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.17501\n",
            "Epoch 149/300\n",
            "\n",
            "Epoch 00149: LearningRateScheduler setting learning rate to tf.Tensor(0.00048545588, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1096 - val_loss: 0.1797\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.17501\n",
            "Epoch 150/300\n",
            "\n",
            "Epoch 00150: LearningRateScheduler setting learning rate to tf.Tensor(0.00048309125, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1115 - val_loss: 0.1760\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.17501\n",
            "Epoch 151/300\n",
            "\n",
            "Epoch 00151: LearningRateScheduler setting learning rate to tf.Tensor(0.00048073815, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1087 - val_loss: 0.1771\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.17501\n",
            "Epoch 152/300\n",
            "\n",
            "Epoch 00152: LearningRateScheduler setting learning rate to tf.Tensor(0.00047839645, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1099 - val_loss: 0.1768\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.17501\n",
            "Epoch 153/300\n",
            "\n",
            "Epoch 00153: LearningRateScheduler setting learning rate to tf.Tensor(0.0004760662, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1241 - val_loss: 0.1829\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.17501\n",
            "Epoch 154/300\n",
            "\n",
            "Epoch 00154: LearningRateScheduler setting learning rate to tf.Tensor(0.0004737473, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1188 - val_loss: 0.1815\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.17501\n",
            "Epoch 155/300\n",
            "\n",
            "Epoch 00155: LearningRateScheduler setting learning rate to tf.Tensor(0.00047143968, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1101 - val_loss: 0.1764\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.17501\n",
            "Epoch 156/300\n",
            "\n",
            "Epoch 00156: LearningRateScheduler setting learning rate to tf.Tensor(0.0004691433, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1129 - val_loss: 0.1843\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.17501\n",
            "Epoch 157/300\n",
            "\n",
            "Epoch 00157: LearningRateScheduler setting learning rate to tf.Tensor(0.00046685815, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1220 - val_loss: 0.1818\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.17501\n",
            "Epoch 158/300\n",
            "\n",
            "Epoch 00158: LearningRateScheduler setting learning rate to tf.Tensor(0.00046458407, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1210 - val_loss: 0.1898\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.17501\n",
            "Epoch 159/300\n",
            "\n",
            "Epoch 00159: LearningRateScheduler setting learning rate to tf.Tensor(0.00046232107, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1156 - val_loss: 0.1779\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.17501\n",
            "Epoch 160/300\n",
            "\n",
            "Epoch 00160: LearningRateScheduler setting learning rate to tf.Tensor(0.00046006907, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1096 - val_loss: 0.1760\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.17501\n",
            "Epoch 161/300\n",
            "\n",
            "Epoch 00161: LearningRateScheduler setting learning rate to tf.Tensor(0.00045782814, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1075 - val_loss: 0.1818\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.17501\n",
            "Epoch 162/300\n",
            "\n",
            "Epoch 00162: LearningRateScheduler setting learning rate to tf.Tensor(0.00045559806, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1043 - val_loss: 0.1765\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.17501\n",
            "Epoch 163/300\n",
            "\n",
            "Epoch 00163: LearningRateScheduler setting learning rate to tf.Tensor(0.00045337883, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 643ms/step - loss: 0.1037 - val_loss: 0.1763\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.17501\n",
            "Epoch 164/300\n",
            "\n",
            "Epoch 00164: LearningRateScheduler setting learning rate to tf.Tensor(0.00045117046, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1020 - val_loss: 0.1806\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.17501\n",
            "Epoch 165/300\n",
            "\n",
            "Epoch 00165: LearningRateScheduler setting learning rate to tf.Tensor(0.00044897277, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1016 - val_loss: 0.1762\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.17501\n",
            "Epoch 166/300\n",
            "\n",
            "Epoch 00166: LearningRateScheduler setting learning rate to tf.Tensor(0.00044678585, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0995 - val_loss: 0.1756\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.17501\n",
            "Epoch 167/300\n",
            "\n",
            "Epoch 00167: LearningRateScheduler setting learning rate to tf.Tensor(0.0004446096, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1114 - val_loss: 0.1794\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.17501\n",
            "Epoch 168/300\n",
            "\n",
            "Epoch 00168: LearningRateScheduler setting learning rate to tf.Tensor(0.0004424439, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 44s 651ms/step - loss: 0.1083 - val_loss: 0.1795\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.17501\n",
            "Epoch 169/300\n",
            "\n",
            "Epoch 00169: LearningRateScheduler setting learning rate to tf.Tensor(0.00044028874, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1039 - val_loss: 0.1775\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.17501\n",
            "Epoch 170/300\n",
            "\n",
            "Epoch 00170: LearningRateScheduler setting learning rate to tf.Tensor(0.00043814414, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0997 - val_loss: 0.1734\n",
            "\n",
            "Epoch 00170: val_loss improved from 0.17501 to 0.17336, saving model to folds0.hdf5\n",
            "Epoch 171/300\n",
            "\n",
            "Epoch 00171: LearningRateScheduler setting learning rate to tf.Tensor(0.00043600993, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0994 - val_loss: 0.1775\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.17336\n",
            "Epoch 172/300\n",
            "\n",
            "Epoch 00172: LearningRateScheduler setting learning rate to tf.Tensor(0.00043388613, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0978 - val_loss: 0.1745\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.17336\n",
            "Epoch 173/300\n",
            "\n",
            "Epoch 00173: LearningRateScheduler setting learning rate to tf.Tensor(0.0004317727, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0973 - val_loss: 0.1737\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.17336\n",
            "Epoch 174/300\n",
            "\n",
            "Epoch 00174: LearningRateScheduler setting learning rate to tf.Tensor(0.0004296695, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0960 - val_loss: 0.1740\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.17336\n",
            "Epoch 175/300\n",
            "\n",
            "Epoch 00175: LearningRateScheduler setting learning rate to tf.Tensor(0.0004275766, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0964 - val_loss: 0.1735\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.17336\n",
            "Epoch 176/300\n",
            "\n",
            "Epoch 00176: LearningRateScheduler setting learning rate to tf.Tensor(0.00042549393, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0955 - val_loss: 0.1739\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.17336\n",
            "Epoch 177/300\n",
            "\n",
            "Epoch 00177: LearningRateScheduler setting learning rate to tf.Tensor(0.00042342133, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0942 - val_loss: 0.1817\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.17336\n",
            "Epoch 178/300\n",
            "\n",
            "Epoch 00178: LearningRateScheduler setting learning rate to tf.Tensor(0.00042135885, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0937 - val_loss: 0.1761\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.17336\n",
            "Epoch 179/300\n",
            "\n",
            "Epoch 00179: LearningRateScheduler setting learning rate to tf.Tensor(0.00041930642, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0953 - val_loss: 0.1801\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.17336\n",
            "Epoch 180/300\n",
            "\n",
            "Epoch 00180: LearningRateScheduler setting learning rate to tf.Tensor(0.00041726397, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0946 - val_loss: 0.1765\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.17336\n",
            "Epoch 181/300\n",
            "\n",
            "Epoch 00181: LearningRateScheduler setting learning rate to tf.Tensor(0.00041523148, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0931 - val_loss: 0.1740\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.17336\n",
            "Epoch 182/300\n",
            "\n",
            "Epoch 00182: LearningRateScheduler setting learning rate to tf.Tensor(0.00041320888, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0915 - val_loss: 0.1742\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.17336\n",
            "Epoch 183/300\n",
            "\n",
            "Epoch 00183: LearningRateScheduler setting learning rate to tf.Tensor(0.00041119618, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0914 - val_loss: 0.1754\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.17336\n",
            "Epoch 184/300\n",
            "\n",
            "Epoch 00184: LearningRateScheduler setting learning rate to tf.Tensor(0.00040919325, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0912 - val_loss: 0.1755\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.17336\n",
            "Epoch 185/300\n",
            "\n",
            "Epoch 00185: LearningRateScheduler setting learning rate to tf.Tensor(0.00040720004, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0904 - val_loss: 0.1750\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.17336\n",
            "Epoch 186/300\n",
            "\n",
            "Epoch 00186: LearningRateScheduler setting learning rate to tf.Tensor(0.0004052166, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0903 - val_loss: 0.1750\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.17336\n",
            "Epoch 187/300\n",
            "\n",
            "Epoch 00187: LearningRateScheduler setting learning rate to tf.Tensor(0.0004032428, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0891 - val_loss: 0.1747\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.17336\n",
            "Epoch 188/300\n",
            "\n",
            "Epoch 00188: LearningRateScheduler setting learning rate to tf.Tensor(0.0004012786, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0886 - val_loss: 0.1752\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.17336\n",
            "Epoch 189/300\n",
            "\n",
            "Epoch 00189: LearningRateScheduler setting learning rate to tf.Tensor(0.00039932402, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0879 - val_loss: 0.1772\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.17336\n",
            "Epoch 190/300\n",
            "\n",
            "Epoch 00190: LearningRateScheduler setting learning rate to tf.Tensor(0.00039737887, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0876 - val_loss: 0.1767\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.17336\n",
            "Epoch 191/300\n",
            "\n",
            "Epoch 00191: LearningRateScheduler setting learning rate to tf.Tensor(0.00039544326, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0900 - val_loss: 0.1762\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.17336\n",
            "Epoch 192/300\n",
            "\n",
            "Epoch 00192: LearningRateScheduler setting learning rate to tf.Tensor(0.00039351705, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0889 - val_loss: 0.1757\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.17336\n",
            "Epoch 193/300\n",
            "\n",
            "Epoch 00193: LearningRateScheduler setting learning rate to tf.Tensor(0.00039160028, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0861 - val_loss: 0.1744\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.17336\n",
            "Epoch 194/300\n",
            "\n",
            "Epoch 00194: LearningRateScheduler setting learning rate to tf.Tensor(0.00038969278, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0857 - val_loss: 0.1774\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.17336\n",
            "Epoch 195/300\n",
            "\n",
            "Epoch 00195: LearningRateScheduler setting learning rate to tf.Tensor(0.0003877946, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0865 - val_loss: 0.1754\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.17336\n",
            "Epoch 196/300\n",
            "\n",
            "Epoch 00196: LearningRateScheduler setting learning rate to tf.Tensor(0.00038590565, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0846 - val_loss: 0.1748\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.17336\n",
            "Epoch 197/300\n",
            "\n",
            "Epoch 00197: LearningRateScheduler setting learning rate to tf.Tensor(0.0003840259, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0858 - val_loss: 0.1768\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.17336\n",
            "Epoch 198/300\n",
            "\n",
            "Epoch 00198: LearningRateScheduler setting learning rate to tf.Tensor(0.00038215535, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0842 - val_loss: 0.1766\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.17336\n",
            "Epoch 199/300\n",
            "\n",
            "Epoch 00199: LearningRateScheduler setting learning rate to tf.Tensor(0.00038029387, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0836 - val_loss: 0.1759\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.17336\n",
            "Epoch 200/300\n",
            "\n",
            "Epoch 00200: LearningRateScheduler setting learning rate to tf.Tensor(0.00037844144, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0835 - val_loss: 0.1753\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.17336\n",
            "Epoch 201/300\n",
            "\n",
            "Epoch 00201: LearningRateScheduler setting learning rate to tf.Tensor(0.00037659804, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0818 - val_loss: 0.1775\n",
            "\n",
            "Epoch 00201: val_loss did not improve from 0.17336\n",
            "Epoch 202/300\n",
            "\n",
            "Epoch 00202: LearningRateScheduler setting learning rate to tf.Tensor(0.00037476368, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0828 - val_loss: 0.1748\n",
            "\n",
            "Epoch 00202: val_loss did not improve from 0.17336\n",
            "Epoch 203/300\n",
            "\n",
            "Epoch 00203: LearningRateScheduler setting learning rate to tf.Tensor(0.00037293817, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0810 - val_loss: 0.1764\n",
            "\n",
            "Epoch 00203: val_loss did not improve from 0.17336\n",
            "Epoch 204/300\n",
            "\n",
            "Epoch 00204: LearningRateScheduler setting learning rate to tf.Tensor(0.0003711216, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0808 - val_loss: 0.1759\n",
            "\n",
            "Epoch 00204: val_loss did not improve from 0.17336\n",
            "Epoch 205/300\n",
            "\n",
            "Epoch 00205: LearningRateScheduler setting learning rate to tf.Tensor(0.0003693139, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0801 - val_loss: 0.1752\n",
            "\n",
            "Epoch 00205: val_loss did not improve from 0.17336\n",
            "Epoch 206/300\n",
            "\n",
            "Epoch 00206: LearningRateScheduler setting learning rate to tf.Tensor(0.000367515, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0811 - val_loss: 0.1760\n",
            "\n",
            "Epoch 00206: val_loss did not improve from 0.17336\n",
            "Epoch 207/300\n",
            "\n",
            "Epoch 00207: LearningRateScheduler setting learning rate to tf.Tensor(0.00036572482, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0801 - val_loss: 0.1748\n",
            "\n",
            "Epoch 00207: val_loss did not improve from 0.17336\n",
            "Epoch 208/300\n",
            "\n",
            "Epoch 00208: LearningRateScheduler setting learning rate to tf.Tensor(0.0003639434, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0795 - val_loss: 0.1752\n",
            "\n",
            "Epoch 00208: val_loss did not improve from 0.17336\n",
            "Epoch 209/300\n",
            "\n",
            "Epoch 00209: LearningRateScheduler setting learning rate to tf.Tensor(0.00036217063, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0789 - val_loss: 0.1749\n",
            "\n",
            "Epoch 00209: val_loss did not improve from 0.17336\n",
            "Epoch 210/300\n",
            "\n",
            "Epoch 00210: LearningRateScheduler setting learning rate to tf.Tensor(0.00036040647, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0781 - val_loss: 0.1752\n",
            "\n",
            "Epoch 00210: val_loss did not improve from 0.17336\n",
            "Epoch 211/300\n",
            "\n",
            "Epoch 00211: LearningRateScheduler setting learning rate to tf.Tensor(0.00035865093, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0783 - val_loss: 0.1755\n",
            "\n",
            "Epoch 00211: val_loss did not improve from 0.17336\n",
            "Epoch 212/300\n",
            "\n",
            "Epoch 00212: LearningRateScheduler setting learning rate to tf.Tensor(0.000356904, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0780 - val_loss: 0.1759\n",
            "\n",
            "Epoch 00212: val_loss did not improve from 0.17336\n",
            "Epoch 213/300\n",
            "\n",
            "Epoch 00213: LearningRateScheduler setting learning rate to tf.Tensor(0.0003551655, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0782 - val_loss: 0.1767\n",
            "\n",
            "Epoch 00213: val_loss did not improve from 0.17336\n",
            "Epoch 214/300\n",
            "\n",
            "Epoch 00214: LearningRateScheduler setting learning rate to tf.Tensor(0.0003534355, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0776 - val_loss: 0.1755\n",
            "\n",
            "Epoch 00214: val_loss did not improve from 0.17336\n",
            "Epoch 215/300\n",
            "\n",
            "Epoch 00215: LearningRateScheduler setting learning rate to tf.Tensor(0.0003517139, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0764 - val_loss: 0.1749\n",
            "\n",
            "Epoch 00215: val_loss did not improve from 0.17336\n",
            "Epoch 216/300\n",
            "\n",
            "Epoch 00216: LearningRateScheduler setting learning rate to tf.Tensor(0.0003500007, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0767 - val_loss: 0.1768\n",
            "\n",
            "Epoch 00216: val_loss did not improve from 0.17336\n",
            "Epoch 217/300\n",
            "\n",
            "Epoch 00217: LearningRateScheduler setting learning rate to tf.Tensor(0.00034829587, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 44s 650ms/step - loss: 0.0759 - val_loss: 0.1764\n",
            "\n",
            "Epoch 00217: val_loss did not improve from 0.17336\n",
            "Epoch 218/300\n",
            "\n",
            "Epoch 00218: LearningRateScheduler setting learning rate to tf.Tensor(0.00034659932, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0767 - val_loss: 0.1780\n",
            "\n",
            "Epoch 00218: val_loss did not improve from 0.17336\n",
            "Epoch 219/300\n",
            "\n",
            "Epoch 00219: LearningRateScheduler setting learning rate to tf.Tensor(0.00034491107, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0751 - val_loss: 0.1754\n",
            "\n",
            "Epoch 00219: val_loss did not improve from 0.17336\n",
            "Epoch 220/300\n",
            "\n",
            "Epoch 00220: LearningRateScheduler setting learning rate to tf.Tensor(0.00034323102, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0741 - val_loss: 0.1763\n",
            "\n",
            "Epoch 00220: val_loss did not improve from 0.17336\n",
            "Epoch 221/300\n",
            "\n",
            "Epoch 00221: LearningRateScheduler setting learning rate to tf.Tensor(0.00034155912, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0740 - val_loss: 0.1776\n",
            "\n",
            "Epoch 00221: val_loss did not improve from 0.17336\n",
            "Epoch 222/300\n",
            "\n",
            "Epoch 00222: LearningRateScheduler setting learning rate to tf.Tensor(0.00033989537, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0740 - val_loss: 0.1758\n",
            "\n",
            "Epoch 00222: val_loss did not improve from 0.17336\n",
            "Epoch 223/300\n",
            "\n",
            "Epoch 00223: LearningRateScheduler setting learning rate to tf.Tensor(0.00033823974, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0740 - val_loss: 0.1757\n",
            "\n",
            "Epoch 00223: val_loss did not improve from 0.17336\n",
            "Epoch 224/300\n",
            "\n",
            "Epoch 00224: LearningRateScheduler setting learning rate to tf.Tensor(0.0003365922, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0733 - val_loss: 0.1770\n",
            "\n",
            "Epoch 00224: val_loss did not improve from 0.17336\n",
            "Epoch 225/300\n",
            "\n",
            "Epoch 00225: LearningRateScheduler setting learning rate to tf.Tensor(0.00033495267, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0722 - val_loss: 0.1761\n",
            "\n",
            "Epoch 00225: val_loss did not improve from 0.17336\n",
            "Epoch 226/300\n",
            "\n",
            "Epoch 00226: LearningRateScheduler setting learning rate to tf.Tensor(0.0003333211, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0717 - val_loss: 0.1762\n",
            "\n",
            "Epoch 00226: val_loss did not improve from 0.17336\n",
            "Epoch 227/300\n",
            "\n",
            "Epoch 00227: LearningRateScheduler setting learning rate to tf.Tensor(0.00033169755, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0741 - val_loss: 0.1778\n",
            "\n",
            "Epoch 00227: val_loss did not improve from 0.17336\n",
            "Epoch 228/300\n",
            "\n",
            "Epoch 00228: LearningRateScheduler setting learning rate to tf.Tensor(0.00033008185, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0714 - val_loss: 0.1757\n",
            "\n",
            "Epoch 00228: val_loss did not improve from 0.17336\n",
            "Epoch 229/300\n",
            "\n",
            "Epoch 00229: LearningRateScheduler setting learning rate to tf.Tensor(0.000328474, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0715 - val_loss: 0.1763\n",
            "\n",
            "Epoch 00229: val_loss did not improve from 0.17336\n",
            "Epoch 230/300\n",
            "\n",
            "Epoch 00230: LearningRateScheduler setting learning rate to tf.Tensor(0.00032687403, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0704 - val_loss: 0.1773\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00230: val_loss did not improve from 0.17336\n",
            "Epoch 00230: early stopping\n",
            "--------------- > Fold 2 < ---------------\n",
            "Epoch 1/300\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 106s 1s/step - loss: 2.4695 - val_loss: 1.2021\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.20212, saving model to folds1.hdf5\n",
            "Epoch 2/300\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.8940 - val_loss: 0.7316\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.20212 to 0.73158, saving model to folds1.hdf5\n",
            "Epoch 3/300\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.6535 - val_loss: 0.5945\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.73158 to 0.59455, saving model to folds1.hdf5\n",
            "Epoch 4/300\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.5540 - val_loss: 0.5644\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.59455 to 0.56443, saving model to folds1.hdf5\n",
            "Epoch 5/300\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.5158 - val_loss: 0.4954\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.56443 to 0.49539, saving model to folds1.hdf5\n",
            "Epoch 6/300\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.4606 - val_loss: 0.4221\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.49539 to 0.42211, saving model to folds1.hdf5\n",
            "Epoch 7/300\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 646ms/step - loss: 0.4341 - val_loss: 0.4386\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.42211\n",
            "Epoch 8/300\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.4064 - val_loss: 0.3870\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.42211 to 0.38702, saving model to folds1.hdf5\n",
            "Epoch 9/300\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.3885 - val_loss: 0.3832\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.38702 to 0.38317, saving model to folds1.hdf5\n",
            "Epoch 10/300\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.3741 - val_loss: 0.3667\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.38317 to 0.36670, saving model to folds1.hdf5\n",
            "Epoch 11/300\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.3605 - val_loss: 0.3500\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.36670 to 0.34999, saving model to folds1.hdf5\n",
            "Epoch 12/300\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.3583 - val_loss: 0.3491\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.34999 to 0.34908, saving model to folds1.hdf5\n",
            "Epoch 13/300\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.3384 - val_loss: 0.3351\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.34908 to 0.33512, saving model to folds1.hdf5\n",
            "Epoch 14/300\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.3279 - val_loss: 0.3407\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.33512\n",
            "Epoch 15/300\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.3226 - val_loss: 0.3063\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.33512 to 0.30633, saving model to folds1.hdf5\n",
            "Epoch 16/300\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.3181 - val_loss: 0.3390\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.30633\n",
            "Epoch 17/300\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.3101 - val_loss: 0.2989\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.30633 to 0.29887, saving model to folds1.hdf5\n",
            "Epoch 18/300\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.2986 - val_loss: 0.2953\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.29887 to 0.29529, saving model to folds1.hdf5\n",
            "Epoch 19/300\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.2943 - val_loss: 0.3737\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.29529\n",
            "Epoch 20/300\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.2959 - val_loss: 0.2709\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.29529 to 0.27094, saving model to folds1.hdf5\n",
            "Epoch 21/300\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2801 - val_loss: 0.3251\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.27094\n",
            "Epoch 22/300\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2713 - val_loss: 0.2656\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.27094 to 0.26560, saving model to folds1.hdf5\n",
            "Epoch 23/300\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2699 - val_loss: 0.2797\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.26560\n",
            "Epoch 24/300\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2555 - val_loss: 0.2764\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.26560\n",
            "Epoch 25/300\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.2495 - val_loss: 0.2497\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.26560 to 0.24967, saving model to folds1.hdf5\n",
            "Epoch 26/300\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.2476 - val_loss: 0.2521\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.24967\n",
            "Epoch 27/300\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.2439 - val_loss: 0.2790\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.24967\n",
            "Epoch 28/300\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.2445 - val_loss: 0.2446\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.24967 to 0.24456, saving model to folds1.hdf5\n",
            "Epoch 29/300\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2494 - val_loss: 0.2465\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.24456\n",
            "Epoch 30/300\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.2494 - val_loss: 0.3281\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.24456\n",
            "Epoch 31/300\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.2585 - val_loss: 0.2360\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.24456 to 0.23598, saving model to folds1.hdf5\n",
            "Epoch 32/300\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.2363 - val_loss: 0.2575\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.23598\n",
            "Epoch 33/300\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2397 - val_loss: 0.2384\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.23598\n",
            "Epoch 34/300\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2292 - val_loss: 0.2323\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.23598 to 0.23232, saving model to folds1.hdf5\n",
            "Epoch 35/300\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.2240 - val_loss: 0.2427\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.23232\n",
            "Epoch 36/300\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2335 - val_loss: 0.2310\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.23232 to 0.23103, saving model to folds1.hdf5\n",
            "Epoch 37/300\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2173 - val_loss: 0.2319\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.23103\n",
            "Epoch 38/300\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2268 - val_loss: 0.2274\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.23103 to 0.22744, saving model to folds1.hdf5\n",
            "Epoch 39/300\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2148 - val_loss: 0.2234\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.22744 to 0.22341, saving model to folds1.hdf5\n",
            "Epoch 40/300\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2119 - val_loss: 0.2208\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.22341 to 0.22080, saving model to folds1.hdf5\n",
            "Epoch 41/300\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2119 - val_loss: 0.2272\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.22080\n",
            "Epoch 42/300\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2158 - val_loss: 0.2200\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.22080 to 0.21997, saving model to folds1.hdf5\n",
            "Epoch 43/300\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2084 - val_loss: 0.2300\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.21997\n",
            "Epoch 44/300\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2128 - val_loss: 0.2703\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.21997\n",
            "Epoch 45/300\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2168 - val_loss: 0.2471\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.21997\n",
            "Epoch 46/300\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.2179 - val_loss: 0.2439\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.21997\n",
            "Epoch 47/300\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2255 - val_loss: 0.2360\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.21997\n",
            "Epoch 48/300\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.2075 - val_loss: 0.2132\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.21997 to 0.21317, saving model to folds1.hdf5\n",
            "Epoch 49/300\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.2022 - val_loss: 0.2239\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.21317\n",
            "Epoch 50/300\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1981 - val_loss: 0.2079\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.21317 to 0.20786, saving model to folds1.hdf5\n",
            "Epoch 51/300\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1975 - val_loss: 0.2164\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.20786\n",
            "Epoch 52/300\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1929 - val_loss: 0.2150\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.20786\n",
            "Epoch 53/300\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 649ms/step - loss: 0.1984 - val_loss: 0.2121\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.20786\n",
            "Epoch 54/300\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1934 - val_loss: 0.2104\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.20786\n",
            "Epoch 55/300\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1866 - val_loss: 0.2087\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.20786\n",
            "Epoch 56/300\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1942 - val_loss: 0.2200\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.20786\n",
            "Epoch 57/300\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 645ms/step - loss: 0.1985 - val_loss: 0.2106\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.20786\n",
            "Epoch 58/300\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1973 - val_loss: 0.2051\n",
            "\n",
            "Epoch 00058: val_loss improved from 0.20786 to 0.20512, saving model to folds1.hdf5\n",
            "Epoch 59/300\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1869 - val_loss: 0.2410\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.20512\n",
            "Epoch 60/300\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1972 - val_loss: 0.2436\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.20512\n",
            "Epoch 61/300\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1954 - val_loss: 0.2136\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.20512\n",
            "Epoch 62/300\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1894 - val_loss: 0.2112\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.20512\n",
            "Epoch 63/300\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to tf.Tensor(0.0007387921, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1840 - val_loss: 0.1999\n",
            "\n",
            "Epoch 00063: val_loss improved from 0.20512 to 0.19991, saving model to folds1.hdf5\n",
            "Epoch 64/300\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to tf.Tensor(0.00073519343, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1835 - val_loss: 0.2045\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.19991\n",
            "Epoch 65/300\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to tf.Tensor(0.0007316123, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1851 - val_loss: 0.2175\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.19991\n",
            "Epoch 66/300\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to tf.Tensor(0.0007280487, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 643ms/step - loss: 0.1805 - val_loss: 0.1985\n",
            "\n",
            "Epoch 00066: val_loss improved from 0.19991 to 0.19853, saving model to folds1.hdf5\n",
            "Epoch 67/300\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to tf.Tensor(0.0007245024, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1797 - val_loss: 0.2014\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.19853\n",
            "Epoch 68/300\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to tf.Tensor(0.0007209733, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1771 - val_loss: 0.2002\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.19853\n",
            "Epoch 69/300\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to tf.Tensor(0.00071746146, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1775 - val_loss: 0.1881\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.19853 to 0.18806, saving model to folds1.hdf5\n",
            "Epoch 70/300\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to tf.Tensor(0.0007139667, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1829 - val_loss: 0.2119\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.18806\n",
            "Epoch 71/300\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to tf.Tensor(0.00071048894, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1835 - val_loss: 0.2017\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.18806\n",
            "Epoch 72/300\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to tf.Tensor(0.0007070282, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1773 - val_loss: 0.1974\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.18806\n",
            "Epoch 73/300\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to tf.Tensor(0.0007035842, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1689 - val_loss: 0.1928\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.18806\n",
            "Epoch 74/300\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to tf.Tensor(0.00070015714, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1705 - val_loss: 0.1947\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.18806\n",
            "Epoch 75/300\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to tf.Tensor(0.0006967467, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1690 - val_loss: 0.2012\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.18806\n",
            "Epoch 76/300\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to tf.Tensor(0.00069335283, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1668 - val_loss: 0.1884\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.18806\n",
            "Epoch 77/300\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to tf.Tensor(0.0006899755, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1631 - val_loss: 0.2610\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.18806\n",
            "Epoch 78/300\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to tf.Tensor(0.00068661466, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.2508 - val_loss: 0.2176\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.18806\n",
            "Epoch 79/300\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to tf.Tensor(0.00068327016, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1859 - val_loss: 0.2022\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.18806\n",
            "Epoch 80/300\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to tf.Tensor(0.00067994196, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1789 - val_loss: 0.1897\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.18806\n",
            "Epoch 81/300\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to tf.Tensor(0.00067663, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1665 - val_loss: 0.1867\n",
            "\n",
            "Epoch 00081: val_loss improved from 0.18806 to 0.18674, saving model to folds1.hdf5\n",
            "Epoch 82/300\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to tf.Tensor(0.0006733342, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 643ms/step - loss: 0.1670 - val_loss: 0.1988\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.18674\n",
            "Epoch 83/300\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to tf.Tensor(0.00067005435, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1689 - val_loss: 0.1905\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.18674\n",
            "Epoch 84/300\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to tf.Tensor(0.0006667905, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 643ms/step - loss: 0.1664 - val_loss: 0.2538\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.18674\n",
            "Epoch 85/300\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to tf.Tensor(0.0006635426, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 643ms/step - loss: 0.1744 - val_loss: 0.1893\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.18674\n",
            "Epoch 86/300\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to tf.Tensor(0.0006603105, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1620 - val_loss: 0.1848\n",
            "\n",
            "Epoch 00086: val_loss improved from 0.18674 to 0.18478, saving model to folds1.hdf5\n",
            "Epoch 87/300\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to tf.Tensor(0.0006570942, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1601 - val_loss: 0.1890\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.18478\n",
            "Epoch 88/300\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to tf.Tensor(0.00065389345, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1562 - val_loss: 0.1968\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.18478\n",
            "Epoch 89/300\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to tf.Tensor(0.00065070833, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1611 - val_loss: 0.1859\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.18478\n",
            "Epoch 90/300\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to tf.Tensor(0.00064753875, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1565 - val_loss: 0.1827\n",
            "\n",
            "Epoch 00090: val_loss improved from 0.18478 to 0.18269, saving model to folds1.hdf5\n",
            "Epoch 91/300\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to tf.Tensor(0.0006443846, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1546 - val_loss: 0.1808\n",
            "\n",
            "Epoch 00091: val_loss improved from 0.18269 to 0.18083, saving model to folds1.hdf5\n",
            "Epoch 92/300\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to tf.Tensor(0.0006412458, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1495 - val_loss: 0.1855\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.18083\n",
            "Epoch 93/300\n",
            "\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to tf.Tensor(0.00063812226, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1510 - val_loss: 0.1797\n",
            "\n",
            "Epoch 00093: val_loss improved from 0.18083 to 0.17966, saving model to folds1.hdf5\n",
            "Epoch 94/300\n",
            "\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to tf.Tensor(0.00063501403, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1523 - val_loss: 0.1927\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.17966\n",
            "Epoch 95/300\n",
            "\n",
            "Epoch 00095: LearningRateScheduler setting learning rate to tf.Tensor(0.0006319209, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1531 - val_loss: 0.1807\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.17966\n",
            "Epoch 96/300\n",
            "\n",
            "Epoch 00096: LearningRateScheduler setting learning rate to tf.Tensor(0.0006288428, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1490 - val_loss: 0.1840\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.17966\n",
            "Epoch 97/300\n",
            "\n",
            "Epoch 00097: LearningRateScheduler setting learning rate to tf.Tensor(0.00062577974, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1455 - val_loss: 0.1767\n",
            "\n",
            "Epoch 00097: val_loss improved from 0.17966 to 0.17666, saving model to folds1.hdf5\n",
            "Epoch 98/300\n",
            "\n",
            "Epoch 00098: LearningRateScheduler setting learning rate to tf.Tensor(0.0006227316, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1430 - val_loss: 0.1794\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.17666\n",
            "Epoch 99/300\n",
            "\n",
            "Epoch 00099: LearningRateScheduler setting learning rate to tf.Tensor(0.00061969826, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1440 - val_loss: 0.1950\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.17666\n",
            "Epoch 100/300\n",
            "\n",
            "Epoch 00100: LearningRateScheduler setting learning rate to tf.Tensor(0.0006166797, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1510 - val_loss: 0.1910\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.17666\n",
            "Epoch 101/300\n",
            "\n",
            "Epoch 00101: LearningRateScheduler setting learning rate to tf.Tensor(0.00061367586, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1463 - val_loss: 0.1885\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.17666\n",
            "Epoch 102/300\n",
            "\n",
            "Epoch 00102: LearningRateScheduler setting learning rate to tf.Tensor(0.00061068666, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 649ms/step - loss: 0.1400 - val_loss: 0.1769\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.17666\n",
            "Epoch 103/300\n",
            "\n",
            "Epoch 00103: LearningRateScheduler setting learning rate to tf.Tensor(0.0006077121, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1390 - val_loss: 0.1790\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.17666\n",
            "Epoch 104/300\n",
            "\n",
            "Epoch 00104: LearningRateScheduler setting learning rate to tf.Tensor(0.00060475187, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1371 - val_loss: 0.1784\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.17666\n",
            "Epoch 105/300\n",
            "\n",
            "Epoch 00105: LearningRateScheduler setting learning rate to tf.Tensor(0.00060180615, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1369 - val_loss: 0.1827\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.17666\n",
            "Epoch 106/300\n",
            "\n",
            "Epoch 00106: LearningRateScheduler setting learning rate to tf.Tensor(0.00059887476, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1406 - val_loss: 0.1953\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.17666\n",
            "Epoch 107/300\n",
            "\n",
            "Epoch 00107: LearningRateScheduler setting learning rate to tf.Tensor(0.0005959577, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1374 - val_loss: 0.1787\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.17666\n",
            "Epoch 108/300\n",
            "\n",
            "Epoch 00108: LearningRateScheduler setting learning rate to tf.Tensor(0.00059305475, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1372 - val_loss: 0.1736\n",
            "\n",
            "Epoch 00108: val_loss improved from 0.17666 to 0.17363, saving model to folds1.hdf5\n",
            "Epoch 109/300\n",
            "\n",
            "Epoch 00109: LearningRateScheduler setting learning rate to tf.Tensor(0.000590166, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1325 - val_loss: 0.1786\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.17363\n",
            "Epoch 110/300\n",
            "\n",
            "Epoch 00110: LearningRateScheduler setting learning rate to tf.Tensor(0.00058729126, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1335 - val_loss: 0.1816\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.17363\n",
            "Epoch 111/300\n",
            "\n",
            "Epoch 00111: LearningRateScheduler setting learning rate to tf.Tensor(0.0005844306, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1398 - val_loss: 0.1918\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.17363\n",
            "Epoch 112/300\n",
            "\n",
            "Epoch 00112: LearningRateScheduler setting learning rate to tf.Tensor(0.0005815838, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1430 - val_loss: 0.1839\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.17363\n",
            "Epoch 113/300\n",
            "\n",
            "Epoch 00113: LearningRateScheduler setting learning rate to tf.Tensor(0.000578751, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1356 - val_loss: 0.1810\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.17363\n",
            "Epoch 114/300\n",
            "\n",
            "Epoch 00114: LearningRateScheduler setting learning rate to tf.Tensor(0.00057593186, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1409 - val_loss: 0.1839\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.17363\n",
            "Epoch 115/300\n",
            "\n",
            "Epoch 00115: LearningRateScheduler setting learning rate to tf.Tensor(0.00057312654, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1453 - val_loss: 0.1820\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.17363\n",
            "Epoch 116/300\n",
            "\n",
            "Epoch 00116: LearningRateScheduler setting learning rate to tf.Tensor(0.00057033484, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1385 - val_loss: 0.1828\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.17363\n",
            "Epoch 117/300\n",
            "\n",
            "Epoch 00117: LearningRateScheduler setting learning rate to tf.Tensor(0.00056755677, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1345 - val_loss: 0.1778\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.17363\n",
            "Epoch 118/300\n",
            "\n",
            "Epoch 00118: LearningRateScheduler setting learning rate to tf.Tensor(0.0005647922, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1297 - val_loss: 0.1737\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.17363\n",
            "Epoch 119/300\n",
            "\n",
            "Epoch 00119: LearningRateScheduler setting learning rate to tf.Tensor(0.0005620411, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1303 - val_loss: 0.1862\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.17363\n",
            "Epoch 120/300\n",
            "\n",
            "Epoch 00120: LearningRateScheduler setting learning rate to tf.Tensor(0.00055930344, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1318 - val_loss: 0.1830\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.17363\n",
            "Epoch 121/300\n",
            "\n",
            "Epoch 00121: LearningRateScheduler setting learning rate to tf.Tensor(0.00055657903, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1353 - val_loss: 0.1763\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.17363\n",
            "Epoch 122/300\n",
            "\n",
            "Epoch 00122: LearningRateScheduler setting learning rate to tf.Tensor(0.00055386795, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1290 - val_loss: 0.1822\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.17363\n",
            "Epoch 123/300\n",
            "\n",
            "Epoch 00123: LearningRateScheduler setting learning rate to tf.Tensor(0.0005511701, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1310 - val_loss: 0.1819\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.17363\n",
            "Epoch 124/300\n",
            "\n",
            "Epoch 00124: LearningRateScheduler setting learning rate to tf.Tensor(0.0005484854, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1269 - val_loss: 0.1746\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.17363\n",
            "Epoch 125/300\n",
            "\n",
            "Epoch 00125: LearningRateScheduler setting learning rate to tf.Tensor(0.0005458137, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1268 - val_loss: 0.1760\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.17363\n",
            "Epoch 126/300\n",
            "\n",
            "Epoch 00126: LearningRateScheduler setting learning rate to tf.Tensor(0.00054315507, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1218 - val_loss: 0.1789\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.17363\n",
            "Epoch 127/300\n",
            "\n",
            "Epoch 00127: LearningRateScheduler setting learning rate to tf.Tensor(0.0005405093, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1215 - val_loss: 0.1804\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.17363\n",
            "Epoch 128/300\n",
            "\n",
            "Epoch 00128: LearningRateScheduler setting learning rate to tf.Tensor(0.0005378765, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1218 - val_loss: 0.1723\n",
            "\n",
            "Epoch 00128: val_loss improved from 0.17363 to 0.17227, saving model to folds1.hdf5\n",
            "Epoch 129/300\n",
            "\n",
            "Epoch 00129: LearningRateScheduler setting learning rate to tf.Tensor(0.0005352565, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1178 - val_loss: 0.1749\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.17227\n",
            "Epoch 130/300\n",
            "\n",
            "Epoch 00130: LearningRateScheduler setting learning rate to tf.Tensor(0.0005326493, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1165 - val_loss: 0.1715\n",
            "\n",
            "Epoch 00130: val_loss improved from 0.17227 to 0.17147, saving model to folds1.hdf5\n",
            "Epoch 131/300\n",
            "\n",
            "Epoch 00131: LearningRateScheduler setting learning rate to tf.Tensor(0.0005300548, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1199 - val_loss: 0.1743\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.17147\n",
            "Epoch 132/300\n",
            "\n",
            "Epoch 00132: LearningRateScheduler setting learning rate to tf.Tensor(0.0005274729, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1168 - val_loss: 0.1721\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.17147\n",
            "Epoch 133/300\n",
            "\n",
            "Epoch 00133: LearningRateScheduler setting learning rate to tf.Tensor(0.00052490365, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1146 - val_loss: 0.1740\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.17147\n",
            "Epoch 134/300\n",
            "\n",
            "Epoch 00134: LearningRateScheduler setting learning rate to tf.Tensor(0.00052234676, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1148 - val_loss: 0.1708\n",
            "\n",
            "Epoch 00134: val_loss improved from 0.17147 to 0.17080, saving model to folds1.hdf5\n",
            "Epoch 135/300\n",
            "\n",
            "Epoch 00135: LearningRateScheduler setting learning rate to tf.Tensor(0.0005198025, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1136 - val_loss: 0.1700\n",
            "\n",
            "Epoch 00135: val_loss improved from 0.17080 to 0.16996, saving model to folds1.hdf5\n",
            "Epoch 136/300\n",
            "\n",
            "Epoch 00136: LearningRateScheduler setting learning rate to tf.Tensor(0.0005172705, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1123 - val_loss: 0.1766\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.16996\n",
            "Epoch 137/300\n",
            "\n",
            "Epoch 00137: LearningRateScheduler setting learning rate to tf.Tensor(0.00051475083, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1127 - val_loss: 0.1739\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.16996\n",
            "Epoch 138/300\n",
            "\n",
            "Epoch 00138: LearningRateScheduler setting learning rate to tf.Tensor(0.00051224354, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1102 - val_loss: 0.1746\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.16996\n",
            "Epoch 139/300\n",
            "\n",
            "Epoch 00139: LearningRateScheduler setting learning rate to tf.Tensor(0.0005097484, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1109 - val_loss: 0.1731\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.16996\n",
            "Epoch 140/300\n",
            "\n",
            "Epoch 00140: LearningRateScheduler setting learning rate to tf.Tensor(0.0005072654, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1105 - val_loss: 0.1774\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.16996\n",
            "Epoch 141/300\n",
            "\n",
            "Epoch 00141: LearningRateScheduler setting learning rate to tf.Tensor(0.0005047946, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1084 - val_loss: 0.1724\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.16996\n",
            "Epoch 142/300\n",
            "\n",
            "Epoch 00142: LearningRateScheduler setting learning rate to tf.Tensor(0.0005023357, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1091 - val_loss: 0.1708\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.16996\n",
            "Epoch 143/300\n",
            "\n",
            "Epoch 00143: LearningRateScheduler setting learning rate to tf.Tensor(0.00049988885, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1062 - val_loss: 0.1709\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.16996\n",
            "Epoch 144/300\n",
            "\n",
            "Epoch 00144: LearningRateScheduler setting learning rate to tf.Tensor(0.0004974539, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1078 - val_loss: 0.1761\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.16996\n",
            "Epoch 145/300\n",
            "\n",
            "Epoch 00145: LearningRateScheduler setting learning rate to tf.Tensor(0.0004950308, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1077 - val_loss: 0.1707\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.16996\n",
            "Epoch 146/300\n",
            "\n",
            "Epoch 00146: LearningRateScheduler setting learning rate to tf.Tensor(0.0004926195, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1080 - val_loss: 0.1728\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.16996\n",
            "Epoch 147/300\n",
            "\n",
            "Epoch 00147: LearningRateScheduler setting learning rate to tf.Tensor(0.00049022, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1068 - val_loss: 0.1711\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.16996\n",
            "Epoch 148/300\n",
            "\n",
            "Epoch 00148: LearningRateScheduler setting learning rate to tf.Tensor(0.00048783212, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1082 - val_loss: 0.1713\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.16996\n",
            "Epoch 149/300\n",
            "\n",
            "Epoch 00149: LearningRateScheduler setting learning rate to tf.Tensor(0.00048545588, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1052 - val_loss: 0.1760\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.16996\n",
            "Epoch 150/300\n",
            "\n",
            "Epoch 00150: LearningRateScheduler setting learning rate to tf.Tensor(0.00048309125, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1038 - val_loss: 0.1736\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.16996\n",
            "Epoch 151/300\n",
            "\n",
            "Epoch 00151: LearningRateScheduler setting learning rate to tf.Tensor(0.00048073815, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 44s 650ms/step - loss: 0.1027 - val_loss: 0.1744\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.16996\n",
            "Epoch 152/300\n",
            "\n",
            "Epoch 00152: LearningRateScheduler setting learning rate to tf.Tensor(0.00047839645, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1024 - val_loss: 0.1728\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.16996\n",
            "Epoch 153/300\n",
            "\n",
            "Epoch 00153: LearningRateScheduler setting learning rate to tf.Tensor(0.0004760662, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1024 - val_loss: 0.1711\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.16996\n",
            "Epoch 154/300\n",
            "\n",
            "Epoch 00154: LearningRateScheduler setting learning rate to tf.Tensor(0.0004737473, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1006 - val_loss: 0.1711\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.16996\n",
            "Epoch 155/300\n",
            "\n",
            "Epoch 00155: LearningRateScheduler setting learning rate to tf.Tensor(0.00047143968, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1008 - val_loss: 0.1729\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.16996\n",
            "Epoch 156/300\n",
            "\n",
            "Epoch 00156: LearningRateScheduler setting learning rate to tf.Tensor(0.0004691433, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0998 - val_loss: 0.1704\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.16996\n",
            "Epoch 157/300\n",
            "\n",
            "Epoch 00157: LearningRateScheduler setting learning rate to tf.Tensor(0.00046685815, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0977 - val_loss: 0.1714\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.16996\n",
            "Epoch 158/300\n",
            "\n",
            "Epoch 00158: LearningRateScheduler setting learning rate to tf.Tensor(0.00046458407, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0991 - val_loss: 0.1724\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.16996\n",
            "Epoch 159/300\n",
            "\n",
            "Epoch 00159: LearningRateScheduler setting learning rate to tf.Tensor(0.00046232107, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0979 - val_loss: 0.1741\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.16996\n",
            "Epoch 160/300\n",
            "\n",
            "Epoch 00160: LearningRateScheduler setting learning rate to tf.Tensor(0.00046006907, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0960 - val_loss: 0.1692\n",
            "\n",
            "Epoch 00160: val_loss improved from 0.16996 to 0.16922, saving model to folds1.hdf5\n",
            "Epoch 161/300\n",
            "\n",
            "Epoch 00161: LearningRateScheduler setting learning rate to tf.Tensor(0.00045782814, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0957 - val_loss: 0.1713\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.16922\n",
            "Epoch 162/300\n",
            "\n",
            "Epoch 00162: LearningRateScheduler setting learning rate to tf.Tensor(0.00045559806, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0951 - val_loss: 0.1755\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.16922\n",
            "Epoch 163/300\n",
            "\n",
            "Epoch 00163: LearningRateScheduler setting learning rate to tf.Tensor(0.00045337883, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0980 - val_loss: 0.1726\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.16922\n",
            "Epoch 164/300\n",
            "\n",
            "Epoch 00164: LearningRateScheduler setting learning rate to tf.Tensor(0.00045117046, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0963 - val_loss: 0.1729\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.16922\n",
            "Epoch 165/300\n",
            "\n",
            "Epoch 00165: LearningRateScheduler setting learning rate to tf.Tensor(0.00044897277, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0968 - val_loss: 0.1737\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.16922\n",
            "Epoch 166/300\n",
            "\n",
            "Epoch 00166: LearningRateScheduler setting learning rate to tf.Tensor(0.00044678585, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0943 - val_loss: 0.1727\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.16922\n",
            "Epoch 167/300\n",
            "\n",
            "Epoch 00167: LearningRateScheduler setting learning rate to tf.Tensor(0.0004446096, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0928 - val_loss: 0.1711\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.16922\n",
            "Epoch 168/300\n",
            "\n",
            "Epoch 00168: LearningRateScheduler setting learning rate to tf.Tensor(0.0004424439, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0916 - val_loss: 0.1711\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.16922\n",
            "Epoch 169/300\n",
            "\n",
            "Epoch 00169: LearningRateScheduler setting learning rate to tf.Tensor(0.00044028874, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0920 - val_loss: 0.1725\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.16922\n",
            "Epoch 170/300\n",
            "\n",
            "Epoch 00170: LearningRateScheduler setting learning rate to tf.Tensor(0.00043814414, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0912 - val_loss: 0.1714\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.16922\n",
            "Epoch 171/300\n",
            "\n",
            "Epoch 00171: LearningRateScheduler setting learning rate to tf.Tensor(0.00043600993, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0915 - val_loss: 0.1720\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.16922\n",
            "Epoch 172/300\n",
            "\n",
            "Epoch 00172: LearningRateScheduler setting learning rate to tf.Tensor(0.00043388613, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0889 - val_loss: 0.1739\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.16922\n",
            "Epoch 173/300\n",
            "\n",
            "Epoch 00173: LearningRateScheduler setting learning rate to tf.Tensor(0.0004317727, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0896 - val_loss: 0.1712\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.16922\n",
            "Epoch 174/300\n",
            "\n",
            "Epoch 00174: LearningRateScheduler setting learning rate to tf.Tensor(0.0004296695, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0902 - val_loss: 0.1732\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.16922\n",
            "Epoch 175/300\n",
            "\n",
            "Epoch 00175: LearningRateScheduler setting learning rate to tf.Tensor(0.0004275766, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0896 - val_loss: 0.1742\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.16922\n",
            "Epoch 176/300\n",
            "\n",
            "Epoch 00176: LearningRateScheduler setting learning rate to tf.Tensor(0.00042549393, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0869 - val_loss: 0.1757\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.16922\n",
            "Epoch 177/300\n",
            "\n",
            "Epoch 00177: LearningRateScheduler setting learning rate to tf.Tensor(0.00042342133, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0870 - val_loss: 0.1737\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.16922\n",
            "Epoch 178/300\n",
            "\n",
            "Epoch 00178: LearningRateScheduler setting learning rate to tf.Tensor(0.00042135885, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0873 - val_loss: 0.1716\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.16922\n",
            "Epoch 179/300\n",
            "\n",
            "Epoch 00179: LearningRateScheduler setting learning rate to tf.Tensor(0.00041930642, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0877 - val_loss: 0.1720\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.16922\n",
            "Epoch 180/300\n",
            "\n",
            "Epoch 00180: LearningRateScheduler setting learning rate to tf.Tensor(0.00041726397, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0876 - val_loss: 0.1707\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.16922\n",
            "Epoch 181/300\n",
            "\n",
            "Epoch 00181: LearningRateScheduler setting learning rate to tf.Tensor(0.00041523148, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0844 - val_loss: 0.1701\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.16922\n",
            "Epoch 182/300\n",
            "\n",
            "Epoch 00182: LearningRateScheduler setting learning rate to tf.Tensor(0.00041320888, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0846 - val_loss: 0.1704\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.16922\n",
            "Epoch 183/300\n",
            "\n",
            "Epoch 00183: LearningRateScheduler setting learning rate to tf.Tensor(0.00041119618, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0838 - val_loss: 0.1712\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.16922\n",
            "Epoch 184/300\n",
            "\n",
            "Epoch 00184: LearningRateScheduler setting learning rate to tf.Tensor(0.00040919325, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0834 - val_loss: 0.1711\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.16922\n",
            "Epoch 185/300\n",
            "\n",
            "Epoch 00185: LearningRateScheduler setting learning rate to tf.Tensor(0.00040720004, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0825 - val_loss: 0.1702\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.16922\n",
            "Epoch 186/300\n",
            "\n",
            "Epoch 00186: LearningRateScheduler setting learning rate to tf.Tensor(0.0004052166, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0827 - val_loss: 0.1722\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.16922\n",
            "Epoch 187/300\n",
            "\n",
            "Epoch 00187: LearningRateScheduler setting learning rate to tf.Tensor(0.0004032428, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0843 - val_loss: 0.1744\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.16922\n",
            "Epoch 188/300\n",
            "\n",
            "Epoch 00188: LearningRateScheduler setting learning rate to tf.Tensor(0.0004012786, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0835 - val_loss: 0.1717\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.16922\n",
            "Epoch 189/300\n",
            "\n",
            "Epoch 00189: LearningRateScheduler setting learning rate to tf.Tensor(0.00039932402, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0809 - val_loss: 0.1723\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.16922\n",
            "Epoch 190/300\n",
            "\n",
            "Epoch 00190: LearningRateScheduler setting learning rate to tf.Tensor(0.00039737887, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0816 - val_loss: 0.1717\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.16922\n",
            "Epoch 191/300\n",
            "\n",
            "Epoch 00191: LearningRateScheduler setting learning rate to tf.Tensor(0.00039544326, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0797 - val_loss: 0.1715\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.16922\n",
            "Epoch 192/300\n",
            "\n",
            "Epoch 00192: LearningRateScheduler setting learning rate to tf.Tensor(0.00039351705, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0799 - val_loss: 0.1750\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.16922\n",
            "Epoch 193/300\n",
            "\n",
            "Epoch 00193: LearningRateScheduler setting learning rate to tf.Tensor(0.00039160028, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0790 - val_loss: 0.1715\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.16922\n",
            "Epoch 194/300\n",
            "\n",
            "Epoch 00194: LearningRateScheduler setting learning rate to tf.Tensor(0.00038969278, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0784 - val_loss: 0.1712\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.16922\n",
            "Epoch 195/300\n",
            "\n",
            "Epoch 00195: LearningRateScheduler setting learning rate to tf.Tensor(0.0003877946, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0790 - val_loss: 0.1711\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.16922\n",
            "Epoch 196/300\n",
            "\n",
            "Epoch 00196: LearningRateScheduler setting learning rate to tf.Tensor(0.00038590565, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0786 - val_loss: 0.1739\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.16922\n",
            "Epoch 197/300\n",
            "\n",
            "Epoch 00197: LearningRateScheduler setting learning rate to tf.Tensor(0.0003840259, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0766 - val_loss: 0.1754\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.16922\n",
            "Epoch 198/300\n",
            "\n",
            "Epoch 00198: LearningRateScheduler setting learning rate to tf.Tensor(0.00038215535, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0767 - val_loss: 0.1716\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.16922\n",
            "Epoch 199/300\n",
            "\n",
            "Epoch 00199: LearningRateScheduler setting learning rate to tf.Tensor(0.00038029387, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 44s 649ms/step - loss: 0.0762 - val_loss: 0.1718\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.16922\n",
            "Epoch 200/300\n",
            "\n",
            "Epoch 00200: LearningRateScheduler setting learning rate to tf.Tensor(0.00037844144, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0772 - val_loss: 0.1729\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.16922\n",
            "Epoch 201/300\n",
            "\n",
            "Epoch 00201: LearningRateScheduler setting learning rate to tf.Tensor(0.00037659804, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0763 - val_loss: 0.1712\n",
            "\n",
            "Epoch 00201: val_loss did not improve from 0.16922\n",
            "Epoch 202/300\n",
            "\n",
            "Epoch 00202: LearningRateScheduler setting learning rate to tf.Tensor(0.00037476368, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0744 - val_loss: 0.1723\n",
            "\n",
            "Epoch 00202: val_loss did not improve from 0.16922\n",
            "Epoch 203/300\n",
            "\n",
            "Epoch 00203: LearningRateScheduler setting learning rate to tf.Tensor(0.00037293817, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0746 - val_loss: 0.1717\n",
            "\n",
            "Epoch 00203: val_loss did not improve from 0.16922\n",
            "Epoch 204/300\n",
            "\n",
            "Epoch 00204: LearningRateScheduler setting learning rate to tf.Tensor(0.0003711216, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0742 - val_loss: 0.1720\n",
            "\n",
            "Epoch 00204: val_loss did not improve from 0.16922\n",
            "Epoch 205/300\n",
            "\n",
            "Epoch 00205: LearningRateScheduler setting learning rate to tf.Tensor(0.0003693139, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0746 - val_loss: 0.1717\n",
            "\n",
            "Epoch 00205: val_loss did not improve from 0.16922\n",
            "Epoch 206/300\n",
            "\n",
            "Epoch 00206: LearningRateScheduler setting learning rate to tf.Tensor(0.000367515, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0747 - val_loss: 0.1738\n",
            "\n",
            "Epoch 00206: val_loss did not improve from 0.16922\n",
            "Epoch 207/300\n",
            "\n",
            "Epoch 00207: LearningRateScheduler setting learning rate to tf.Tensor(0.00036572482, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0740 - val_loss: 0.1716\n",
            "\n",
            "Epoch 00207: val_loss did not improve from 0.16922\n",
            "Epoch 208/300\n",
            "\n",
            "Epoch 00208: LearningRateScheduler setting learning rate to tf.Tensor(0.0003639434, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0727 - val_loss: 0.1723\n",
            "\n",
            "Epoch 00208: val_loss did not improve from 0.16922\n",
            "Epoch 209/300\n",
            "\n",
            "Epoch 00209: LearningRateScheduler setting learning rate to tf.Tensor(0.00036217063, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0723 - val_loss: 0.1715\n",
            "\n",
            "Epoch 00209: val_loss did not improve from 0.16922\n",
            "Epoch 210/300\n",
            "\n",
            "Epoch 00210: LearningRateScheduler setting learning rate to tf.Tensor(0.00036040647, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0717 - val_loss: 0.1714\n",
            "\n",
            "Epoch 00210: val_loss did not improve from 0.16922\n",
            "Epoch 211/300\n",
            "\n",
            "Epoch 00211: LearningRateScheduler setting learning rate to tf.Tensor(0.00035865093, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0719 - val_loss: 0.1735\n",
            "\n",
            "Epoch 00211: val_loss did not improve from 0.16922\n",
            "Epoch 212/300\n",
            "\n",
            "Epoch 00212: LearningRateScheduler setting learning rate to tf.Tensor(0.000356904, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0716 - val_loss: 0.1721\n",
            "\n",
            "Epoch 00212: val_loss did not improve from 0.16922\n",
            "Epoch 213/300\n",
            "\n",
            "Epoch 00213: LearningRateScheduler setting learning rate to tf.Tensor(0.0003551655, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0700 - val_loss: 0.1725\n",
            "\n",
            "Epoch 00213: val_loss did not improve from 0.16922\n",
            "Epoch 214/300\n",
            "\n",
            "Epoch 00214: LearningRateScheduler setting learning rate to tf.Tensor(0.0003534355, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0702 - val_loss: 0.1710\n",
            "\n",
            "Epoch 00214: val_loss did not improve from 0.16922\n",
            "Epoch 215/300\n",
            "\n",
            "Epoch 00215: LearningRateScheduler setting learning rate to tf.Tensor(0.0003517139, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0695 - val_loss: 0.1715\n",
            "\n",
            "Epoch 00215: val_loss did not improve from 0.16922\n",
            "Epoch 216/300\n",
            "\n",
            "Epoch 00216: LearningRateScheduler setting learning rate to tf.Tensor(0.0003500007, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0701 - val_loss: 0.1724\n",
            "\n",
            "Epoch 00216: val_loss did not improve from 0.16922\n",
            "Epoch 217/300\n",
            "\n",
            "Epoch 00217: LearningRateScheduler setting learning rate to tf.Tensor(0.00034829587, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0688 - val_loss: 0.1712\n",
            "\n",
            "Epoch 00217: val_loss did not improve from 0.16922\n",
            "Epoch 218/300\n",
            "\n",
            "Epoch 00218: LearningRateScheduler setting learning rate to tf.Tensor(0.00034659932, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0690 - val_loss: 0.1716\n",
            "\n",
            "Epoch 00218: val_loss did not improve from 0.16922\n",
            "Epoch 219/300\n",
            "\n",
            "Epoch 00219: LearningRateScheduler setting learning rate to tf.Tensor(0.00034491107, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0691 - val_loss: 0.1736\n",
            "\n",
            "Epoch 00219: val_loss did not improve from 0.16922\n",
            "Epoch 220/300\n",
            "\n",
            "Epoch 00220: LearningRateScheduler setting learning rate to tf.Tensor(0.00034323102, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0687 - val_loss: 0.1724\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00220: val_loss did not improve from 0.16922\n",
            "Epoch 00220: early stopping\n",
            "--------------- > Fold 3 < ---------------\n",
            "Epoch 1/300\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 103s 1s/step - loss: 2.4338 - val_loss: 1.0936\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.09363, saving model to folds2.hdf5\n",
            "Epoch 2/300\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.8847 - val_loss: 0.7732\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.09363 to 0.77325, saving model to folds2.hdf5\n",
            "Epoch 3/300\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.6867 - val_loss: 0.6439\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.77325 to 0.64393, saving model to folds2.hdf5\n",
            "Epoch 4/300\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.5965 - val_loss: 0.5443\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.64393 to 0.54429, saving model to folds2.hdf5\n",
            "Epoch 5/300\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.5199 - val_loss: 0.4754\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.54429 to 0.47540, saving model to folds2.hdf5\n",
            "Epoch 6/300\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.4786 - val_loss: 0.4784\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.47540\n",
            "Epoch 7/300\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.4305 - val_loss: 0.4916\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.47540\n",
            "Epoch 8/300\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.4258 - val_loss: 0.4411\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.47540 to 0.44105, saving model to folds2.hdf5\n",
            "Epoch 9/300\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.4058 - val_loss: 0.4134\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.44105 to 0.41340, saving model to folds2.hdf5\n",
            "Epoch 10/300\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.3804 - val_loss: 0.4587\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.41340\n",
            "Epoch 11/300\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.3750 - val_loss: 0.3750\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.41340 to 0.37503, saving model to folds2.hdf5\n",
            "Epoch 12/300\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 643ms/step - loss: 0.3523 - val_loss: 0.3863\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.37503\n",
            "Epoch 13/300\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 643ms/step - loss: 0.3385 - val_loss: 0.3606\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.37503 to 0.36061, saving model to folds2.hdf5\n",
            "Epoch 14/300\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.3406 - val_loss: 0.3440\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.36061 to 0.34405, saving model to folds2.hdf5\n",
            "Epoch 15/300\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.3208 - val_loss: 0.3311\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.34405 to 0.33106, saving model to folds2.hdf5\n",
            "Epoch 16/300\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.3158 - val_loss: 0.3126\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.33106 to 0.31260, saving model to folds2.hdf5\n",
            "Epoch 17/300\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.3090 - val_loss: 0.3169\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.31260\n",
            "Epoch 18/300\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.3027 - val_loss: 0.2906\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.31260 to 0.29061, saving model to folds2.hdf5\n",
            "Epoch 19/300\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2925 - val_loss: 0.2921\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.29061\n",
            "Epoch 20/300\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2791 - val_loss: 0.2884\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.29061 to 0.28840, saving model to folds2.hdf5\n",
            "Epoch 21/300\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2700 - val_loss: 0.3127\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.28840\n",
            "Epoch 22/300\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2762 - val_loss: 0.2714\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.28840 to 0.27138, saving model to folds2.hdf5\n",
            "Epoch 23/300\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2697 - val_loss: 0.2577\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.27138 to 0.25766, saving model to folds2.hdf5\n",
            "Epoch 24/300\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2540 - val_loss: 0.2654\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.25766\n",
            "Epoch 25/300\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.2657 - val_loss: 0.2813\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.25766\n",
            "Epoch 26/300\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2618 - val_loss: 0.2655\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.25766\n",
            "Epoch 27/300\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2544 - val_loss: 0.2657\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.25766\n",
            "Epoch 28/300\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.2432 - val_loss: 0.2522\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.25766 to 0.25220, saving model to folds2.hdf5\n",
            "Epoch 29/300\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.2412 - val_loss: 0.2438\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.25220 to 0.24385, saving model to folds2.hdf5\n",
            "Epoch 30/300\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.2390 - val_loss: 0.2891\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.24385\n",
            "Epoch 31/300\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 643ms/step - loss: 0.2341 - val_loss: 0.2505\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.24385\n",
            "Epoch 32/300\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2363 - val_loss: 0.2539\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.24385\n",
            "Epoch 33/300\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2315 - val_loss: 0.2515\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.24385\n",
            "Epoch 34/300\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2254 - val_loss: 0.2276\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.24385 to 0.22757, saving model to folds2.hdf5\n",
            "Epoch 35/300\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2201 - val_loss: 0.2543\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.22757\n",
            "Epoch 36/300\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2261 - val_loss: 0.2592\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.22757\n",
            "Epoch 37/300\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2233 - val_loss: 0.2408\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.22757\n",
            "Epoch 38/300\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2231 - val_loss: 0.2460\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.22757\n",
            "Epoch 39/300\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2170 - val_loss: 0.2295\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.22757\n",
            "Epoch 40/300\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2085 - val_loss: 0.2380\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.22757\n",
            "Epoch 41/300\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2123 - val_loss: 0.2283\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.22757\n",
            "Epoch 42/300\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2080 - val_loss: 0.2294\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.22757\n",
            "Epoch 43/300\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2115 - val_loss: 0.2255\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.22757 to 0.22549, saving model to folds2.hdf5\n",
            "Epoch 44/300\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2188 - val_loss: 0.2481\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.22549\n",
            "Epoch 45/300\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2163 - val_loss: 0.2271\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.22549\n",
            "Epoch 46/300\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2080 - val_loss: 0.2165\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.22549 to 0.21648, saving model to folds2.hdf5\n",
            "Epoch 47/300\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1999 - val_loss: 0.2189\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.21648\n",
            "Epoch 48/300\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 44s 649ms/step - loss: 0.2096 - val_loss: 0.2185\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.21648\n",
            "Epoch 49/300\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1920 - val_loss: 0.2172\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.21648\n",
            "Epoch 50/300\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1913 - val_loss: 0.2077\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.21648 to 0.20774, saving model to folds2.hdf5\n",
            "Epoch 51/300\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1927 - val_loss: 0.2139\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.20774\n",
            "Epoch 52/300\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1906 - val_loss: 0.2223\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.20774\n",
            "Epoch 53/300\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2032 - val_loss: 0.2170\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.20774\n",
            "Epoch 54/300\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1940 - val_loss: 0.2167\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.20774\n",
            "Epoch 55/300\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1887 - val_loss: 0.2016\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.20774 to 0.20162, saving model to folds2.hdf5\n",
            "Epoch 56/300\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1862 - val_loss: 0.2050\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.20162\n",
            "Epoch 57/300\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1873 - val_loss: 0.2130\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.20162\n",
            "Epoch 58/300\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1875 - val_loss: 0.2276\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.20162\n",
            "Epoch 59/300\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1888 - val_loss: 0.2112\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.20162\n",
            "Epoch 60/300\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1802 - val_loss: 0.2076\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.20162\n",
            "Epoch 61/300\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1804 - val_loss: 0.2034\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.20162\n",
            "Epoch 62/300\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1770 - val_loss: 0.2156\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.20162\n",
            "Epoch 63/300\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to tf.Tensor(0.0007387921, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1808 - val_loss: 0.2061\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.20162\n",
            "Epoch 64/300\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to tf.Tensor(0.00073519343, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1756 - val_loss: 0.2103\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.20162\n",
            "Epoch 65/300\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to tf.Tensor(0.0007316123, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1778 - val_loss: 0.2013\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.20162 to 0.20132, saving model to folds2.hdf5\n",
            "Epoch 66/300\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to tf.Tensor(0.0007280487, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1758 - val_loss: 0.1989\n",
            "\n",
            "Epoch 00066: val_loss improved from 0.20132 to 0.19891, saving model to folds2.hdf5\n",
            "Epoch 67/300\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to tf.Tensor(0.0007245024, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1734 - val_loss: 0.1995\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.19891\n",
            "Epoch 68/300\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to tf.Tensor(0.0007209733, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1725 - val_loss: 0.2004\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.19891\n",
            "Epoch 69/300\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to tf.Tensor(0.00071746146, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1672 - val_loss: 0.1992\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.19891\n",
            "Epoch 70/300\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to tf.Tensor(0.0007139667, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1808 - val_loss: 0.2036\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.19891\n",
            "Epoch 71/300\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to tf.Tensor(0.00071048894, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1720 - val_loss: 0.2074\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.19891\n",
            "Epoch 72/300\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to tf.Tensor(0.0007070282, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1678 - val_loss: 0.2105\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.19891\n",
            "Epoch 73/300\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to tf.Tensor(0.0007035842, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1671 - val_loss: 0.2018\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.19891\n",
            "Epoch 74/300\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to tf.Tensor(0.00070015714, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1671 - val_loss: 0.1927\n",
            "\n",
            "Epoch 00074: val_loss improved from 0.19891 to 0.19265, saving model to folds2.hdf5\n",
            "Epoch 75/300\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to tf.Tensor(0.0006967467, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1640 - val_loss: 0.1925\n",
            "\n",
            "Epoch 00075: val_loss improved from 0.19265 to 0.19251, saving model to folds2.hdf5\n",
            "Epoch 76/300\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to tf.Tensor(0.00069335283, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1650 - val_loss: 0.1973\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.19251\n",
            "Epoch 77/300\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to tf.Tensor(0.0006899755, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1702 - val_loss: 0.1986\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.19251\n",
            "Epoch 78/300\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to tf.Tensor(0.00068661466, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1638 - val_loss: 0.2194\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.19251\n",
            "Epoch 79/300\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to tf.Tensor(0.00068327016, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1605 - val_loss: 0.1939\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.19251\n",
            "Epoch 80/300\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to tf.Tensor(0.00067994196, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1641 - val_loss: 0.1903\n",
            "\n",
            "Epoch 00080: val_loss improved from 0.19251 to 0.19030, saving model to folds2.hdf5\n",
            "Epoch 81/300\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to tf.Tensor(0.00067663, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1561 - val_loss: 0.2002\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.19030\n",
            "Epoch 82/300\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to tf.Tensor(0.0006733342, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1538 - val_loss: 0.1871\n",
            "\n",
            "Epoch 00082: val_loss improved from 0.19030 to 0.18715, saving model to folds2.hdf5\n",
            "Epoch 83/300\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to tf.Tensor(0.00067005435, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1564 - val_loss: 0.1862\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.18715 to 0.18624, saving model to folds2.hdf5\n",
            "Epoch 84/300\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to tf.Tensor(0.0006667905, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1539 - val_loss: 0.1923\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.18624\n",
            "Epoch 85/300\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to tf.Tensor(0.0006635426, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1581 - val_loss: 0.1923\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.18624\n",
            "Epoch 86/300\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to tf.Tensor(0.0006603105, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1533 - val_loss: 0.1910\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.18624\n",
            "Epoch 87/300\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to tf.Tensor(0.0006570942, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1513 - val_loss: 0.1891\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.18624\n",
            "Epoch 88/300\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to tf.Tensor(0.00065389345, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1511 - val_loss: 0.1922\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.18624\n",
            "Epoch 89/300\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to tf.Tensor(0.00065070833, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1508 - val_loss: 0.1836\n",
            "\n",
            "Epoch 00089: val_loss improved from 0.18624 to 0.18357, saving model to folds2.hdf5\n",
            "Epoch 90/300\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to tf.Tensor(0.00064753875, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1517 - val_loss: 0.1937\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.18357\n",
            "Epoch 91/300\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to tf.Tensor(0.0006443846, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1539 - val_loss: 0.2015\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.18357\n",
            "Epoch 92/300\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to tf.Tensor(0.0006412458, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1478 - val_loss: 0.1895\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.18357\n",
            "Epoch 93/300\n",
            "\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to tf.Tensor(0.00063812226, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1490 - val_loss: 0.1974\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.18357\n",
            "Epoch 94/300\n",
            "\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to tf.Tensor(0.00063501403, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1463 - val_loss: 0.1835\n",
            "\n",
            "Epoch 00094: val_loss improved from 0.18357 to 0.18351, saving model to folds2.hdf5\n",
            "Epoch 95/300\n",
            "\n",
            "Epoch 00095: LearningRateScheduler setting learning rate to tf.Tensor(0.0006319209, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1432 - val_loss: 0.2062\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.18351\n",
            "Epoch 96/300\n",
            "\n",
            "Epoch 00096: LearningRateScheduler setting learning rate to tf.Tensor(0.0006288428, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1516 - val_loss: 0.1870\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.18351\n",
            "Epoch 97/300\n",
            "\n",
            "Epoch 00097: LearningRateScheduler setting learning rate to tf.Tensor(0.00062577974, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 44s 650ms/step - loss: 0.1447 - val_loss: 0.1839\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.18351\n",
            "Epoch 98/300\n",
            "\n",
            "Epoch 00098: LearningRateScheduler setting learning rate to tf.Tensor(0.0006227316, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1403 - val_loss: 0.1825\n",
            "\n",
            "Epoch 00098: val_loss improved from 0.18351 to 0.18245, saving model to folds2.hdf5\n",
            "Epoch 99/300\n",
            "\n",
            "Epoch 00099: LearningRateScheduler setting learning rate to tf.Tensor(0.00061969826, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1464 - val_loss: 0.1898\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.18245\n",
            "Epoch 100/300\n",
            "\n",
            "Epoch 00100: LearningRateScheduler setting learning rate to tf.Tensor(0.0006166797, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1400 - val_loss: 0.1853\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.18245\n",
            "Epoch 101/300\n",
            "\n",
            "Epoch 00101: LearningRateScheduler setting learning rate to tf.Tensor(0.00061367586, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1442 - val_loss: 0.1840\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.18245\n",
            "Epoch 102/300\n",
            "\n",
            "Epoch 00102: LearningRateScheduler setting learning rate to tf.Tensor(0.00061068666, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1435 - val_loss: 0.1873\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.18245\n",
            "Epoch 103/300\n",
            "\n",
            "Epoch 00103: LearningRateScheduler setting learning rate to tf.Tensor(0.0006077121, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1373 - val_loss: 0.1838\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.18245\n",
            "Epoch 104/300\n",
            "\n",
            "Epoch 00104: LearningRateScheduler setting learning rate to tf.Tensor(0.00060475187, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1414 - val_loss: 0.1871\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.18245\n",
            "Epoch 105/300\n",
            "\n",
            "Epoch 00105: LearningRateScheduler setting learning rate to tf.Tensor(0.00060180615, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1395 - val_loss: 0.1879\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.18245\n",
            "Epoch 106/300\n",
            "\n",
            "Epoch 00106: LearningRateScheduler setting learning rate to tf.Tensor(0.00059887476, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1414 - val_loss: 0.1977\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.18245\n",
            "Epoch 107/300\n",
            "\n",
            "Epoch 00107: LearningRateScheduler setting learning rate to tf.Tensor(0.0005959577, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1420 - val_loss: 0.1855\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.18245\n",
            "Epoch 108/300\n",
            "\n",
            "Epoch 00108: LearningRateScheduler setting learning rate to tf.Tensor(0.00059305475, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1356 - val_loss: 0.1822\n",
            "\n",
            "Epoch 00108: val_loss improved from 0.18245 to 0.18218, saving model to folds2.hdf5\n",
            "Epoch 109/300\n",
            "\n",
            "Epoch 00109: LearningRateScheduler setting learning rate to tf.Tensor(0.000590166, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1336 - val_loss: 0.1989\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.18218\n",
            "Epoch 110/300\n",
            "\n",
            "Epoch 00110: LearningRateScheduler setting learning rate to tf.Tensor(0.00058729126, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1366 - val_loss: 0.1825\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.18218\n",
            "Epoch 111/300\n",
            "\n",
            "Epoch 00111: LearningRateScheduler setting learning rate to tf.Tensor(0.0005844306, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1386 - val_loss: 0.1842\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.18218\n",
            "Epoch 112/300\n",
            "\n",
            "Epoch 00112: LearningRateScheduler setting learning rate to tf.Tensor(0.0005815838, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1392 - val_loss: 0.1869\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.18218\n",
            "Epoch 113/300\n",
            "\n",
            "Epoch 00113: LearningRateScheduler setting learning rate to tf.Tensor(0.000578751, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1331 - val_loss: 0.2168\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.18218\n",
            "Epoch 114/300\n",
            "\n",
            "Epoch 00114: LearningRateScheduler setting learning rate to tf.Tensor(0.00057593186, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1438 - val_loss: 0.1830\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.18218\n",
            "Epoch 115/300\n",
            "\n",
            "Epoch 00115: LearningRateScheduler setting learning rate to tf.Tensor(0.00057312654, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1332 - val_loss: 0.1900\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.18218\n",
            "Epoch 116/300\n",
            "\n",
            "Epoch 00116: LearningRateScheduler setting learning rate to tf.Tensor(0.00057033484, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1305 - val_loss: 0.1784\n",
            "\n",
            "Epoch 00116: val_loss improved from 0.18218 to 0.17841, saving model to folds2.hdf5\n",
            "Epoch 117/300\n",
            "\n",
            "Epoch 00117: LearningRateScheduler setting learning rate to tf.Tensor(0.00056755677, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1290 - val_loss: 0.1788\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.17841\n",
            "Epoch 118/300\n",
            "\n",
            "Epoch 00118: LearningRateScheduler setting learning rate to tf.Tensor(0.0005647922, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1277 - val_loss: 0.1786\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.17841\n",
            "Epoch 119/300\n",
            "\n",
            "Epoch 00119: LearningRateScheduler setting learning rate to tf.Tensor(0.0005620411, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1259 - val_loss: 0.1804\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.17841\n",
            "Epoch 120/300\n",
            "\n",
            "Epoch 00120: LearningRateScheduler setting learning rate to tf.Tensor(0.00055930344, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1235 - val_loss: 0.1783\n",
            "\n",
            "Epoch 00120: val_loss improved from 0.17841 to 0.17833, saving model to folds2.hdf5\n",
            "Epoch 121/300\n",
            "\n",
            "Epoch 00121: LearningRateScheduler setting learning rate to tf.Tensor(0.00055657903, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1236 - val_loss: 0.1809\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.17833\n",
            "Epoch 122/300\n",
            "\n",
            "Epoch 00122: LearningRateScheduler setting learning rate to tf.Tensor(0.00055386795, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1239 - val_loss: 0.1745\n",
            "\n",
            "Epoch 00122: val_loss improved from 0.17833 to 0.17454, saving model to folds2.hdf5\n",
            "Epoch 123/300\n",
            "\n",
            "Epoch 00123: LearningRateScheduler setting learning rate to tf.Tensor(0.0005511701, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1194 - val_loss: 0.1761\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.17454\n",
            "Epoch 124/300\n",
            "\n",
            "Epoch 00124: LearningRateScheduler setting learning rate to tf.Tensor(0.0005484854, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1196 - val_loss: 0.1791\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.17454\n",
            "Epoch 125/300\n",
            "\n",
            "Epoch 00125: LearningRateScheduler setting learning rate to tf.Tensor(0.0005458137, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1186 - val_loss: 0.1758\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.17454\n",
            "Epoch 126/300\n",
            "\n",
            "Epoch 00126: LearningRateScheduler setting learning rate to tf.Tensor(0.00054315507, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1227 - val_loss: 0.1945\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.17454\n",
            "Epoch 127/300\n",
            "\n",
            "Epoch 00127: LearningRateScheduler setting learning rate to tf.Tensor(0.0005405093, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1423 - val_loss: 0.1805\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.17454\n",
            "Epoch 128/300\n",
            "\n",
            "Epoch 00128: LearningRateScheduler setting learning rate to tf.Tensor(0.0005378765, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1214 - val_loss: 0.1799\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.17454\n",
            "Epoch 129/300\n",
            "\n",
            "Epoch 00129: LearningRateScheduler setting learning rate to tf.Tensor(0.0005352565, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1181 - val_loss: 0.1773\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.17454\n",
            "Epoch 130/300\n",
            "\n",
            "Epoch 00130: LearningRateScheduler setting learning rate to tf.Tensor(0.0005326493, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1186 - val_loss: 0.1755\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.17454\n",
            "Epoch 131/300\n",
            "\n",
            "Epoch 00131: LearningRateScheduler setting learning rate to tf.Tensor(0.0005300548, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1154 - val_loss: 0.1748\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.17454\n",
            "Epoch 132/300\n",
            "\n",
            "Epoch 00132: LearningRateScheduler setting learning rate to tf.Tensor(0.0005274729, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1151 - val_loss: 0.1737\n",
            "\n",
            "Epoch 00132: val_loss improved from 0.17454 to 0.17371, saving model to folds2.hdf5\n",
            "Epoch 133/300\n",
            "\n",
            "Epoch 00133: LearningRateScheduler setting learning rate to tf.Tensor(0.00052490365, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1130 - val_loss: 0.1738\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.17371\n",
            "Epoch 134/300\n",
            "\n",
            "Epoch 00134: LearningRateScheduler setting learning rate to tf.Tensor(0.00052234676, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1116 - val_loss: 0.1776\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.17371\n",
            "Epoch 135/300\n",
            "\n",
            "Epoch 00135: LearningRateScheduler setting learning rate to tf.Tensor(0.0005198025, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1136 - val_loss: 0.1803\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.17371\n",
            "Epoch 136/300\n",
            "\n",
            "Epoch 00136: LearningRateScheduler setting learning rate to tf.Tensor(0.0005172705, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1109 - val_loss: 0.1810\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.17371\n",
            "Epoch 137/300\n",
            "\n",
            "Epoch 00137: LearningRateScheduler setting learning rate to tf.Tensor(0.00051475083, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1126 - val_loss: 0.1743\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.17371\n",
            "Epoch 138/300\n",
            "\n",
            "Epoch 00138: LearningRateScheduler setting learning rate to tf.Tensor(0.00051224354, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1096 - val_loss: 0.1787\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.17371\n",
            "Epoch 139/300\n",
            "\n",
            "Epoch 00139: LearningRateScheduler setting learning rate to tf.Tensor(0.0005097484, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1088 - val_loss: 0.1744\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.17371\n",
            "Epoch 140/300\n",
            "\n",
            "Epoch 00140: LearningRateScheduler setting learning rate to tf.Tensor(0.0005072654, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1111 - val_loss: 0.1790\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.17371\n",
            "Epoch 141/300\n",
            "\n",
            "Epoch 00141: LearningRateScheduler setting learning rate to tf.Tensor(0.0005047946, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1106 - val_loss: 0.1745\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.17371\n",
            "Epoch 142/300\n",
            "\n",
            "Epoch 00142: LearningRateScheduler setting learning rate to tf.Tensor(0.0005023357, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1081 - val_loss: 0.1791\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.17371\n",
            "Epoch 143/300\n",
            "\n",
            "Epoch 00143: LearningRateScheduler setting learning rate to tf.Tensor(0.00049988885, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1071 - val_loss: 0.1736\n",
            "\n",
            "Epoch 00143: val_loss improved from 0.17371 to 0.17357, saving model to folds2.hdf5\n",
            "Epoch 144/300\n",
            "\n",
            "Epoch 00144: LearningRateScheduler setting learning rate to tf.Tensor(0.0004974539, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1046 - val_loss: 0.1743\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.17357\n",
            "Epoch 145/300\n",
            "\n",
            "Epoch 00145: LearningRateScheduler setting learning rate to tf.Tensor(0.0004950308, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1074 - val_loss: 0.1786\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.17357\n",
            "Epoch 146/300\n",
            "\n",
            "Epoch 00146: LearningRateScheduler setting learning rate to tf.Tensor(0.0004926195, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1025 - val_loss: 0.1734\n",
            "\n",
            "Epoch 00146: val_loss improved from 0.17357 to 0.17338, saving model to folds2.hdf5\n",
            "Epoch 147/300\n",
            "\n",
            "Epoch 00147: LearningRateScheduler setting learning rate to tf.Tensor(0.00049022, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 649ms/step - loss: 0.1045 - val_loss: 0.1746\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.17338\n",
            "Epoch 148/300\n",
            "\n",
            "Epoch 00148: LearningRateScheduler setting learning rate to tf.Tensor(0.00048783212, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1035 - val_loss: 0.1767\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.17338\n",
            "Epoch 149/300\n",
            "\n",
            "Epoch 00149: LearningRateScheduler setting learning rate to tf.Tensor(0.00048545588, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1023 - val_loss: 0.1752\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.17338\n",
            "Epoch 150/300\n",
            "\n",
            "Epoch 00150: LearningRateScheduler setting learning rate to tf.Tensor(0.00048309125, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1023 - val_loss: 0.1748\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.17338\n",
            "Epoch 151/300\n",
            "\n",
            "Epoch 00151: LearningRateScheduler setting learning rate to tf.Tensor(0.00048073815, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1042 - val_loss: 0.1750\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.17338\n",
            "Epoch 152/300\n",
            "\n",
            "Epoch 00152: LearningRateScheduler setting learning rate to tf.Tensor(0.00047839645, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1010 - val_loss: 0.1741\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.17338\n",
            "Epoch 153/300\n",
            "\n",
            "Epoch 00153: LearningRateScheduler setting learning rate to tf.Tensor(0.0004760662, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0988 - val_loss: 0.1737\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.17338\n",
            "Epoch 154/300\n",
            "\n",
            "Epoch 00154: LearningRateScheduler setting learning rate to tf.Tensor(0.0004737473, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0987 - val_loss: 0.1736\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.17338\n",
            "Epoch 155/300\n",
            "\n",
            "Epoch 00155: LearningRateScheduler setting learning rate to tf.Tensor(0.00047143968, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0983 - val_loss: 0.1845\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.17338\n",
            "Epoch 156/300\n",
            "\n",
            "Epoch 00156: LearningRateScheduler setting learning rate to tf.Tensor(0.0004691433, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0992 - val_loss: 0.1737\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.17338\n",
            "Epoch 157/300\n",
            "\n",
            "Epoch 00157: LearningRateScheduler setting learning rate to tf.Tensor(0.00046685815, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0985 - val_loss: 0.1750\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.17338\n",
            "Epoch 158/300\n",
            "\n",
            "Epoch 00158: LearningRateScheduler setting learning rate to tf.Tensor(0.00046458407, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0961 - val_loss: 0.1767\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.17338\n",
            "Epoch 159/300\n",
            "\n",
            "Epoch 00159: LearningRateScheduler setting learning rate to tf.Tensor(0.00046232107, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0971 - val_loss: 0.1756\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.17338\n",
            "Epoch 160/300\n",
            "\n",
            "Epoch 00160: LearningRateScheduler setting learning rate to tf.Tensor(0.00046006907, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0980 - val_loss: 0.1748\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.17338\n",
            "Epoch 161/300\n",
            "\n",
            "Epoch 00161: LearningRateScheduler setting learning rate to tf.Tensor(0.00045782814, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0948 - val_loss: 0.1776\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.17338\n",
            "Epoch 162/300\n",
            "\n",
            "Epoch 00162: LearningRateScheduler setting learning rate to tf.Tensor(0.00045559806, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0941 - val_loss: 0.1750\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.17338\n",
            "Epoch 163/300\n",
            "\n",
            "Epoch 00163: LearningRateScheduler setting learning rate to tf.Tensor(0.00045337883, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0951 - val_loss: 0.1745\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.17338\n",
            "Epoch 164/300\n",
            "\n",
            "Epoch 00164: LearningRateScheduler setting learning rate to tf.Tensor(0.00045117046, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0941 - val_loss: 0.1811\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.17338\n",
            "Epoch 165/300\n",
            "\n",
            "Epoch 00165: LearningRateScheduler setting learning rate to tf.Tensor(0.00044897277, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0941 - val_loss: 0.1736\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.17338\n",
            "Epoch 166/300\n",
            "\n",
            "Epoch 00166: LearningRateScheduler setting learning rate to tf.Tensor(0.00044678585, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0929 - val_loss: 0.1740\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.17338\n",
            "Epoch 167/300\n",
            "\n",
            "Epoch 00167: LearningRateScheduler setting learning rate to tf.Tensor(0.0004446096, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0933 - val_loss: 0.1751\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.17338\n",
            "Epoch 168/300\n",
            "\n",
            "Epoch 00168: LearningRateScheduler setting learning rate to tf.Tensor(0.0004424439, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0924 - val_loss: 0.1741\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.17338\n",
            "Epoch 169/300\n",
            "\n",
            "Epoch 00169: LearningRateScheduler setting learning rate to tf.Tensor(0.00044028874, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0907 - val_loss: 0.1732\n",
            "\n",
            "Epoch 00169: val_loss improved from 0.17338 to 0.17324, saving model to folds2.hdf5\n",
            "Epoch 170/300\n",
            "\n",
            "Epoch 00170: LearningRateScheduler setting learning rate to tf.Tensor(0.00043814414, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0904 - val_loss: 0.1754\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.17324\n",
            "Epoch 171/300\n",
            "\n",
            "Epoch 00171: LearningRateScheduler setting learning rate to tf.Tensor(0.00043600993, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0896 - val_loss: 0.1761\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.17324\n",
            "Epoch 172/300\n",
            "\n",
            "Epoch 00172: LearningRateScheduler setting learning rate to tf.Tensor(0.00043388613, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0899 - val_loss: 0.1742\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.17324\n",
            "Epoch 173/300\n",
            "\n",
            "Epoch 00173: LearningRateScheduler setting learning rate to tf.Tensor(0.0004317727, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0879 - val_loss: 0.1759\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.17324\n",
            "Epoch 174/300\n",
            "\n",
            "Epoch 00174: LearningRateScheduler setting learning rate to tf.Tensor(0.0004296695, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0903 - val_loss: 0.1742\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.17324\n",
            "Epoch 175/300\n",
            "\n",
            "Epoch 00175: LearningRateScheduler setting learning rate to tf.Tensor(0.0004275766, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0910 - val_loss: 0.1749\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.17324\n",
            "Epoch 176/300\n",
            "\n",
            "Epoch 00176: LearningRateScheduler setting learning rate to tf.Tensor(0.00042549393, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0872 - val_loss: 0.1751\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.17324\n",
            "Epoch 177/300\n",
            "\n",
            "Epoch 00177: LearningRateScheduler setting learning rate to tf.Tensor(0.00042342133, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0858 - val_loss: 0.1775\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.17324\n",
            "Epoch 178/300\n",
            "\n",
            "Epoch 00178: LearningRateScheduler setting learning rate to tf.Tensor(0.00042135885, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0859 - val_loss: 0.1741\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.17324\n",
            "Epoch 179/300\n",
            "\n",
            "Epoch 00179: LearningRateScheduler setting learning rate to tf.Tensor(0.00041930642, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0856 - val_loss: 0.1735\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.17324\n",
            "Epoch 180/300\n",
            "\n",
            "Epoch 00180: LearningRateScheduler setting learning rate to tf.Tensor(0.00041726397, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0844 - val_loss: 0.1740\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.17324\n",
            "Epoch 181/300\n",
            "\n",
            "Epoch 00181: LearningRateScheduler setting learning rate to tf.Tensor(0.00041523148, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0847 - val_loss: 0.1755\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.17324\n",
            "Epoch 182/300\n",
            "\n",
            "Epoch 00182: LearningRateScheduler setting learning rate to tf.Tensor(0.00041320888, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0842 - val_loss: 0.1746\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.17324\n",
            "Epoch 183/300\n",
            "\n",
            "Epoch 00183: LearningRateScheduler setting learning rate to tf.Tensor(0.00041119618, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0840 - val_loss: 0.1752\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.17324\n",
            "Epoch 184/300\n",
            "\n",
            "Epoch 00184: LearningRateScheduler setting learning rate to tf.Tensor(0.00040919325, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0836 - val_loss: 0.1744\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.17324\n",
            "Epoch 185/300\n",
            "\n",
            "Epoch 00185: LearningRateScheduler setting learning rate to tf.Tensor(0.00040720004, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0856 - val_loss: 0.1749\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.17324\n",
            "Epoch 186/300\n",
            "\n",
            "Epoch 00186: LearningRateScheduler setting learning rate to tf.Tensor(0.0004052166, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0829 - val_loss: 0.1750\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.17324\n",
            "Epoch 187/300\n",
            "\n",
            "Epoch 00187: LearningRateScheduler setting learning rate to tf.Tensor(0.0004032428, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0815 - val_loss: 0.1750\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.17324\n",
            "Epoch 188/300\n",
            "\n",
            "Epoch 00188: LearningRateScheduler setting learning rate to tf.Tensor(0.0004012786, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0811 - val_loss: 0.1738\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.17324\n",
            "Epoch 189/300\n",
            "\n",
            "Epoch 00189: LearningRateScheduler setting learning rate to tf.Tensor(0.00039932402, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0808 - val_loss: 0.1750\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.17324\n",
            "Epoch 190/300\n",
            "\n",
            "Epoch 00190: LearningRateScheduler setting learning rate to tf.Tensor(0.00039737887, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0801 - val_loss: 0.1756\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.17324\n",
            "Epoch 191/300\n",
            "\n",
            "Epoch 00191: LearningRateScheduler setting learning rate to tf.Tensor(0.00039544326, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0798 - val_loss: 0.1744\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.17324\n",
            "Epoch 192/300\n",
            "\n",
            "Epoch 00192: LearningRateScheduler setting learning rate to tf.Tensor(0.00039351705, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 649ms/step - loss: 0.0796 - val_loss: 0.1764\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.17324\n",
            "Epoch 193/300\n",
            "\n",
            "Epoch 00193: LearningRateScheduler setting learning rate to tf.Tensor(0.00039160028, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0797 - val_loss: 0.1754\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.17324\n",
            "Epoch 194/300\n",
            "\n",
            "Epoch 00194: LearningRateScheduler setting learning rate to tf.Tensor(0.00038969278, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0791 - val_loss: 0.1745\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.17324\n",
            "Epoch 195/300\n",
            "\n",
            "Epoch 00195: LearningRateScheduler setting learning rate to tf.Tensor(0.0003877946, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0773 - val_loss: 0.1742\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.17324\n",
            "Epoch 196/300\n",
            "\n",
            "Epoch 00196: LearningRateScheduler setting learning rate to tf.Tensor(0.00038590565, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0774 - val_loss: 0.1762\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.17324\n",
            "Epoch 197/300\n",
            "\n",
            "Epoch 00197: LearningRateScheduler setting learning rate to tf.Tensor(0.0003840259, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0772 - val_loss: 0.1737\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.17324\n",
            "Epoch 198/300\n",
            "\n",
            "Epoch 00198: LearningRateScheduler setting learning rate to tf.Tensor(0.00038215535, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0764 - val_loss: 0.1747\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.17324\n",
            "Epoch 199/300\n",
            "\n",
            "Epoch 00199: LearningRateScheduler setting learning rate to tf.Tensor(0.00038029387, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0764 - val_loss: 0.1744\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.17324\n",
            "Epoch 200/300\n",
            "\n",
            "Epoch 00200: LearningRateScheduler setting learning rate to tf.Tensor(0.00037844144, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0749 - val_loss: 0.1751\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.17324\n",
            "Epoch 201/300\n",
            "\n",
            "Epoch 00201: LearningRateScheduler setting learning rate to tf.Tensor(0.00037659804, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0760 - val_loss: 0.1761\n",
            "\n",
            "Epoch 00201: val_loss did not improve from 0.17324\n",
            "Epoch 202/300\n",
            "\n",
            "Epoch 00202: LearningRateScheduler setting learning rate to tf.Tensor(0.00037476368, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0754 - val_loss: 0.1754\n",
            "\n",
            "Epoch 00202: val_loss did not improve from 0.17324\n",
            "Epoch 203/300\n",
            "\n",
            "Epoch 00203: LearningRateScheduler setting learning rate to tf.Tensor(0.00037293817, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0763 - val_loss: 0.1746\n",
            "\n",
            "Epoch 00203: val_loss did not improve from 0.17324\n",
            "Epoch 204/300\n",
            "\n",
            "Epoch 00204: LearningRateScheduler setting learning rate to tf.Tensor(0.0003711216, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0741 - val_loss: 0.1747\n",
            "\n",
            "Epoch 00204: val_loss did not improve from 0.17324\n",
            "Epoch 205/300\n",
            "\n",
            "Epoch 00205: LearningRateScheduler setting learning rate to tf.Tensor(0.0003693139, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0726 - val_loss: 0.1756\n",
            "\n",
            "Epoch 00205: val_loss did not improve from 0.17324\n",
            "Epoch 206/300\n",
            "\n",
            "Epoch 00206: LearningRateScheduler setting learning rate to tf.Tensor(0.000367515, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0728 - val_loss: 0.1759\n",
            "\n",
            "Epoch 00206: val_loss did not improve from 0.17324\n",
            "Epoch 207/300\n",
            "\n",
            "Epoch 00207: LearningRateScheduler setting learning rate to tf.Tensor(0.00036572482, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0731 - val_loss: 0.1759\n",
            "\n",
            "Epoch 00207: val_loss did not improve from 0.17324\n",
            "Epoch 208/300\n",
            "\n",
            "Epoch 00208: LearningRateScheduler setting learning rate to tf.Tensor(0.0003639434, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0721 - val_loss: 0.1761\n",
            "\n",
            "Epoch 00208: val_loss did not improve from 0.17324\n",
            "Epoch 209/300\n",
            "\n",
            "Epoch 00209: LearningRateScheduler setting learning rate to tf.Tensor(0.00036217063, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0726 - val_loss: 0.1751\n",
            "\n",
            "Epoch 00209: val_loss did not improve from 0.17324\n",
            "Epoch 210/300\n",
            "\n",
            "Epoch 00210: LearningRateScheduler setting learning rate to tf.Tensor(0.00036040647, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0716 - val_loss: 0.1745\n",
            "\n",
            "Epoch 00210: val_loss did not improve from 0.17324\n",
            "Epoch 211/300\n",
            "\n",
            "Epoch 00211: LearningRateScheduler setting learning rate to tf.Tensor(0.00035865093, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0709 - val_loss: 0.1768\n",
            "\n",
            "Epoch 00211: val_loss did not improve from 0.17324\n",
            "Epoch 212/300\n",
            "\n",
            "Epoch 00212: LearningRateScheduler setting learning rate to tf.Tensor(0.000356904, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0717 - val_loss: 0.1754\n",
            "\n",
            "Epoch 00212: val_loss did not improve from 0.17324\n",
            "Epoch 213/300\n",
            "\n",
            "Epoch 00213: LearningRateScheduler setting learning rate to tf.Tensor(0.0003551655, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0719 - val_loss: 0.1751\n",
            "\n",
            "Epoch 00213: val_loss did not improve from 0.17324\n",
            "Epoch 214/300\n",
            "\n",
            "Epoch 00214: LearningRateScheduler setting learning rate to tf.Tensor(0.0003534355, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0699 - val_loss: 0.1750\n",
            "\n",
            "Epoch 00214: val_loss did not improve from 0.17324\n",
            "Epoch 215/300\n",
            "\n",
            "Epoch 00215: LearningRateScheduler setting learning rate to tf.Tensor(0.0003517139, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0709 - val_loss: 0.1752\n",
            "\n",
            "Epoch 00215: val_loss did not improve from 0.17324\n",
            "Epoch 216/300\n",
            "\n",
            "Epoch 00216: LearningRateScheduler setting learning rate to tf.Tensor(0.0003500007, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0701 - val_loss: 0.1789\n",
            "\n",
            "Epoch 00216: val_loss did not improve from 0.17324\n",
            "Epoch 217/300\n",
            "\n",
            "Epoch 00217: LearningRateScheduler setting learning rate to tf.Tensor(0.00034829587, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0688 - val_loss: 0.1754\n",
            "\n",
            "Epoch 00217: val_loss did not improve from 0.17324\n",
            "Epoch 218/300\n",
            "\n",
            "Epoch 00218: LearningRateScheduler setting learning rate to tf.Tensor(0.00034659932, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0679 - val_loss: 0.1746\n",
            "\n",
            "Epoch 00218: val_loss did not improve from 0.17324\n",
            "Epoch 219/300\n",
            "\n",
            "Epoch 00219: LearningRateScheduler setting learning rate to tf.Tensor(0.00034491107, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0689 - val_loss: 0.1749\n",
            "\n",
            "Epoch 00219: val_loss did not improve from 0.17324\n",
            "Epoch 220/300\n",
            "\n",
            "Epoch 00220: LearningRateScheduler setting learning rate to tf.Tensor(0.00034323102, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0676 - val_loss: 0.1764\n",
            "\n",
            "Epoch 00220: val_loss did not improve from 0.17324\n",
            "Epoch 221/300\n",
            "\n",
            "Epoch 00221: LearningRateScheduler setting learning rate to tf.Tensor(0.00034155912, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0680 - val_loss: 0.1743\n",
            "\n",
            "Epoch 00221: val_loss did not improve from 0.17324\n",
            "Epoch 222/300\n",
            "\n",
            "Epoch 00222: LearningRateScheduler setting learning rate to tf.Tensor(0.00033989537, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0670 - val_loss: 0.1766\n",
            "\n",
            "Epoch 00222: val_loss did not improve from 0.17324\n",
            "Epoch 223/300\n",
            "\n",
            "Epoch 00223: LearningRateScheduler setting learning rate to tf.Tensor(0.00033823974, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0669 - val_loss: 0.1753\n",
            "\n",
            "Epoch 00223: val_loss did not improve from 0.17324\n",
            "Epoch 224/300\n",
            "\n",
            "Epoch 00224: LearningRateScheduler setting learning rate to tf.Tensor(0.0003365922, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0663 - val_loss: 0.1754\n",
            "\n",
            "Epoch 00224: val_loss did not improve from 0.17324\n",
            "Epoch 225/300\n",
            "\n",
            "Epoch 00225: LearningRateScheduler setting learning rate to tf.Tensor(0.00033495267, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0659 - val_loss: 0.1747\n",
            "\n",
            "Epoch 00225: val_loss did not improve from 0.17324\n",
            "Epoch 226/300\n",
            "\n",
            "Epoch 00226: LearningRateScheduler setting learning rate to tf.Tensor(0.0003333211, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0666 - val_loss: 0.1763\n",
            "\n",
            "Epoch 00226: val_loss did not improve from 0.17324\n",
            "Epoch 227/300\n",
            "\n",
            "Epoch 00227: LearningRateScheduler setting learning rate to tf.Tensor(0.00033169755, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0657 - val_loss: 0.1757\n",
            "\n",
            "Epoch 00227: val_loss did not improve from 0.17324\n",
            "Epoch 228/300\n",
            "\n",
            "Epoch 00228: LearningRateScheduler setting learning rate to tf.Tensor(0.00033008185, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0645 - val_loss: 0.1757\n",
            "\n",
            "Epoch 00228: val_loss did not improve from 0.17324\n",
            "Epoch 229/300\n",
            "\n",
            "Epoch 00229: LearningRateScheduler setting learning rate to tf.Tensor(0.000328474, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0647 - val_loss: 0.1765\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00229: val_loss did not improve from 0.17324\n",
            "Epoch 00229: early stopping\n",
            "--------------- > Fold 4 < ---------------\n",
            "Epoch 1/300\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 106s 1s/step - loss: 2.5901 - val_loss: 1.0583\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.05827, saving model to folds3.hdf5\n",
            "Epoch 2/300\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.8480 - val_loss: 0.7221\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.05827 to 0.72213, saving model to folds3.hdf5\n",
            "Epoch 3/300\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.6241 - val_loss: 0.5492\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.72213 to 0.54920, saving model to folds3.hdf5\n",
            "Epoch 4/300\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.5390 - val_loss: 0.4723\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.54920 to 0.47228, saving model to folds3.hdf5\n",
            "Epoch 5/300\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.4893 - val_loss: 0.5087\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.47228\n",
            "Epoch 6/300\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 646ms/step - loss: 0.4502 - val_loss: 0.4744\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.47228\n",
            "Epoch 7/300\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.4793 - val_loss: 0.5104\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.47228\n",
            "Epoch 8/300\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.4305 - val_loss: 0.4139\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.47228 to 0.41392, saving model to folds3.hdf5\n",
            "Epoch 9/300\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.3887 - val_loss: 0.3937\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.41392 to 0.39372, saving model to folds3.hdf5\n",
            "Epoch 10/300\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.3808 - val_loss: 0.3565\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.39372 to 0.35646, saving model to folds3.hdf5\n",
            "Epoch 11/300\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.3615 - val_loss: 0.4115\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.35646\n",
            "Epoch 12/300\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.3457 - val_loss: 0.3896\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.35646\n",
            "Epoch 13/300\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.3355 - val_loss: 0.3573\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.35646\n",
            "Epoch 14/300\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.3242 - val_loss: 0.3210\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.35646 to 0.32103, saving model to folds3.hdf5\n",
            "Epoch 15/300\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.3115 - val_loss: 0.3572\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.32103\n",
            "Epoch 16/300\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.3082 - val_loss: 0.3209\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.32103 to 0.32087, saving model to folds3.hdf5\n",
            "Epoch 17/300\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.3022 - val_loss: 0.3018\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.32087 to 0.30184, saving model to folds3.hdf5\n",
            "Epoch 18/300\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2933 - val_loss: 0.2929\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.30184 to 0.29288, saving model to folds3.hdf5\n",
            "Epoch 19/300\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2819 - val_loss: 0.2830\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.29288 to 0.28296, saving model to folds3.hdf5\n",
            "Epoch 20/300\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2907 - val_loss: 0.3088\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.28296\n",
            "Epoch 21/300\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2727 - val_loss: 0.2751\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.28296 to 0.27509, saving model to folds3.hdf5\n",
            "Epoch 22/300\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2669 - val_loss: 0.2810\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.27509\n",
            "Epoch 23/300\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2728 - val_loss: 0.2775\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.27509\n",
            "Epoch 24/300\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.2543 - val_loss: 0.2749\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.27509 to 0.27487, saving model to folds3.hdf5\n",
            "Epoch 25/300\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2584 - val_loss: 0.2570\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.27487 to 0.25699, saving model to folds3.hdf5\n",
            "Epoch 26/300\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2489 - val_loss: 0.2613\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.25699\n",
            "Epoch 27/300\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2501 - val_loss: 0.2641\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.25699\n",
            "Epoch 28/300\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.2479 - val_loss: 0.2921\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.25699\n",
            "Epoch 29/300\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.2457 - val_loss: 0.2500\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.25699 to 0.24998, saving model to folds3.hdf5\n",
            "Epoch 30/300\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2353 - val_loss: 0.2544\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.24998\n",
            "Epoch 31/300\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.2393 - val_loss: 0.2599\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.24998\n",
            "Epoch 32/300\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2358 - val_loss: 0.2461\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.24998 to 0.24609, saving model to folds3.hdf5\n",
            "Epoch 33/300\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2347 - val_loss: 0.2573\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.24609\n",
            "Epoch 34/300\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2259 - val_loss: 0.2381\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.24609 to 0.23805, saving model to folds3.hdf5\n",
            "Epoch 35/300\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2283 - val_loss: 0.2391\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.23805\n",
            "Epoch 36/300\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2194 - val_loss: 0.2290\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.23805 to 0.22895, saving model to folds3.hdf5\n",
            "Epoch 37/300\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2173 - val_loss: 0.2354\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.22895\n",
            "Epoch 38/300\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2130 - val_loss: 0.2235\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.22895 to 0.22354, saving model to folds3.hdf5\n",
            "Epoch 39/300\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2086 - val_loss: 0.2460\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.22354\n",
            "Epoch 40/300\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2139 - val_loss: 0.2308\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.22354\n",
            "Epoch 41/300\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.2083 - val_loss: 0.2261\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.22354\n",
            "Epoch 42/300\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.2061 - val_loss: 0.2223\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.22354 to 0.22232, saving model to folds3.hdf5\n",
            "Epoch 43/300\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2119 - val_loss: 0.2333\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.22232\n",
            "Epoch 44/300\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.2030 - val_loss: 0.2347\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.22232\n",
            "Epoch 45/300\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2023 - val_loss: 0.2339\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.22232\n",
            "Epoch 46/300\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2133 - val_loss: 0.2373\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.22232\n",
            "Epoch 47/300\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2130 - val_loss: 0.2293\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.22232\n",
            "Epoch 48/300\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.2030 - val_loss: 0.2267\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.22232\n",
            "Epoch 49/300\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2049 - val_loss: 0.2193\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.22232 to 0.21930, saving model to folds3.hdf5\n",
            "Epoch 50/300\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1932 - val_loss: 0.2204\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.21930\n",
            "Epoch 51/300\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1919 - val_loss: 0.2129\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.21930 to 0.21286, saving model to folds3.hdf5\n",
            "Epoch 52/300\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1931 - val_loss: 0.2366\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.21286\n",
            "Epoch 53/300\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 44s 649ms/step - loss: 0.1925 - val_loss: 0.2090\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.21286 to 0.20900, saving model to folds3.hdf5\n",
            "Epoch 54/300\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1903 - val_loss: 0.2188\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.20900\n",
            "Epoch 55/300\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1926 - val_loss: 0.2087\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.20900 to 0.20872, saving model to folds3.hdf5\n",
            "Epoch 56/300\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1818 - val_loss: 0.2027\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.20872 to 0.20274, saving model to folds3.hdf5\n",
            "Epoch 57/300\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1794 - val_loss: 0.2066\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.20274\n",
            "Epoch 58/300\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1756 - val_loss: 0.2147\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.20274\n",
            "Epoch 59/300\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1746 - val_loss: 0.2041\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.20274\n",
            "Epoch 60/300\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1754 - val_loss: 0.2024\n",
            "\n",
            "Epoch 00060: val_loss improved from 0.20274 to 0.20239, saving model to folds3.hdf5\n",
            "Epoch 61/300\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1750 - val_loss: 0.2001\n",
            "\n",
            "Epoch 00061: val_loss improved from 0.20239 to 0.20013, saving model to folds3.hdf5\n",
            "Epoch 62/300\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1746 - val_loss: 0.1999\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.20013 to 0.19990, saving model to folds3.hdf5\n",
            "Epoch 63/300\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to tf.Tensor(0.0007387921, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1738 - val_loss: 0.2057\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.19990\n",
            "Epoch 64/300\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to tf.Tensor(0.00073519343, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1767 - val_loss: 0.2064\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.19990\n",
            "Epoch 65/300\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to tf.Tensor(0.0007316123, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1762 - val_loss: 0.1982\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.19990 to 0.19816, saving model to folds3.hdf5\n",
            "Epoch 66/300\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to tf.Tensor(0.0007280487, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1693 - val_loss: 0.2008\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.19816\n",
            "Epoch 67/300\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to tf.Tensor(0.0007245024, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1781 - val_loss: 0.2000\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.19816\n",
            "Epoch 68/300\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to tf.Tensor(0.0007209733, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1795 - val_loss: 0.2329\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.19816\n",
            "Epoch 69/300\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to tf.Tensor(0.00071746146, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1782 - val_loss: 0.2134\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.19816\n",
            "Epoch 70/300\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to tf.Tensor(0.0007139667, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1685 - val_loss: 0.1964\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.19816 to 0.19643, saving model to folds3.hdf5\n",
            "Epoch 71/300\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to tf.Tensor(0.00071048894, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1651 - val_loss: 0.1958\n",
            "\n",
            "Epoch 00071: val_loss improved from 0.19643 to 0.19580, saving model to folds3.hdf5\n",
            "Epoch 72/300\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to tf.Tensor(0.0007070282, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1712 - val_loss: 0.1980\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.19580\n",
            "Epoch 73/300\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to tf.Tensor(0.0007035842, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1608 - val_loss: 0.1995\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.19580\n",
            "Epoch 74/300\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to tf.Tensor(0.00070015714, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1642 - val_loss: 0.2102\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.19580\n",
            "Epoch 75/300\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to tf.Tensor(0.0006967467, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1605 - val_loss: 0.1945\n",
            "\n",
            "Epoch 00075: val_loss improved from 0.19580 to 0.19445, saving model to folds3.hdf5\n",
            "Epoch 76/300\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to tf.Tensor(0.00069335283, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1601 - val_loss: 0.1997\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.19445\n",
            "Epoch 77/300\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to tf.Tensor(0.0006899755, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1606 - val_loss: 0.1919\n",
            "\n",
            "Epoch 00077: val_loss improved from 0.19445 to 0.19188, saving model to folds3.hdf5\n",
            "Epoch 78/300\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to tf.Tensor(0.00068661466, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1574 - val_loss: 0.2103\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.19188\n",
            "Epoch 79/300\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to tf.Tensor(0.00068327016, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1590 - val_loss: 0.1899\n",
            "\n",
            "Epoch 00079: val_loss improved from 0.19188 to 0.18987, saving model to folds3.hdf5\n",
            "Epoch 80/300\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to tf.Tensor(0.00067994196, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1585 - val_loss: 0.1920\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.18987\n",
            "Epoch 81/300\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to tf.Tensor(0.00067663, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1527 - val_loss: 0.1936\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.18987\n",
            "Epoch 82/300\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to tf.Tensor(0.0006733342, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1566 - val_loss: 0.1965\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.18987\n",
            "Epoch 83/300\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to tf.Tensor(0.00067005435, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1572 - val_loss: 0.1891\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.18987 to 0.18910, saving model to folds3.hdf5\n",
            "Epoch 84/300\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to tf.Tensor(0.0006667905, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1520 - val_loss: 0.1863\n",
            "\n",
            "Epoch 00084: val_loss improved from 0.18910 to 0.18633, saving model to folds3.hdf5\n",
            "Epoch 85/300\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to tf.Tensor(0.0006635426, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1515 - val_loss: 0.1848\n",
            "\n",
            "Epoch 00085: val_loss improved from 0.18633 to 0.18480, saving model to folds3.hdf5\n",
            "Epoch 86/300\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to tf.Tensor(0.0006603105, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1521 - val_loss: 0.2092\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.18480\n",
            "Epoch 87/300\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to tf.Tensor(0.0006570942, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1557 - val_loss: 0.2232\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.18480\n",
            "Epoch 88/300\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to tf.Tensor(0.00065389345, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1650 - val_loss: 0.2095\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.18480\n",
            "Epoch 89/300\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to tf.Tensor(0.00065070833, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1595 - val_loss: 0.1975\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.18480\n",
            "Epoch 90/300\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to tf.Tensor(0.00064753875, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1483 - val_loss: 0.1951\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.18480\n",
            "Epoch 91/300\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to tf.Tensor(0.0006443846, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1567 - val_loss: 0.1930\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.18480\n",
            "Epoch 92/300\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to tf.Tensor(0.0006412458, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1464 - val_loss: 0.1898\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.18480\n",
            "Epoch 93/300\n",
            "\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to tf.Tensor(0.00063812226, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1437 - val_loss: 0.1842\n",
            "\n",
            "Epoch 00093: val_loss improved from 0.18480 to 0.18424, saving model to folds3.hdf5\n",
            "Epoch 94/300\n",
            "\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to tf.Tensor(0.00063501403, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1407 - val_loss: 0.1892\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.18424\n",
            "Epoch 95/300\n",
            "\n",
            "Epoch 00095: LearningRateScheduler setting learning rate to tf.Tensor(0.0006319209, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1368 - val_loss: 0.1837\n",
            "\n",
            "Epoch 00095: val_loss improved from 0.18424 to 0.18374, saving model to folds3.hdf5\n",
            "Epoch 96/300\n",
            "\n",
            "Epoch 00096: LearningRateScheduler setting learning rate to tf.Tensor(0.0006288428, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1371 - val_loss: 0.1918\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.18374\n",
            "Epoch 97/300\n",
            "\n",
            "Epoch 00097: LearningRateScheduler setting learning rate to tf.Tensor(0.00062577974, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1373 - val_loss: 0.1932\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.18374\n",
            "Epoch 98/300\n",
            "\n",
            "Epoch 00098: LearningRateScheduler setting learning rate to tf.Tensor(0.0006227316, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1372 - val_loss: 0.1839\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.18374\n",
            "Epoch 99/300\n",
            "\n",
            "Epoch 00099: LearningRateScheduler setting learning rate to tf.Tensor(0.00061969826, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1369 - val_loss: 0.1870\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.18374\n",
            "Epoch 100/300\n",
            "\n",
            "Epoch 00100: LearningRateScheduler setting learning rate to tf.Tensor(0.0006166797, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1338 - val_loss: 0.1807\n",
            "\n",
            "Epoch 00100: val_loss improved from 0.18374 to 0.18066, saving model to folds3.hdf5\n",
            "Epoch 101/300\n",
            "\n",
            "Epoch 00101: LearningRateScheduler setting learning rate to tf.Tensor(0.00061367586, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1336 - val_loss: 0.1927\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.18066\n",
            "Epoch 102/300\n",
            "\n",
            "Epoch 00102: LearningRateScheduler setting learning rate to tf.Tensor(0.00061068666, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 44s 650ms/step - loss: 0.1359 - val_loss: 0.1998\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.18066\n",
            "Epoch 103/300\n",
            "\n",
            "Epoch 00103: LearningRateScheduler setting learning rate to tf.Tensor(0.0006077121, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1413 - val_loss: 0.1888\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.18066\n",
            "Epoch 104/300\n",
            "\n",
            "Epoch 00104: LearningRateScheduler setting learning rate to tf.Tensor(0.00060475187, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1389 - val_loss: 0.1938\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.18066\n",
            "Epoch 105/300\n",
            "\n",
            "Epoch 00105: LearningRateScheduler setting learning rate to tf.Tensor(0.00060180615, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1328 - val_loss: 0.1869\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.18066\n",
            "Epoch 106/300\n",
            "\n",
            "Epoch 00106: LearningRateScheduler setting learning rate to tf.Tensor(0.00059887476, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1305 - val_loss: 0.1802\n",
            "\n",
            "Epoch 00106: val_loss improved from 0.18066 to 0.18025, saving model to folds3.hdf5\n",
            "Epoch 107/300\n",
            "\n",
            "Epoch 00107: LearningRateScheduler setting learning rate to tf.Tensor(0.0005959577, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 644ms/step - loss: 0.1275 - val_loss: 0.1819\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.18025\n",
            "Epoch 108/300\n",
            "\n",
            "Epoch 00108: LearningRateScheduler setting learning rate to tf.Tensor(0.00059305475, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1275 - val_loss: 0.1806\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.18025\n",
            "Epoch 109/300\n",
            "\n",
            "Epoch 00109: LearningRateScheduler setting learning rate to tf.Tensor(0.000590166, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1247 - val_loss: 0.1841\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.18025\n",
            "Epoch 110/300\n",
            "\n",
            "Epoch 00110: LearningRateScheduler setting learning rate to tf.Tensor(0.00058729126, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1249 - val_loss: 0.1819\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.18025\n",
            "Epoch 111/300\n",
            "\n",
            "Epoch 00111: LearningRateScheduler setting learning rate to tf.Tensor(0.0005844306, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1253 - val_loss: 0.1807\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.18025\n",
            "Epoch 112/300\n",
            "\n",
            "Epoch 00112: LearningRateScheduler setting learning rate to tf.Tensor(0.0005815838, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1239 - val_loss: 0.1940\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.18025\n",
            "Epoch 113/300\n",
            "\n",
            "Epoch 00113: LearningRateScheduler setting learning rate to tf.Tensor(0.000578751, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1430 - val_loss: 0.1872\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.18025\n",
            "Epoch 114/300\n",
            "\n",
            "Epoch 00114: LearningRateScheduler setting learning rate to tf.Tensor(0.00057593186, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1342 - val_loss: 0.1923\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.18025\n",
            "Epoch 115/300\n",
            "\n",
            "Epoch 00115: LearningRateScheduler setting learning rate to tf.Tensor(0.00057312654, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1315 - val_loss: 0.1846\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.18025\n",
            "Epoch 116/300\n",
            "\n",
            "Epoch 00116: LearningRateScheduler setting learning rate to tf.Tensor(0.00057033484, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1233 - val_loss: 0.1782\n",
            "\n",
            "Epoch 00116: val_loss improved from 0.18025 to 0.17822, saving model to folds3.hdf5\n",
            "Epoch 117/300\n",
            "\n",
            "Epoch 00117: LearningRateScheduler setting learning rate to tf.Tensor(0.00056755677, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1249 - val_loss: 0.1804\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.17822\n",
            "Epoch 118/300\n",
            "\n",
            "Epoch 00118: LearningRateScheduler setting learning rate to tf.Tensor(0.0005647922, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1201 - val_loss: 0.1802\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.17822\n",
            "Epoch 119/300\n",
            "\n",
            "Epoch 00119: LearningRateScheduler setting learning rate to tf.Tensor(0.0005620411, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1195 - val_loss: 0.1901\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.17822\n",
            "Epoch 120/300\n",
            "\n",
            "Epoch 00120: LearningRateScheduler setting learning rate to tf.Tensor(0.00055930344, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1185 - val_loss: 0.1802\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.17822\n",
            "Epoch 121/300\n",
            "\n",
            "Epoch 00121: LearningRateScheduler setting learning rate to tf.Tensor(0.00055657903, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1158 - val_loss: 0.1830\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.17822\n",
            "Epoch 122/300\n",
            "\n",
            "Epoch 00122: LearningRateScheduler setting learning rate to tf.Tensor(0.00055386795, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1176 - val_loss: 0.1849\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.17822\n",
            "Epoch 123/300\n",
            "\n",
            "Epoch 00123: LearningRateScheduler setting learning rate to tf.Tensor(0.0005511701, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1160 - val_loss: 0.1839\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.17822\n",
            "Epoch 124/300\n",
            "\n",
            "Epoch 00124: LearningRateScheduler setting learning rate to tf.Tensor(0.0005484854, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1154 - val_loss: 0.1790\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.17822\n",
            "Epoch 125/300\n",
            "\n",
            "Epoch 00125: LearningRateScheduler setting learning rate to tf.Tensor(0.0005458137, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1131 - val_loss: 0.1829\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.17822\n",
            "Epoch 126/300\n",
            "\n",
            "Epoch 00126: LearningRateScheduler setting learning rate to tf.Tensor(0.00054315507, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1121 - val_loss: 0.1783\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.17822\n",
            "Epoch 127/300\n",
            "\n",
            "Epoch 00127: LearningRateScheduler setting learning rate to tf.Tensor(0.0005405093, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1169 - val_loss: 0.1900\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.17822\n",
            "Epoch 128/300\n",
            "\n",
            "Epoch 00128: LearningRateScheduler setting learning rate to tf.Tensor(0.0005378765, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1131 - val_loss: 0.1802\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.17822\n",
            "Epoch 129/300\n",
            "\n",
            "Epoch 00129: LearningRateScheduler setting learning rate to tf.Tensor(0.0005352565, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1115 - val_loss: 0.1820\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.17822\n",
            "Epoch 130/300\n",
            "\n",
            "Epoch 00130: LearningRateScheduler setting learning rate to tf.Tensor(0.0005326493, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1159 - val_loss: 0.1840\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.17822\n",
            "Epoch 131/300\n",
            "\n",
            "Epoch 00131: LearningRateScheduler setting learning rate to tf.Tensor(0.0005300548, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1177 - val_loss: 0.1853\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.17822\n",
            "Epoch 132/300\n",
            "\n",
            "Epoch 00132: LearningRateScheduler setting learning rate to tf.Tensor(0.0005274729, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1126 - val_loss: 0.1883\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.17822\n",
            "Epoch 133/300\n",
            "\n",
            "Epoch 00133: LearningRateScheduler setting learning rate to tf.Tensor(0.00052490365, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1123 - val_loss: 0.1801\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.17822\n",
            "Epoch 134/300\n",
            "\n",
            "Epoch 00134: LearningRateScheduler setting learning rate to tf.Tensor(0.00052234676, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1101 - val_loss: 0.1813\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.17822\n",
            "Epoch 135/300\n",
            "\n",
            "Epoch 00135: LearningRateScheduler setting learning rate to tf.Tensor(0.0005198025, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1094 - val_loss: 0.1804\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.17822\n",
            "Epoch 136/300\n",
            "\n",
            "Epoch 00136: LearningRateScheduler setting learning rate to tf.Tensor(0.0005172705, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1083 - val_loss: 0.1812\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.17822\n",
            "Epoch 137/300\n",
            "\n",
            "Epoch 00137: LearningRateScheduler setting learning rate to tf.Tensor(0.00051475083, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1069 - val_loss: 0.1837\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.17822\n",
            "Epoch 138/300\n",
            "\n",
            "Epoch 00138: LearningRateScheduler setting learning rate to tf.Tensor(0.00051224354, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1059 - val_loss: 0.1888\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.17822\n",
            "Epoch 139/300\n",
            "\n",
            "Epoch 00139: LearningRateScheduler setting learning rate to tf.Tensor(0.0005097484, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1056 - val_loss: 0.1796\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.17822\n",
            "Epoch 140/300\n",
            "\n",
            "Epoch 00140: LearningRateScheduler setting learning rate to tf.Tensor(0.0005072654, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1039 - val_loss: 0.1843\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.17822\n",
            "Epoch 141/300\n",
            "\n",
            "Epoch 00141: LearningRateScheduler setting learning rate to tf.Tensor(0.0005047946, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1035 - val_loss: 0.1802\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.17822\n",
            "Epoch 142/300\n",
            "\n",
            "Epoch 00142: LearningRateScheduler setting learning rate to tf.Tensor(0.0005023357, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1032 - val_loss: 0.1780\n",
            "\n",
            "Epoch 00142: val_loss improved from 0.17822 to 0.17802, saving model to folds3.hdf5\n",
            "Epoch 143/300\n",
            "\n",
            "Epoch 00143: LearningRateScheduler setting learning rate to tf.Tensor(0.00049988885, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1027 - val_loss: 0.1796\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.17802\n",
            "Epoch 144/300\n",
            "\n",
            "Epoch 00144: LearningRateScheduler setting learning rate to tf.Tensor(0.0004974539, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1011 - val_loss: 0.1785\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.17802\n",
            "Epoch 145/300\n",
            "\n",
            "Epoch 00145: LearningRateScheduler setting learning rate to tf.Tensor(0.0004950308, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1002 - val_loss: 0.1805\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.17802\n",
            "Epoch 146/300\n",
            "\n",
            "Epoch 00146: LearningRateScheduler setting learning rate to tf.Tensor(0.0004926195, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1024 - val_loss: 0.1805\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.17802\n",
            "Epoch 147/300\n",
            "\n",
            "Epoch 00147: LearningRateScheduler setting learning rate to tf.Tensor(0.00049022, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0996 - val_loss: 0.1792\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.17802\n",
            "Epoch 148/300\n",
            "\n",
            "Epoch 00148: LearningRateScheduler setting learning rate to tf.Tensor(0.00048783212, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0991 - val_loss: 0.1875\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.17802\n",
            "Epoch 149/300\n",
            "\n",
            "Epoch 00149: LearningRateScheduler setting learning rate to tf.Tensor(0.00048545588, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0993 - val_loss: 0.1796\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.17802\n",
            "Epoch 150/300\n",
            "\n",
            "Epoch 00150: LearningRateScheduler setting learning rate to tf.Tensor(0.00048309125, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0984 - val_loss: 0.1807\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.17802\n",
            "Epoch 151/300\n",
            "\n",
            "Epoch 00151: LearningRateScheduler setting learning rate to tf.Tensor(0.00048073815, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0981 - val_loss: 0.1801\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.17802\n",
            "Epoch 152/300\n",
            "\n",
            "Epoch 00152: LearningRateScheduler setting learning rate to tf.Tensor(0.00047839645, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 646ms/step - loss: 0.0976 - val_loss: 0.1829\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.17802\n",
            "Epoch 153/300\n",
            "\n",
            "Epoch 00153: LearningRateScheduler setting learning rate to tf.Tensor(0.0004760662, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 44s 651ms/step - loss: 0.0958 - val_loss: 0.1786\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.17802\n",
            "Epoch 154/300\n",
            "\n",
            "Epoch 00154: LearningRateScheduler setting learning rate to tf.Tensor(0.0004737473, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0958 - val_loss: 0.1798\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.17802\n",
            "Epoch 155/300\n",
            "\n",
            "Epoch 00155: LearningRateScheduler setting learning rate to tf.Tensor(0.00047143968, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0936 - val_loss: 0.1859\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.17802\n",
            "Epoch 156/300\n",
            "\n",
            "Epoch 00156: LearningRateScheduler setting learning rate to tf.Tensor(0.0004691433, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0935 - val_loss: 0.1820\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.17802\n",
            "Epoch 157/300\n",
            "\n",
            "Epoch 00157: LearningRateScheduler setting learning rate to tf.Tensor(0.00046685815, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0932 - val_loss: 0.1802\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.17802\n",
            "Epoch 158/300\n",
            "\n",
            "Epoch 00158: LearningRateScheduler setting learning rate to tf.Tensor(0.00046458407, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0914 - val_loss: 0.1786\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.17802\n",
            "Epoch 159/300\n",
            "\n",
            "Epoch 00159: LearningRateScheduler setting learning rate to tf.Tensor(0.00046232107, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0928 - val_loss: 0.1806\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.17802\n",
            "Epoch 160/300\n",
            "\n",
            "Epoch 00160: LearningRateScheduler setting learning rate to tf.Tensor(0.00046006907, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0902 - val_loss: 0.1827\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.17802\n",
            "Epoch 161/300\n",
            "\n",
            "Epoch 00161: LearningRateScheduler setting learning rate to tf.Tensor(0.00045782814, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0901 - val_loss: 0.1804\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.17802\n",
            "Epoch 162/300\n",
            "\n",
            "Epoch 00162: LearningRateScheduler setting learning rate to tf.Tensor(0.00045559806, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0898 - val_loss: 0.1786\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.17802\n",
            "Epoch 163/300\n",
            "\n",
            "Epoch 00163: LearningRateScheduler setting learning rate to tf.Tensor(0.00045337883, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0900 - val_loss: 0.1784\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.17802\n",
            "Epoch 164/300\n",
            "\n",
            "Epoch 00164: LearningRateScheduler setting learning rate to tf.Tensor(0.00045117046, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0887 - val_loss: 0.1834\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.17802\n",
            "Epoch 165/300\n",
            "\n",
            "Epoch 00165: LearningRateScheduler setting learning rate to tf.Tensor(0.00044897277, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0884 - val_loss: 0.1794\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.17802\n",
            "Epoch 166/300\n",
            "\n",
            "Epoch 00166: LearningRateScheduler setting learning rate to tf.Tensor(0.00044678585, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0883 - val_loss: 0.1800\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.17802\n",
            "Epoch 167/300\n",
            "\n",
            "Epoch 00167: LearningRateScheduler setting learning rate to tf.Tensor(0.0004446096, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0873 - val_loss: 0.1808\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.17802\n",
            "Epoch 168/300\n",
            "\n",
            "Epoch 00168: LearningRateScheduler setting learning rate to tf.Tensor(0.0004424439, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0899 - val_loss: 0.1845\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.17802\n",
            "Epoch 169/300\n",
            "\n",
            "Epoch 00169: LearningRateScheduler setting learning rate to tf.Tensor(0.00044028874, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0874 - val_loss: 0.1797\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.17802\n",
            "Epoch 170/300\n",
            "\n",
            "Epoch 00170: LearningRateScheduler setting learning rate to tf.Tensor(0.00043814414, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0869 - val_loss: 0.1795\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.17802\n",
            "Epoch 171/300\n",
            "\n",
            "Epoch 00171: LearningRateScheduler setting learning rate to tf.Tensor(0.00043600993, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0856 - val_loss: 0.1813\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.17802\n",
            "Epoch 172/300\n",
            "\n",
            "Epoch 00172: LearningRateScheduler setting learning rate to tf.Tensor(0.00043388613, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0846 - val_loss: 0.1806\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.17802\n",
            "Epoch 173/300\n",
            "\n",
            "Epoch 00173: LearningRateScheduler setting learning rate to tf.Tensor(0.0004317727, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0840 - val_loss: 0.1789\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.17802\n",
            "Epoch 174/300\n",
            "\n",
            "Epoch 00174: LearningRateScheduler setting learning rate to tf.Tensor(0.0004296695, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0834 - val_loss: 0.1796\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.17802\n",
            "Epoch 175/300\n",
            "\n",
            "Epoch 00175: LearningRateScheduler setting learning rate to tf.Tensor(0.0004275766, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0826 - val_loss: 0.1821\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.17802\n",
            "Epoch 176/300\n",
            "\n",
            "Epoch 00176: LearningRateScheduler setting learning rate to tf.Tensor(0.00042549393, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0829 - val_loss: 0.1796\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.17802\n",
            "Epoch 177/300\n",
            "\n",
            "Epoch 00177: LearningRateScheduler setting learning rate to tf.Tensor(0.00042342133, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0838 - val_loss: 0.1836\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.17802\n",
            "Epoch 178/300\n",
            "\n",
            "Epoch 00178: LearningRateScheduler setting learning rate to tf.Tensor(0.00042135885, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0841 - val_loss: 0.1793\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.17802\n",
            "Epoch 179/300\n",
            "\n",
            "Epoch 00179: LearningRateScheduler setting learning rate to tf.Tensor(0.00041930642, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0812 - val_loss: 0.1792\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.17802\n",
            "Epoch 180/300\n",
            "\n",
            "Epoch 00180: LearningRateScheduler setting learning rate to tf.Tensor(0.00041726397, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 649ms/step - loss: 0.0810 - val_loss: 0.1800\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.17802\n",
            "Epoch 181/300\n",
            "\n",
            "Epoch 00181: LearningRateScheduler setting learning rate to tf.Tensor(0.00041523148, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0802 - val_loss: 0.1818\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.17802\n",
            "Epoch 182/300\n",
            "\n",
            "Epoch 00182: LearningRateScheduler setting learning rate to tf.Tensor(0.00041320888, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0814 - val_loss: 0.1812\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.17802\n",
            "Epoch 183/300\n",
            "\n",
            "Epoch 00183: LearningRateScheduler setting learning rate to tf.Tensor(0.00041119618, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0811 - val_loss: 0.1826\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.17802\n",
            "Epoch 184/300\n",
            "\n",
            "Epoch 00184: LearningRateScheduler setting learning rate to tf.Tensor(0.00040919325, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0804 - val_loss: 0.1816\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.17802\n",
            "Epoch 185/300\n",
            "\n",
            "Epoch 00185: LearningRateScheduler setting learning rate to tf.Tensor(0.00040720004, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0789 - val_loss: 0.1814\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.17802\n",
            "Epoch 186/300\n",
            "\n",
            "Epoch 00186: LearningRateScheduler setting learning rate to tf.Tensor(0.0004052166, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0787 - val_loss: 0.1799\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.17802\n",
            "Epoch 187/300\n",
            "\n",
            "Epoch 00187: LearningRateScheduler setting learning rate to tf.Tensor(0.0004032428, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0779 - val_loss: 0.1794\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.17802\n",
            "Epoch 188/300\n",
            "\n",
            "Epoch 00188: LearningRateScheduler setting learning rate to tf.Tensor(0.0004012786, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0778 - val_loss: 0.1801\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.17802\n",
            "Epoch 189/300\n",
            "\n",
            "Epoch 00189: LearningRateScheduler setting learning rate to tf.Tensor(0.00039932402, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0765 - val_loss: 0.1798\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.17802\n",
            "Epoch 190/300\n",
            "\n",
            "Epoch 00190: LearningRateScheduler setting learning rate to tf.Tensor(0.00039737887, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0761 - val_loss: 0.1810\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.17802\n",
            "Epoch 191/300\n",
            "\n",
            "Epoch 00191: LearningRateScheduler setting learning rate to tf.Tensor(0.00039544326, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0766 - val_loss: 0.1796\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.17802\n",
            "Epoch 192/300\n",
            "\n",
            "Epoch 00192: LearningRateScheduler setting learning rate to tf.Tensor(0.00039351705, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0761 - val_loss: 0.1792\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.17802\n",
            "Epoch 193/300\n",
            "\n",
            "Epoch 00193: LearningRateScheduler setting learning rate to tf.Tensor(0.00039160028, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0777 - val_loss: 0.1799\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.17802\n",
            "Epoch 194/300\n",
            "\n",
            "Epoch 00194: LearningRateScheduler setting learning rate to tf.Tensor(0.00038969278, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0749 - val_loss: 0.1797\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.17802\n",
            "Epoch 195/300\n",
            "\n",
            "Epoch 00195: LearningRateScheduler setting learning rate to tf.Tensor(0.0003877946, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0746 - val_loss: 0.1797\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.17802\n",
            "Epoch 196/300\n",
            "\n",
            "Epoch 00196: LearningRateScheduler setting learning rate to tf.Tensor(0.00038590565, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.0755 - val_loss: 0.1799\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.17802\n",
            "Epoch 197/300\n",
            "\n",
            "Epoch 00197: LearningRateScheduler setting learning rate to tf.Tensor(0.0003840259, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0737 - val_loss: 0.1799\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.17802\n",
            "Epoch 198/300\n",
            "\n",
            "Epoch 00198: LearningRateScheduler setting learning rate to tf.Tensor(0.00038215535, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0739 - val_loss: 0.1796\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.17802\n",
            "Epoch 199/300\n",
            "\n",
            "Epoch 00199: LearningRateScheduler setting learning rate to tf.Tensor(0.00038029387, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0729 - val_loss: 0.1808\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.17802\n",
            "Epoch 200/300\n",
            "\n",
            "Epoch 00200: LearningRateScheduler setting learning rate to tf.Tensor(0.00037844144, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.0714 - val_loss: 0.1817\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.17802\n",
            "Epoch 201/300\n",
            "\n",
            "Epoch 00201: LearningRateScheduler setting learning rate to tf.Tensor(0.00037659804, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.0714 - val_loss: 0.1797\n",
            "\n",
            "Epoch 00201: val_loss did not improve from 0.17802\n",
            "Epoch 202/300\n",
            "\n",
            "Epoch 00202: LearningRateScheduler setting learning rate to tf.Tensor(0.00037476368, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 44s 650ms/step - loss: 0.0718 - val_loss: 0.1791\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00202: val_loss did not improve from 0.17802\n",
            "Epoch 00202: early stopping\n",
            "--------------- > Fold 5 < ---------------\n",
            "Epoch 1/300\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 106s 1s/step - loss: 2.4551 - val_loss: 1.1450\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.14500, saving model to folds4.hdf5\n",
            "Epoch 2/300\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 648ms/step - loss: 0.9245 - val_loss: 0.7326\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.14500 to 0.73259, saving model to folds4.hdf5\n",
            "Epoch 3/300\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.6630 - val_loss: 0.6265\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.73259 to 0.62650, saving model to folds4.hdf5\n",
            "Epoch 4/300\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.5611 - val_loss: 0.5902\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.62650 to 0.59019, saving model to folds4.hdf5\n",
            "Epoch 5/300\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.4949 - val_loss: 0.4598\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.59019 to 0.45982, saving model to folds4.hdf5\n",
            "Epoch 6/300\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.4634 - val_loss: 0.4461\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.45982 to 0.44609, saving model to folds4.hdf5\n",
            "Epoch 7/300\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.4412 - val_loss: 0.4521\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.44609\n",
            "Epoch 8/300\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.4171 - val_loss: 0.4243\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.44609 to 0.42425, saving model to folds4.hdf5\n",
            "Epoch 9/300\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.4136 - val_loss: 0.3932\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.42425 to 0.39322, saving model to folds4.hdf5\n",
            "Epoch 10/300\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.3805 - val_loss: 0.3637\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.39322 to 0.36370, saving model to folds4.hdf5\n",
            "Epoch 11/300\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.3737 - val_loss: 0.3601\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.36370 to 0.36014, saving model to folds4.hdf5\n",
            "Epoch 12/300\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.3507 - val_loss: 0.3461\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.36014 to 0.34612, saving model to folds4.hdf5\n",
            "Epoch 13/300\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.3560 - val_loss: 0.3521\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.34612\n",
            "Epoch 14/300\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.3388 - val_loss: 0.3562\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.34612\n",
            "Epoch 15/300\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.3286 - val_loss: 0.3176\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.34612 to 0.31758, saving model to folds4.hdf5\n",
            "Epoch 16/300\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.3144 - val_loss: 0.3174\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.31758 to 0.31735, saving model to folds4.hdf5\n",
            "Epoch 17/300\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.3131 - val_loss: 0.3029\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.31735 to 0.30286, saving model to folds4.hdf5\n",
            "Epoch 18/300\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.3003 - val_loss: 0.3492\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.30286\n",
            "Epoch 19/300\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2957 - val_loss: 0.2924\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.30286 to 0.29238, saving model to folds4.hdf5\n",
            "Epoch 20/300\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2960 - val_loss: 0.2945\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.29238\n",
            "Epoch 21/300\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.2836 - val_loss: 0.2852\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.29238 to 0.28517, saving model to folds4.hdf5\n",
            "Epoch 22/300\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2808 - val_loss: 0.2688\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.28517 to 0.26884, saving model to folds4.hdf5\n",
            "Epoch 23/300\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.2691 - val_loss: 0.3010\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.26884\n",
            "Epoch 24/300\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.2636 - val_loss: 0.2643\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.26884 to 0.26433, saving model to folds4.hdf5\n",
            "Epoch 25/300\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.2683 - val_loss: 0.2677\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.26433\n",
            "Epoch 26/300\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2589 - val_loss: 0.2921\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.26433\n",
            "Epoch 27/300\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2575 - val_loss: 0.2651\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.26433\n",
            "Epoch 28/300\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2511 - val_loss: 0.2588\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.26433 to 0.25883, saving model to folds4.hdf5\n",
            "Epoch 29/300\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 648ms/step - loss: 0.2629 - val_loss: 0.2747\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.25883\n",
            "Epoch 30/300\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2708 - val_loss: 0.2945\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.25883\n",
            "Epoch 31/300\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.2561 - val_loss: 0.2503\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.25883 to 0.25027, saving model to folds4.hdf5\n",
            "Epoch 32/300\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2352 - val_loss: 0.2569\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.25027\n",
            "Epoch 33/300\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2323 - val_loss: 0.2349\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.25027 to 0.23486, saving model to folds4.hdf5\n",
            "Epoch 34/300\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2634 - val_loss: 0.3110\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.23486\n",
            "Epoch 35/300\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2513 - val_loss: 0.2464\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.23486\n",
            "Epoch 36/300\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2401 - val_loss: 0.2597\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.23486\n",
            "Epoch 37/300\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2263 - val_loss: 0.2269\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.23486 to 0.22693, saving model to folds4.hdf5\n",
            "Epoch 38/300\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2316 - val_loss: 0.2478\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.22693\n",
            "Epoch 39/300\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.2221 - val_loss: 0.2238\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.22693 to 0.22379, saving model to folds4.hdf5\n",
            "Epoch 40/300\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.2236 - val_loss: 0.2300\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.22379\n",
            "Epoch 41/300\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2112 - val_loss: 0.2186\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.22379 to 0.21862, saving model to folds4.hdf5\n",
            "Epoch 42/300\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2118 - val_loss: 0.2280\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.21862\n",
            "Epoch 43/300\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2142 - val_loss: 0.2152\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.21862 to 0.21517, saving model to folds4.hdf5\n",
            "Epoch 44/300\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2157 - val_loss: 0.2230\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.21517\n",
            "Epoch 45/300\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2120 - val_loss: 0.2258\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.21517\n",
            "Epoch 46/300\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.2079 - val_loss: 0.2267\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.21517\n",
            "Epoch 47/300\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2040 - val_loss: 0.2131\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.21517 to 0.21312, saving model to folds4.hdf5\n",
            "Epoch 48/300\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2132 - val_loss: 0.2182\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.21312\n",
            "Epoch 49/300\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2050 - val_loss: 0.2144\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.21312\n",
            "Epoch 50/300\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2068 - val_loss: 0.2170\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.21312\n",
            "Epoch 51/300\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1972 - val_loss: 0.2068\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.21312 to 0.20675, saving model to folds4.hdf5\n",
            "Epoch 52/300\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.2173 - val_loss: 0.2354\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.20675\n",
            "Epoch 53/300\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.2031 - val_loss: 0.2488\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.20675\n",
            "Epoch 54/300\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.2034 - val_loss: 0.2100\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.20675\n",
            "Epoch 55/300\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1967 - val_loss: 0.2118\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.20675\n",
            "Epoch 56/300\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1914 - val_loss: 0.2067\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.20675 to 0.20674, saving model to folds4.hdf5\n",
            "Epoch 57/300\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1923 - val_loss: 0.2038\n",
            "\n",
            "Epoch 00057: val_loss improved from 0.20674 to 0.20378, saving model to folds4.hdf5\n",
            "Epoch 58/300\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1871 - val_loss: 0.2072\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.20378\n",
            "Epoch 59/300\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1855 - val_loss: 0.2115\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.20378\n",
            "Epoch 60/300\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1929 - val_loss: 0.2252\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.20378\n",
            "Epoch 61/300\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1909 - val_loss: 0.2129\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.20378\n",
            "Epoch 62/300\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1856 - val_loss: 0.2071\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.20378\n",
            "Epoch 63/300\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to tf.Tensor(0.0007387921, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1784 - val_loss: 0.2137\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.20378\n",
            "Epoch 64/300\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to tf.Tensor(0.00073519343, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1797 - val_loss: 0.2045\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.20378\n",
            "Epoch 65/300\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to tf.Tensor(0.0007316123, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1820 - val_loss: 0.1977\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.20378 to 0.19766, saving model to folds4.hdf5\n",
            "Epoch 66/300\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to tf.Tensor(0.0007280487, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1839 - val_loss: 0.2029\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.19766\n",
            "Epoch 67/300\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to tf.Tensor(0.0007245024, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1776 - val_loss: 0.2050\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.19766\n",
            "Epoch 68/300\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to tf.Tensor(0.0007209733, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1790 - val_loss: 0.2148\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.19766\n",
            "Epoch 69/300\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to tf.Tensor(0.00071746146, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1788 - val_loss: 0.2064\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.19766\n",
            "Epoch 70/300\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to tf.Tensor(0.0007139667, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1706 - val_loss: 0.1959\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.19766 to 0.19587, saving model to folds4.hdf5\n",
            "Epoch 71/300\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to tf.Tensor(0.00071048894, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1710 - val_loss: 0.2088\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.19587\n",
            "Epoch 72/300\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to tf.Tensor(0.0007070282, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1718 - val_loss: 0.1988\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.19587\n",
            "Epoch 73/300\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to tf.Tensor(0.0007035842, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1735 - val_loss: 0.1929\n",
            "\n",
            "Epoch 00073: val_loss improved from 0.19587 to 0.19287, saving model to folds4.hdf5\n",
            "Epoch 74/300\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to tf.Tensor(0.00070015714, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1686 - val_loss: 0.2029\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.19287\n",
            "Epoch 75/300\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to tf.Tensor(0.0006967467, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1728 - val_loss: 0.1903\n",
            "\n",
            "Epoch 00075: val_loss improved from 0.19287 to 0.19026, saving model to folds4.hdf5\n",
            "Epoch 76/300\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to tf.Tensor(0.00069335283, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1672 - val_loss: 0.1910\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.19026\n",
            "Epoch 77/300\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to tf.Tensor(0.0006899755, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1666 - val_loss: 0.1882\n",
            "\n",
            "Epoch 00077: val_loss improved from 0.19026 to 0.18820, saving model to folds4.hdf5\n",
            "Epoch 78/300\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to tf.Tensor(0.00068661466, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.1695 - val_loss: 0.2251\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.18820\n",
            "Epoch 79/300\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to tf.Tensor(0.00068327016, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1732 - val_loss: 0.2036\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.18820\n",
            "Epoch 80/300\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to tf.Tensor(0.00067994196, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1647 - val_loss: 0.2021\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.18820\n",
            "Epoch 81/300\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to tf.Tensor(0.00067663, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 44s 650ms/step - loss: 0.1686 - val_loss: 0.1873\n",
            "\n",
            "Epoch 00081: val_loss improved from 0.18820 to 0.18726, saving model to folds4.hdf5\n",
            "Epoch 82/300\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to tf.Tensor(0.0006733342, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1617 - val_loss: 0.1891\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.18726\n",
            "Epoch 83/300\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to tf.Tensor(0.00067005435, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1609 - val_loss: 0.1834\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.18726 to 0.18342, saving model to folds4.hdf5\n",
            "Epoch 84/300\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to tf.Tensor(0.0006667905, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1550 - val_loss: 0.1893\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.18342\n",
            "Epoch 85/300\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to tf.Tensor(0.0006635426, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1547 - val_loss: 0.1847\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.18342\n",
            "Epoch 86/300\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to tf.Tensor(0.0006603105, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1528 - val_loss: 0.1893\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.18342\n",
            "Epoch 87/300\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to tf.Tensor(0.0006570942, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1554 - val_loss: 0.1854\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.18342\n",
            "Epoch 88/300\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to tf.Tensor(0.00065389345, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1531 - val_loss: 0.1859\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.18342\n",
            "Epoch 89/300\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to tf.Tensor(0.00065070833, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1497 - val_loss: 0.1816\n",
            "\n",
            "Epoch 00089: val_loss improved from 0.18342 to 0.18161, saving model to folds4.hdf5\n",
            "Epoch 90/300\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to tf.Tensor(0.00064753875, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1468 - val_loss: 0.1826\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.18161\n",
            "Epoch 91/300\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to tf.Tensor(0.0006443846, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 642ms/step - loss: 0.1488 - val_loss: 0.1803\n",
            "\n",
            "Epoch 00091: val_loss improved from 0.18161 to 0.18026, saving model to folds4.hdf5\n",
            "Epoch 92/300\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to tf.Tensor(0.0006412458, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1466 - val_loss: 0.1819\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.18026\n",
            "Epoch 93/300\n",
            "\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to tf.Tensor(0.00063812226, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1448 - val_loss: 0.1819\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.18026\n",
            "Epoch 94/300\n",
            "\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to tf.Tensor(0.00063501403, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1431 - val_loss: 0.1804\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.18026\n",
            "Epoch 95/300\n",
            "\n",
            "Epoch 00095: LearningRateScheduler setting learning rate to tf.Tensor(0.0006319209, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1443 - val_loss: 0.1796\n",
            "\n",
            "Epoch 00095: val_loss improved from 0.18026 to 0.17960, saving model to folds4.hdf5\n",
            "Epoch 96/300\n",
            "\n",
            "Epoch 00096: LearningRateScheduler setting learning rate to tf.Tensor(0.0006288428, shape=(), dtype=float32).\n",
            "67/67 [==============================] - 43s 641ms/step - loss: 0.1434 - val_loss: 0.1807\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.17960\n",
            "Epoch 97/300\n",
            "\n",
            "Epoch 00097: LearningRateScheduler setting learning rate to tf.Tensor(0.00062577974, shape=(), dtype=float32).\n",
            "64/67 [===========================>..] - ETA: 1s - loss: 0.1438"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "fa34eff3"
      },
      "source": [
        "## Median method from [Chris Deotte](https://www.kaggle.com/cdeotte/ensemble-folds-with-median-0-153)"
      ],
      "id": "fa34eff3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-06T13:25:41.104884Z",
          "iopub.status.busy": "2021-10-06T13:25:41.104618Z",
          "iopub.status.idle": "2021-10-06T13:25:53.401461Z",
          "shell.execute_reply": "2021-10-06T13:25:53.40066Z",
          "shell.execute_reply.started": "2021-10-06T13:25:41.104848Z"
        },
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "24a46854"
      },
      "source": [
        "submission[\"pressure\"] = sum(test_preds)/NUM_FOLDS\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "# ENSEMBLE FOLDS WITH MEDIAN\n",
        "submission[\"pressure\"] = np.median(np.vstack(test_preds),axis=0)\n",
        "submission.to_csv('submission_median.csv', index=False)\n",
        "\n",
        "# ENSEMBLE FOLDS WITH MEDIAN AND ROUND PREDICTIONS\n",
        "submission[\"pressure\"] =\\\n",
        "    np.round( (submission.pressure - PRESSURE_MIN)/PRESSURE_STEP ) * PRESSURE_STEP + PRESSURE_MIN\n",
        "submission.pressure = np.clip(submission.pressure, PRESSURE_MIN, PRESSURE_MAX)\n",
        "submission.to_csv('submission_median_round.csv', index=False)"
      ],
      "id": "24a46854",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu2Wf-Oydbkj"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('submission.csv')\n",
        "files.download('submission_median.csv')\n",
        "files.download('submission_median_round.csv')\n"
      ],
      "id": "Tu2Wf-Oydbkj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4ZMO92idii3"
      },
      "source": [
        ""
      ],
      "id": "o4ZMO92idii3",
      "execution_count": null,
      "outputs": []
    }
  ]
}