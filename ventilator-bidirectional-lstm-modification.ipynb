{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08c38ea9",
   "metadata": {
    "_cell_guid": "3e5a0bd1-3e22-4b2c-a565-68985e55f95e",
    "_uuid": "e331dbcc-0346-4019-9ff6-b890154a878b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-10-07T13:42:44.091398Z",
     "iopub.status.busy": "2021-10-07T13:42:44.090045Z",
     "iopub.status.idle": "2021-10-07T13:42:51.274417Z",
     "shell.execute_reply": "2021-10-07T13:42:51.273780Z",
     "shell.execute_reply.started": "2021-10-06T07:27:20.229376Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 7.197728,
     "end_time": "2021-10-07T13:42:51.274629",
     "exception": false,
     "start_time": "2021-10-07T13:42:44.076901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import optuna\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.preprocessing import RobustScaler, normalize\n",
    "from sklearn.model_selection import train_test_split, GroupKFold, KFold\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "735fbfa4",
   "metadata": {
    "_cell_guid": "89eb257e-0ed2-4f8b-94d6-462a5e995eb1",
    "_uuid": "ca71d87d-6594-4f31-906d-0b53cd4c1374",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-10-07T13:42:51.298700Z",
     "iopub.status.busy": "2021-10-07T13:42:51.297870Z",
     "iopub.status.idle": "2021-10-07T13:43:04.843622Z",
     "shell.execute_reply": "2021-10-07T13:43:04.844111Z",
     "shell.execute_reply.started": "2021-10-06T07:27:20.23849Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 13.56036,
     "end_time": "2021-10-07T13:43:04.844301",
     "exception": false,
     "start_time": "2021-10-07T13:42:51.283941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "train = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\n",
    "test = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\n",
    "submission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n",
    "\n",
    "if DEBUG:\n",
    "    train = train[:80*1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1eb95c",
   "metadata": {
    "papermill": {
     "duration": 0.00769,
     "end_time": "2021-10-07T13:43:04.860045",
     "exception": false,
     "start_time": "2021-10-07T13:43:04.852355",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Engineer Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db48a273",
   "metadata": {
    "papermill": {
     "duration": 0.007522,
     "end_time": "2021-10-07T13:43:04.875490",
     "exception": false,
     "start_time": "2021-10-07T13:43:04.867968",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## From [Ventilator: Feature engineering](https://www.kaggle.com/mistag/ventilator-feature-engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34bf48a7",
   "metadata": {
    "_cell_guid": "13a36b46-7067-4b29-aad3-7e3b15e8415b",
    "_uuid": "dc41dbf2-f199-4b9d-bbd9-bf6084162b47",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-10-07T13:43:04.917023Z",
     "iopub.status.busy": "2021-10-07T13:43:04.911085Z",
     "iopub.status.idle": "2021-10-07T13:43:43.661039Z",
     "shell.execute_reply": "2021-10-07T13:43:43.661484Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 38.778258,
     "end_time": "2021-10-07T13:43:43.661678",
     "exception": false,
     "start_time": "2021-10-07T13:43:04.883420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Feature engineering\n",
    "def add_features(df):\n",
    "    df['area'] = df['time_step'] * df['u_in']\n",
    "    df['area'] = df.groupby('breath_id')['area'].cumsum()\n",
    "    \n",
    "    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n",
    "    \n",
    "    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n",
    "    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n",
    "    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n",
    "    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n",
    "    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n",
    "    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n",
    "    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n",
    "    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n",
    "    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n",
    "    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n",
    "    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n",
    "    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n",
    "    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n",
    "    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n",
    "    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n",
    "    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n",
    "    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n",
    "    \n",
    "    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n",
    "    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n",
    "    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n",
    "    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n",
    "    \n",
    "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
    "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
    "    \n",
    "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
    "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
    "    \n",
    "    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n",
    "    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n",
    "    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n",
    "    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n",
    "    df['cross']= df['u_in']*df['u_out']\n",
    "    df['cross2']= df['time_step']*df['u_out']\n",
    "    \n",
    "    df['R'] = df['R'].astype(str)\n",
    "    df['C'] = df['C'].astype(str)\n",
    "    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n",
    "    df = pd.get_dummies(df)\n",
    "    return df\n",
    "\n",
    "train = add_features(train)\n",
    "test = add_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9bc5ccf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-07T13:43:43.684700Z",
     "iopub.status.busy": "2021-10-07T13:43:43.684073Z",
     "iopub.status.idle": "2021-10-07T13:43:43.688031Z",
     "shell.execute_reply": "2021-10-07T13:43:43.688508Z"
    },
    "papermill": {
     "duration": 0.018945,
     "end_time": "2021-10-07T13:43:43.688688",
     "exception": false,
     "start_time": "2021-10-07T13:43:43.669743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4024000, 52)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72bad96f",
   "metadata": {
    "_cell_guid": "01328860-fa2a-421c-9e5f-ea0048246f98",
    "_uuid": "346bf2c0-96d2-4da5-8837-c0f820294a85",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-10-07T13:43:43.709994Z",
     "iopub.status.busy": "2021-10-07T13:43:43.709306Z",
     "iopub.status.idle": "2021-10-07T13:43:47.135372Z",
     "shell.execute_reply": "2021-10-07T13:43:47.134816Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.437871,
     "end_time": "2021-10-07T13:43:47.135523",
     "exception": false,
     "start_time": "2021-10-07T13:43:43.697652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = train[['pressure']].to_numpy().reshape(-1, 80)\n",
    "train.drop(['pressure', 'id', 'breath_id'], axis=1, inplace=True)\n",
    "test = test.drop(['id', 'breath_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e18e67ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-07T13:43:47.161397Z",
     "iopub.status.busy": "2021-10-07T13:43:47.160008Z",
     "iopub.status.idle": "2021-10-07T13:43:57.821082Z",
     "shell.execute_reply": "2021-10-07T13:43:57.820564Z"
    },
    "papermill": {
     "duration": 10.676832,
     "end_time": "2021-10-07T13:43:57.821233",
     "exception": false,
     "start_time": "2021-10-07T13:43:47.144401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Normalise the dataset\n",
    "RS = RobustScaler()\n",
    "train = RS.fit_transform(train)\n",
    "test = RS.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0174b86a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-07T13:43:57.844046Z",
     "iopub.status.busy": "2021-10-07T13:43:57.843150Z",
     "iopub.status.idle": "2021-10-07T13:43:57.846063Z",
     "shell.execute_reply": "2021-10-07T13:43:57.845508Z"
    },
    "papermill": {
     "duration": 0.016185,
     "end_time": "2021-10-07T13:43:57.846195",
     "exception": false,
     "start_time": "2021-10-07T13:43:57.830010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Reshape group to 80 timesteps for each breath ID\n",
    "train = train.reshape(-1, 80, train.shape[-1])\n",
    "test = test.reshape(-1, 80, train.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d2fb01",
   "metadata": {
    "papermill": {
     "duration": 0.00825,
     "end_time": "2021-10-07T13:43:57.863196",
     "exception": false,
     "start_time": "2021-10-07T13:43:57.854946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dcf75dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-07T13:43:57.892905Z",
     "iopub.status.busy": "2021-10-07T13:43:57.892246Z",
     "iopub.status.idle": "2021-10-07T13:43:58.199913Z",
     "shell.execute_reply": "2021-10-07T13:43:58.199263Z",
     "shell.execute_reply.started": "2021-10-06T07:28:39.357315Z"
    },
    "papermill": {
     "duration": 0.328414,
     "end_time": "2021-10-07T13:43:58.200201",
     "exception": true,
     "start_time": "2021-10-07T13:43:57.871787",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please provide a TPU Name to connect to.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22/303018256.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# detect and init the TPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUClusterResolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# instantiate a distribution strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(tpu, zone, project)\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mno\u001b[0m \u001b[0mTPU\u001b[0m \u001b[0mdevices\u001b[0m \u001b[0mfound\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meager\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \"\"\"\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mresolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTPUClusterResolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mremote\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect_to_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tpu, zone, project, job_name, coordinator_name, coordinator_address, credentials, service, discovery_url)\u001b[0m\n\u001b[1;32m    205\u001b[0m           \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m           \u001b[0mservice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m           discovery_url=discovery_url)\n\u001b[0m\u001b[1;32m    208\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cloud_tpu_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/cloud_tpu_client/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tpu, zone, project, credentials, service, discovery_url)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtpu\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please provide a TPU Name to connect to.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Please provide a TPU Name to connect to."
     ]
    }
   ],
   "source": [
    "EPOCH = 300\n",
    "BATCH_SIZE = 1024\n",
    "NUM_FOLDS = 10\n",
    "\n",
    "# detect and init the TPU\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "\n",
    "# instantiate a distribution strategy\n",
    "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "#GPU init\n",
    "#gpu_strategy = tf.distribute.get_strategy()\n",
    "\n",
    "#with gpu_strategy.scope():\n",
    "with tpu_strategy.scope():\n",
    "    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=2021)\n",
    "    test_preds = []\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n",
    "        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n",
    "        X_train, X_valid = train[train_idx], train[test_idx]\n",
    "        y_train, y_valid = targets[train_idx], targets[test_idx]\n",
    "        model = keras.models.Sequential([\n",
    "            keras.layers.Input(shape=train.shape[-2:]),\n",
    "            #bidirectional LSTM 1024->512->256->128\n",
    "            keras.layers.Bidirectional(keras.layers.LSTM(1024, return_sequences=True)),\n",
    "            keras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True)),\n",
    "            keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True)),\n",
    "            keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),\n",
    "\n",
    "            keras.layers.Dense(128, activation='selu'),\n",
    "          # keras.layers.Dropout(0.1),\n",
    "            keras.layers.Dense(1),\n",
    "        ])\n",
    "        model.compile(optimizer=\"adam\", loss=\"mae\")\n",
    "\n",
    "        scheduler = ExponentialDecay(1e-3, 40*((len(train)*0.8)/BATCH_SIZE), 1e-5)\n",
    "        lr = LearningRateScheduler(scheduler, verbose=1)\n",
    "        \n",
    "        #lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1)\n",
    "        #lr = WarmupExponentialDecay(lr_base=1e-3, decay=1e-5, warmup_epochs=30)\n",
    "        es = EarlyStopping(monitor=\"val_loss\", patience=60, verbose=1, mode=\"min\", restore_best_weights=True)\n",
    "    \n",
    "        checkpoint_filepath = f\"folds{fold}.hdf5\"\n",
    "        sv = keras.callbacks.ModelCheckpoint(\n",
    "            checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "            save_weights_only=False, mode='auto', save_freq='epoch',\n",
    "            options=None\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr, es, sv])\n",
    "        #model.save(f'Fold{fold+1} RNN Weights')\n",
    "        test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa34eff3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Median method from [Chris Deotte](https://www.kaggle.com/cdeotte/ensemble-folds-with-median-0-153)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a46854",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T13:25:41.104884Z",
     "iopub.status.busy": "2021-10-06T13:25:41.104618Z",
     "iopub.status.idle": "2021-10-06T13:25:53.401461Z",
     "shell.execute_reply": "2021-10-06T13:25:53.40066Z",
     "shell.execute_reply.started": "2021-10-06T13:25:41.104848Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission[\"pressure\"] = sum(test_preds)/NUM_FOLDS\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# ENSEMBLE FOLDS WITH MEDIAN\n",
    "submission[\"pressure\"] = np.median(np.vstack(test_preds),axis=0)\n",
    "submission.to_csv('submission_median.csv', index=False)\n",
    "\n",
    "# ENSEMBLE FOLDS WITH MEDIAN AND ROUND PREDICTIONS\n",
    "submission[\"pressure\"] =\\\n",
    "    np.round( (submission.pressure - PRESSURE_MIN)/PRESSURE_STEP ) * PRESSURE_STEP + PRESSURE_MIN\n",
    "submission.pressure = np.clip(submission.pressure, PRESSURE_MIN, PRESSURE_MAX)\n",
    "submission.to_csv('submission_median_round.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 84.777097,
   "end_time": "2021-10-07T13:44:01.547476",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-07T13:42:36.770379",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
