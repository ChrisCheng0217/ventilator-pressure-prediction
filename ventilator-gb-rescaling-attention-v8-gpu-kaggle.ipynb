{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"V1: Keep R/C, improve\n\nV2: Add R**2, no improve\n\nV3: Update model from https://www.kaggle.com/dlaststark/gb-vpp-pulp-fiction. Not much improve compare V1\n\nV4: Use whole db for test Fold-1\nFold-1 | OOF Score: 0.15912771348961205\n\nV5: Add loading ScaleLayer from saved model\n\nV6: Add TransformerEncoder. TransformerEncoder(128, 512, 8, name=\"transformer_layer\")(x). Testing in GPU.\n\nV7: Try to scale targe to 0-1, but it slow the train as MASE cannot be scaled.\n\nV8: Removed target scale.\n","metadata":{"id":"Yh6Zg50KJQBQ"}},{"cell_type":"code","source":"# Update pandas version for Colab TPU\n#!pip install pandas==1.3.2\n","metadata":{"id":"uslq2jL49nGk","outputId":"a9034aba-065d-414c-8ee9-bb8fcfc6d26b","execution":{"iopub.status.busy":"2021-10-22T18:06:05.547763Z","iopub.execute_input":"2021-10-22T18:06:05.548612Z","iopub.status.idle":"2021-10-22T18:06:05.566899Z","shell.execute_reply.started":"2021-10-22T18:06:05.548483Z","shell.execute_reply":"2021-10-22T18:06:05.566206Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Import libraries","metadata":{"id":"RBJlpUNI9com"}},{"cell_type":"code","source":"try:\n  import google.colab\n  IN_COLAB = True\nexcept:\n  IN_COLAB = False\nDEBUG = False","metadata":{"id":"iXzLriPA9coq","execution":{"iopub.status.busy":"2021-10-22T18:06:05.569953Z","iopub.execute_input":"2021-10-22T18:06:05.570719Z","iopub.status.idle":"2021-10-22T18:06:05.580553Z","shell.execute_reply.started":"2021-10-22T18:06:05.570668Z","shell.execute_reply":"2021-10-22T18:06:05.579824Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"if IN_COLAB:\n  from google.colab import drive\n  drive.mount(\"/gdrive\", force_remount=True)","metadata":{"id":"9esF__aG9cor","outputId":"44128744-2672-41fb-e16d-94ed86b44a41","execution":{"iopub.status.busy":"2021-10-22T18:06:05.582016Z","iopub.execute_input":"2021-10-22T18:06:05.582576Z","iopub.status.idle":"2021-10-22T18:06:05.589631Z","shell.execute_reply.started":"2021-10-22T18:06:05.582535Z","shell.execute_reply":"2021-10-22T18:06:05.588895Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"if IN_COLAB:\n  !pip install kaggle\n  !mkdir /root/.kaggle\n  !cp /gdrive/MyDrive/ventilator-pressure-prediction/kaggle.json /root/.kaggle\n  !kaggle competitions download -c ventilator-pressure-prediction\n  !mkdir -p ../input/ventilator-pressure-prediction\n  !unzip '*.zip' -d ../input/ventilator-pressure-prediction\n  !ls ../input/ventilator-pressure-prediction\n  !mkdir /gdrive/MyDrive/ventilator-pressure-prediction/gb-rescaling-eda-v3-gpu\n  #Map Google driver folder to local folder model to save model\n  !ln -s /gdrive/MyDrive/ventilator-pressure-prediction/gb-rescaling-eda-v3-gpu model-gpu\nelse:\n  #Download feature files\n  !pip install gdown\n  !gdown https://drive.google.com/uc?id=1-Ds4O7pYglC4rFNc11jbOAw-mQInqSGc\n  !unzip features.zip\n  !mkdir ./model-gpu","metadata":{"id":"MZ_f3Z2M9cos","outputId":"450ad63e-c0fa-49a1-fce9-007820ea3738","execution":{"iopub.status.busy":"2021-10-22T18:06:05.591644Z","iopub.execute_input":"2021-10-22T18:06:05.592371Z","iopub.status.idle":"2021-10-22T18:07:34.753818Z","shell.execute_reply.started":"2021-10-22T18:06:05.592336Z","shell.execute_reply":"2021-10-22T18:07:34.752834Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import gc\nimport numpy as np\nimport pandas as pd\nimport random\nimport os\nfrom sklearn.model_selection import KFold\n\nfrom sklearn.metrics import mean_absolute_error\n\nimport tensorflow as tf\ngpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n  tf.config.experimental.set_memory_growth(gpu, True)\n\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Dense, Dropout, Input\nfrom tensorflow.keras.layers import Concatenate, LSTM, GRU\nfrom tensorflow.keras.layers import Bidirectional, Multiply\n\n\n# Random Seed Initialize\nRANDOM_SEED = 42\n\ndef seed_everything(seed=RANDOM_SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\n    \nseed_everything()","metadata":{"id":"1TfjZidC9cos","execution":{"iopub.status.busy":"2021-10-22T18:07:34.755480Z","iopub.execute_input":"2021-10-22T18:07:34.756024Z","iopub.status.idle":"2021-10-22T18:07:40.448648Z","shell.execute_reply.started":"2021-10-22T18:07:34.755984Z","shell.execute_reply":"2021-10-22T18:07:40.447900Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Load datasets","metadata":{"id":"XycyrO7g9cot"}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\n\nall_pressure = np.sort(train_df['pressure'].unique())\npressure_min =  all_pressure[0].item()\npressure_max = all_pressure[-1].item()\npressure_step = (all_pressure[1] - all_pressure[0]).item()\n\npressure_min,pressure_max,pressure_step","metadata":{"execution":{"iopub.status.busy":"2021-10-22T18:07:40.450615Z","iopub.execute_input":"2021-10-22T18:07:40.450999Z","iopub.status.idle":"2021-10-22T18:07:40.456768Z","shell.execute_reply.started":"2021-10-22T18:07:40.450963Z","shell.execute_reply":"2021-10-22T18:07:40.456108Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train = np.load('train.npy')\ntest = np.load('test.npy')\ntargets = train_df[['pressure']].to_numpy().reshape(-1, 80)\ndel train_df\ngc.collect()\n\nprint(f\"train: {train.shape} \\ntest: {test.shape} \\ntargets: {targets.shape}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-22T18:07:40.457976Z","iopub.execute_input":"2021-10-22T18:07:40.458250Z","iopub.status.idle":"2021-10-22T18:07:57.531680Z","shell.execute_reply.started":"2021-10-22T18:07:40.458217Z","shell.execute_reply":"2021-10-22T18:07:57.530839Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Hardware config","metadata":{"id":"Osu14DeV9co1"}},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    BATCH_SIZE = tpu_strategy.num_replicas_in_sync * 64\n    print(\"Running on TPU:\", tpu.master())\n    print(f\"Batch Size: {BATCH_SIZE}\")\n    \nexcept ValueError:\n    tpu_strategy = tf.distribute.get_strategy()\n    BATCH_SIZE = 512\n    print(f\"Running on {tpu_strategy.num_replicas_in_sync} replicas\")\n    print(f\"Batch Size: {BATCH_SIZE}\")","metadata":{"id":"CisxazED9co1","execution":{"iopub.status.busy":"2021-10-22T18:07:57.532913Z","iopub.execute_input":"2021-10-22T18:07:57.533497Z","iopub.status.idle":"2021-10-22T18:07:57.724145Z","shell.execute_reply.started":"2021-10-22T18:07:57.533456Z","shell.execute_reply":"2021-10-22T18:07:57.723404Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Rescaling layer","metadata":{"id":"GAZMw10A9co1"}},{"cell_type":"code","source":"@tf.custom_gradient\ndef round_with_gradients(x):\n    def grad(dy):\n        return dy\n    return tf.round(x), grad\n\nclass ScaleLayer(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super(ScaleLayer, self).__init__(**kwargs)\n        self.min = tf.constant(pressure_min, dtype=np.float32)\n        self.max = tf.constant(pressure_max, dtype=np.float32)\n        self.step = tf.constant(pressure_step, dtype=np.float32)\n\n    def call(self, inputs):\n        steps = tf.math.divide(tf.math.add(inputs, -self.min), self.step)\n        int_steps = round_with_gradients(steps)\n        rescaled_steps = tf.math.add(tf.math.multiply(int_steps, self.step), self.min)\n        clipped = tf.clip_by_value(rescaled_steps, self.min, self.max)\n        return clipped\n    # def get_config(self):\n    #     return super(ScaleLayer, self).get_config()\n","metadata":{"id":"qLou5BDt9co2","execution":{"iopub.status.busy":"2021-10-22T18:07:57.725470Z","iopub.execute_input":"2021-10-22T18:07:57.725736Z","iopub.status.idle":"2021-10-22T18:07:59.344478Z","shell.execute_reply.started":"2021-10-22T18:07:57.725700Z","shell.execute_reply":"2021-10-22T18:07:59.342504Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class TransformerEncoder(tf.keras.layers.Layer):\n    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n        super().__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.dense_dim = dense_dim\n        self.num_heads = num_heads\n        self.attention = tf.keras.layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim, dropout=0.3\n        )\n        self.dense_proj = tf.keras.Sequential(\n            [tf.keras.layers.Dense(dense_dim, activation=tf.nn.gelu), tf.keras.layers.Dense(embed_dim),]\n        )\n        self.layernorm_1 = tf.keras.layers.LayerNormalization()\n        self.layernorm_2 = tf.keras.layers.LayerNormalization()\n\n    def call(self, inputs, mask=None):\n        if mask is not None:\n            mask = mask[:, tf.newaxis, :]\n\n        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n        proj_input = self.layernorm_1(inputs + attention_output)\n        proj_output = self.dense_proj(proj_input)\n        return self.layernorm_2(proj_input + proj_output)\n    def get_config(self):\n        config = super(TransformerEncoder, self).get_config()\n        config.update({\"embed_dim\": self.embed_dim,\n            \"dense_dim\": self.dense_dim,\n            \"num_heads\": self.num_heads})\n        return config","metadata":{"id":"PfmPPh-U2EUY","execution":{"iopub.status.busy":"2021-10-22T18:07:59.351059Z","iopub.execute_input":"2021-10-22T18:07:59.353730Z","iopub.status.idle":"2021-10-22T18:07:59.375578Z","shell.execute_reply.started":"2021-10-22T18:07:59.353556Z","shell.execute_reply":"2021-10-22T18:07:59.374870Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Keras DNN Model","metadata":{"id":"5Ft0JBPC9co2"}},{"cell_type":"code","source":"def dnn_model():\n    \n    x_input = Input(shape=(train.shape[-2:]))\n    \n    x1 = Bidirectional(LSTM(units=768, return_sequences=True))(x_input)\n    x2 = Bidirectional(LSTM(units=512, return_sequences=True))(x1)\n    x3 = Bidirectional(LSTM(units=384, return_sequences=True))(x2)\n    x4 = Bidirectional(LSTM(units=256, return_sequences=True))(x3)\n    x5 = Bidirectional(LSTM(units=128, return_sequences=True))(x4)\n    \n    z2 = Bidirectional(GRU(units=384, return_sequences=True))(x2)\n    \n    z31 = Multiply()([x3, z2])\n    z31 = BatchNormalization()(z31)\n    z3 = Bidirectional(GRU(units=256, return_sequences=True))(z31)\n    \n    z41 = Multiply()([x4, z3])\n    z41 = BatchNormalization()(z41)\n    z4 = Bidirectional(GRU(units=128, return_sequences=True))(z41)\n    \n    z51 = Multiply()([x5, z4])\n    z51 = BatchNormalization()(z51)\n    z5 = Bidirectional(GRU(units=64, return_sequences=True))(z51)\n    \n    x = Concatenate(axis=2)([x5, z2, z3, z4, z5])\n\n    x = Dense(units=128)(x)\n\n    x_transformer = BatchNormalization()(x)\n    x_transformer = TransformerEncoder(128, 128, 4, name=\"transformer_layer\")(x_transformer)\n    x = Multiply()([x, x_transformer])\n    \n    x = Dense(units=128, activation='selu')(x)\n    \n    x_output = Dense(units=1)(x)\n    \n    x_output = ScaleLayer()(x_output)\n\n    model = Model(inputs=x_input, outputs=x_output, \n                  name='DNN_Model')\n    return model","metadata":{"id":"_HuMFGY39co2","execution":{"iopub.status.busy":"2021-10-22T18:07:59.385741Z","iopub.execute_input":"2021-10-22T18:07:59.387959Z","iopub.status.idle":"2021-10-22T18:07:59.409046Z","shell.execute_reply.started":"2021-10-22T18:07:59.387916Z","shell.execute_reply":"2021-10-22T18:07:59.408211Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = dnn_model()\nmodel.summary()","metadata":{"id":"_d8ybRJc9co2","execution":{"iopub.status.busy":"2021-10-22T18:07:59.415701Z","iopub.execute_input":"2021-10-22T18:07:59.417826Z","iopub.status.idle":"2021-10-22T18:08:08.078578Z","shell.execute_reply.started":"2021-10-22T18:07:59.417789Z","shell.execute_reply":"2021-10-22T18:08:08.077834Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"plot_model(\n    model, \n    to_file='Google_Brain_Keras_Model.png', \n    show_shapes=True,\n    show_layer_names=True\n)","metadata":{"id":"e-M0ZMvC9co3","execution":{"iopub.status.busy":"2021-10-22T18:08:08.080127Z","iopub.execute_input":"2021-10-22T18:08:08.080482Z","iopub.status.idle":"2021-10-22T18:08:09.246594Z","shell.execute_reply.started":"2021-10-22T18:08:08.080443Z","shell.execute_reply":"2021-10-22T18:08:09.245847Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"del model\ngc.collect()","metadata":{"id":"rxWQVBYm-0VK","execution":{"iopub.status.busy":"2021-10-22T18:08:09.247832Z","iopub.execute_input":"2021-10-22T18:08:09.248102Z","iopub.status.idle":"2021-10-22T18:08:09.456991Z","shell.execute_reply.started":"2021-10-22T18:08:09.248063Z","shell.execute_reply":"2021-10-22T18:08:09.456160Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#reset Keras Session\ndef reset_keras():\n    sess = tf.compat.v1.keras.backend.get_session()\n    tf.compat.v1.keras.backend.clear_session()\n    sess.close()\n    sess = tf.compat.v1.keras.backend.get_session()\n\n    # use the same config as you used to create the session\n    config = tf.compat.v1.ConfigProto()\n    config.gpu_options.per_process_gpu_memory_fraction = 1\n    config.gpu_options.visible_device_list = \"0\"\n    tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))\n    gc.collect()\n\nreset_keras()","metadata":{"id":"u1v9SMji9co3","execution":{"iopub.status.busy":"2021-10-22T18:08:09.458593Z","iopub.execute_input":"2021-10-22T18:08:09.458869Z","iopub.status.idle":"2021-10-22T18:08:10.086668Z","shell.execute_reply.started":"2021-10-22T18:08:09.458834Z","shell.execute_reply":"2021-10-22T18:08:10.085695Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_pred = np.zeros(targets.shape)","metadata":{"id":"qDsDMBnE9co3","execution":{"iopub.status.busy":"2021-10-22T18:08:10.088514Z","iopub.execute_input":"2021-10-22T18:08:10.089077Z","iopub.status.idle":"2021-10-22T18:08:10.093531Z","shell.execute_reply.started":"2021-10-22T18:08:10.089037Z","shell.execute_reply":"2021-10-22T18:08:10.092842Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#skip_folds = np.arange(1)\nskip_folds = []","metadata":{"id":"INtJvC7xfKdV","execution":{"iopub.status.busy":"2021-10-22T18:08:10.095791Z","iopub.execute_input":"2021-10-22T18:08:10.096285Z","iopub.status.idle":"2021-10-22T18:08:10.106787Z","shell.execute_reply.started":"2021-10-22T18:08:10.096247Z","shell.execute_reply":"2021-10-22T18:08:10.105964Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"with tpu_strategy.scope():\n    \n    VERBOSE = 0\n    EPOCHS = 200\n    FOLDS = 7\n    if DEBUG:\n      EPOCHS = 100\n    test_preds = []\n    kf = KFold(n_splits=FOLDS, shuffle=True, random_state=2021)\n    \n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        if len(test_preds) > fold:\n          print(f'Ignore corrent fold {fold+1} as we already predicted test data')\n\n        if DEBUG and fold > 0:\n          continue\n        X_train, X_valid = train[train_idx], train[test_idx]\n        y_train, y_valid = targets[train_idx], targets[test_idx]\n        \n        model = dnn_model()\n        model.compile(optimizer=\"adam\", loss=\"mae\")\n\n        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.75, \n                               patience=10, verbose=VERBOSE)\n        checkpoint_name = f'./model-gpu/Bidirect_LSTM_model_{fold+1}C.h5'\n        chk_point = ModelCheckpoint(checkpoint_name,\n                                    monitor='val_loss', verbose=VERBOSE, \n                                    save_best_only=True, mode='min')\n\n        es = EarlyStopping(monitor=\"val_loss\", patience=50, \n                           verbose=VERBOSE, mode=\"min\", \n                           restore_best_weights=True)\n        \n        if fold not in skip_folds:\n          model.fit(X_train, y_train, \n                    validation_data=(X_valid, y_valid), \n                    epochs=EPOCHS,\n                    verbose=VERBOSE,\n                    batch_size=BATCH_SIZE, \n                    callbacks=[lr, chk_point, es])\n        else:\n          print('Load pretrain weight from ', checkpoint_name)\n          load_locally = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\n          try:\n            # At loading time, register the custom objects with a `custom_object_scope`:\n            custom_objects = {\"ScaleLayer\": ScaleLayer}\n            with tf.keras.utils.custom_object_scope(custom_objects):\n                model = load_model(checkpoint_name, options=load_locally)\n          except (OSError):\n            print('Cannot load pretrain weight from ', checkpoint_name)\n            break\n                \n        y_true = y_valid.squeeze().reshape(-1, 1)\n        y_pred = model.predict(X_valid, batch_size=BATCH_SIZE).squeeze().reshape(-1, 1)\n        train_pred[test_idx] = y_pred.reshape(-1, 80)\n        score = mean_absolute_error(y_true, y_pred)\n        test_preds.append(model.predict(test, batch_size=BATCH_SIZE).squeeze().reshape(-1, 1).squeeze())\n\n        print(f\"Fold-{fold+1} | OOF Score: {score}\")\n        \n        del X_train, X_valid, y_train, y_valid, model\n        reset_keras()\n        gc.collect()\n","metadata":{"id":"SYJkCi1-9co3","execution":{"iopub.status.busy":"2021-10-22T18:08:10.108669Z","iopub.execute_input":"2021-10-22T18:08:10.109716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not DEBUG:\n  train_pred = train_pred.flatten()\n  targets = targets.flatten()\n  score = mean_absolute_error(targets, train_pred)\n  print(f\"Train Score: {score}\")","metadata":{"id":"fUanGPDq9co3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create submission file","metadata":{"id":"QHx2oF849co4"}},{"cell_type":"code","source":"if not DEBUG:\n  submission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n  submission[\"pressure\"] = sum(test_preds)/5\n  submission.to_csv('submission.csv', index=False)\n\n  # ENSEMBLE FOLDS WITH MEDIAN\n  #取中位数\n  submission[\"pressure\"] = np.median(np.vstack(test_preds),axis=0)\n  submission.to_csv('submission_median.csv', index=False)\n\n\n  # ENSEMBLE FOLDS WITH MEDIAN AND ROUND PREDICTIONS\n  submission[\"pressure\"] =\\\n      np.round( (submission.pressure - pressure_min)/pressure_step ) * pressure_step + pressure_min\n  submission.pressure = np.clip(submission.pressure, pressure_min, pressure_max)\n  submission.to_csv('submission_median_round.csv', index=False)","metadata":{"id":"tS9VjV7K9co4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"8lg88GUo4OCK"},"execution_count":null,"outputs":[]}]}