{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modification:\n",
    "    \n",
    "    Concate: CNN and BiLSTM in parallel\n",
    "\n",
    "Results:\n",
    "    \n",
    "    Median: 0.224\n",
    "    Median and round predtions: 0.223"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "3e5a0bd1-3e22-4b2c-a565-68985e55f95e",
    "_uuid": "e331dbcc-0346-4019-9ff6-b890154a878b",
    "execution": {
     "iopub.execute_input": "2021-10-12T22:50:19.115026Z",
     "iopub.status.busy": "2021-10-12T22:50:19.113235Z",
     "iopub.status.idle": "2021-10-12T22:50:26.340866Z",
     "shell.execute_reply": "2021-10-12T22:50:26.341459Z",
     "shell.execute_reply.started": "2021-10-12T20:58:51.640584Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 7.252589,
     "end_time": "2021-10-12T22:50:26.341763",
     "exception": false,
     "start_time": "2021-10-12T22:50:19.089174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import optuna\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.preprocessing import RobustScaler, normalize\n",
    "from sklearn.model_selection import train_test_split, GroupKFold, KFold\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "89eb257e-0ed2-4f8b-94d6-462a5e995eb1",
    "_uuid": "ca71d87d-6594-4f31-906d-0b53cd4c1374",
    "execution": {
     "iopub.execute_input": "2021-10-12T22:50:26.378989Z",
     "iopub.status.busy": "2021-10-12T22:50:26.377995Z",
     "iopub.status.idle": "2021-10-12T22:50:41.393062Z",
     "shell.execute_reply": "2021-10-12T22:50:41.392338Z",
     "shell.execute_reply.started": "2021-10-12T20:58:58.456739Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 15.034591,
     "end_time": "2021-10-12T22:50:41.393267",
     "exception": false,
     "start_time": "2021-10-12T22:50:26.358676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "train = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\n",
    "test = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\n",
    "submission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n",
    "\n",
    "if DEBUG:\n",
    "    train = train[:80*1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T22:50:41.436666Z",
     "iopub.status.busy": "2021-10-12T22:50:41.435896Z",
     "iopub.status.idle": "2021-10-12T22:50:41.507742Z",
     "shell.execute_reply": "2021-10-12T22:50:41.508291Z",
     "shell.execute_reply.started": "2021-10-12T20:59:14.074770Z"
    },
    "papermill": {
     "duration": 0.098144,
     "end_time": "2021-10-12T22:50:41.508491",
     "exception": false,
     "start_time": "2021-10-12T22:50:41.410347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_pressure = np.sort(train['pressure'].unique())\n",
    "pressure_min =  all_pressure[0].item()\n",
    "pressure_max = all_pressure[-1].item()\n",
    "pressure_step = (all_pressure[1] - all_pressure[0]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T22:50:41.546641Z",
     "iopub.status.busy": "2021-10-12T22:50:41.545845Z",
     "iopub.status.idle": "2021-10-12T22:50:41.556215Z",
     "shell.execute_reply": "2021-10-12T22:50:41.555673Z",
     "shell.execute_reply.started": "2021-10-12T20:59:14.157488Z"
    },
    "papermill": {
     "duration": 0.031541,
     "end_time": "2021-10-12T22:50:41.556370",
     "exception": false,
     "start_time": "2021-10-12T22:50:41.524829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.895744294564641"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "64.8209917386395"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.07030214545121005"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pressure_min)\n",
    "display(pressure_max)\n",
    "display(pressure_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021797,
     "end_time": "2021-10-12T22:50:41.599381",
     "exception": false,
     "start_time": "2021-10-12T22:50:41.577584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Engineer Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021348,
     "end_time": "2021-10-12T22:50:41.643411",
     "exception": false,
     "start_time": "2021-10-12T22:50:41.622063",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## From [Ventilator: Feature engineering](https://www.kaggle.com/mistag/ventilator-feature-engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "13a36b46-7067-4b29-aad3-7e3b15e8415b",
    "_uuid": "dc41dbf2-f199-4b9d-bbd9-bf6084162b47",
    "execution": {
     "iopub.execute_input": "2021-10-12T22:50:41.705879Z",
     "iopub.status.busy": "2021-10-12T22:50:41.695304Z",
     "iopub.status.idle": "2021-10-12T22:51:40.194565Z",
     "shell.execute_reply": "2021-10-12T22:51:40.193682Z",
     "shell.execute_reply.started": "2021-10-12T20:59:14.173719Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 58.533211,
     "end_time": "2021-10-12T22:51:40.194757",
     "exception": false,
     "start_time": "2021-10-12T22:50:41.661546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Feature engineering\n",
    "def add_features(df):\n",
    "    #time_step*u_in\n",
    "    df['area'] = df['time_step'] * df['u_in']\n",
    "    df['area'] = df.groupby('breath_id')['area'].cumsum()\n",
    "    \n",
    "    #sum of u_in\n",
    "    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n",
    "    \n",
    "    #shift +1 -1 +3 -3\n",
    "    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n",
    "    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n",
    "    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n",
    "    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n",
    "    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n",
    "    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n",
    "    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n",
    "    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n",
    "    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n",
    "    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n",
    "    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n",
    "    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n",
    "    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n",
    "    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n",
    "    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n",
    "    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n",
    "    df = df.fillna(0)\n",
    "         \n",
    "    df['u_in_first'] = df.groupby(['breath_id'])['u_in'].transform('first')\n",
    "    df['u_in_last'] = df.groupby(['breath_id'])['u_in'].transform('last')\n",
    "    \n",
    "    # max value of u_in and u_out for each breath\n",
    "    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n",
    "    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n",
    "   \n",
    "    # difference between consequitive values\n",
    "    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n",
    "    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n",
    "    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n",
    "    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n",
    "    \n",
    "    df.loc[train['time_step'] == 0, 'u_in_diff'] = 0\n",
    "    df.loc[train['time_step'] == 0, 'u_out_diff'] = 0\n",
    "    \n",
    "    # difference between the current value of u_in and the max value within the breath\n",
    "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
    "    # difference between the current value of u_in and the mean value within the breath\n",
    "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
    "    \n",
    "    # difference between consequitive values\n",
    "    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n",
    "    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n",
    "    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n",
    "    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n",
    "    \n",
    "    #u_in*u_out\n",
    "    df['cross']= df['u_in']*df['u_out']\n",
    "    \n",
    "    #time_step*u_out\n",
    "    df['cross2']= df['time_step']*df['u_out']\n",
    "    \n",
    "    df['R'] = df['R'].astype(str)\n",
    "    df['C'] = df['C'].astype(str)\n",
    "    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n",
    "    #one hot encoding\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "train = add_features(train)\n",
    "test = add_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T22:51:40.238544Z",
     "iopub.status.busy": "2021-10-12T22:51:40.237499Z",
     "iopub.status.idle": "2021-10-12T22:51:40.241705Z",
     "shell.execute_reply": "2021-10-12T22:51:40.241167Z",
     "shell.execute_reply.started": "2021-10-12T21:00:11.352344Z"
    },
    "papermill": {
     "duration": 0.028705,
     "end_time": "2021-10-12T22:51:40.241860",
     "exception": false,
     "start_time": "2021-10-12T22:51:40.213155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4024000, 56)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T22:51:40.284077Z",
     "iopub.status.busy": "2021-10-12T22:51:40.283306Z",
     "iopub.status.idle": "2021-10-12T22:51:41.348094Z",
     "shell.execute_reply": "2021-10-12T22:51:41.347502Z",
     "shell.execute_reply.started": "2021-10-12T21:00:11.361557Z"
    },
    "papermill": {
     "duration": 1.088406,
     "end_time": "2021-10-12T22:51:41.348236",
     "exception": false,
     "start_time": "2021-10-12T22:51:40.259830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "check_train_nan = train.isnull().sum().sum()\n",
    "check_test_nan = test.isnull().sum().sum()\n",
    "\n",
    "print(check_train_nan)\n",
    "print(check_test_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T22:51:41.392958Z",
     "iopub.status.busy": "2021-10-12T22:51:41.392272Z",
     "iopub.status.idle": "2021-10-12T22:51:41.413821Z",
     "shell.execute_reply": "2021-10-12T22:51:41.413139Z",
     "shell.execute_reply.started": "2021-10-12T21:00:12.416641Z"
    },
    "papermill": {
     "duration": 0.047521,
     "end_time": "2021-10-12T22:51:41.413968",
     "exception": false,
     "start_time": "2021-10-12T22:51:41.366447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "      <th>pressure</th>\n",
       "      <th>area</th>\n",
       "      <th>u_in_cumsum</th>\n",
       "      <th>u_in_lag1</th>\n",
       "      <th>u_out_lag1</th>\n",
       "      <th>...</th>\n",
       "      <th>C_50</th>\n",
       "      <th>R__C_20__10</th>\n",
       "      <th>R__C_20__20</th>\n",
       "      <th>R__C_20__50</th>\n",
       "      <th>R__C_50__10</th>\n",
       "      <th>R__C_50__20</th>\n",
       "      <th>R__C_50__50</th>\n",
       "      <th>R__C_5__10</th>\n",
       "      <th>R__C_5__20</th>\n",
       "      <th>R__C_5__50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0</td>\n",
       "      <td>5.837492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033652</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0</td>\n",
       "      <td>5.907794</td>\n",
       "      <td>0.618632</td>\n",
       "      <td>18.466375</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067514</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>0</td>\n",
       "      <td>7.876254</td>\n",
       "      <td>2.138333</td>\n",
       "      <td>40.975653</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  breath_id  time_step       u_in  u_out  pressure      area  \\\n",
       "0   1          1   0.000000   0.083334      0  5.837492  0.000000   \n",
       "1   2          1   0.033652  18.383041      0  5.907794  0.618632   \n",
       "2   3          1   0.067514  22.509278      0  7.876254  2.138333   \n",
       "\n",
       "   u_in_cumsum  u_in_lag1  u_out_lag1  ...  C_50  R__C_20__10  R__C_20__20  \\\n",
       "0     0.083334   0.000000         0.0  ...     1            0            0   \n",
       "1    18.466375   0.083334         0.0  ...     1            0            0   \n",
       "2    40.975653  18.383041         0.0  ...     1            0            0   \n",
       "\n",
       "   R__C_20__50  R__C_50__10  R__C_50__20  R__C_50__50  R__C_5__10  R__C_5__20  \\\n",
       "0            1            0            0            0           0           0   \n",
       "1            1            0            0            0           0           0   \n",
       "2            1            0            0            0           0           0   \n",
       "\n",
       "   R__C_5__50  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "\n",
       "[3 rows x 57 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "01328860-fa2a-421c-9e5f-ea0048246f98",
    "_uuid": "346bf2c0-96d2-4da5-8837-c0f820294a85",
    "execution": {
     "iopub.execute_input": "2021-10-12T22:51:42.175836Z",
     "iopub.status.busy": "2021-10-12T22:51:42.174709Z",
     "iopub.status.idle": "2021-10-12T22:51:42.712530Z",
     "shell.execute_reply": "2021-10-12T22:51:42.711976Z",
     "shell.execute_reply.started": "2021-10-12T21:00:12.447706Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.279363,
     "end_time": "2021-10-12T22:51:42.712691",
     "exception": false,
     "start_time": "2021-10-12T22:51:41.433328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = train[['pressure']].to_numpy().reshape(-1, 80)\n",
    "train.drop(['pressure', 'id', 'breath_id'], axis=1, inplace=True)\n",
    "test = test.drop(['id', 'breath_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T22:51:42.753454Z",
     "iopub.status.busy": "2021-10-12T22:51:42.752781Z",
     "iopub.status.idle": "2021-10-12T22:51:53.853117Z",
     "shell.execute_reply": "2021-10-12T22:51:53.852440Z",
     "shell.execute_reply.started": "2021-10-12T21:00:13.682221Z"
    },
    "papermill": {
     "duration": 11.121998,
     "end_time": "2021-10-12T22:51:53.853264",
     "exception": false,
     "start_time": "2021-10-12T22:51:42.731266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Normalise the dataset\n",
    "RS = RobustScaler()\n",
    "train = RS.fit_transform(train)\n",
    "test = RS.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T22:51:53.895994Z",
     "iopub.status.busy": "2021-10-12T22:51:53.894033Z",
     "iopub.status.idle": "2021-10-12T22:51:53.898852Z",
     "shell.execute_reply": "2021-10-12T22:51:53.898287Z",
     "shell.execute_reply.started": "2021-10-12T21:00:24.422284Z"
    },
    "papermill": {
     "duration": 0.026975,
     "end_time": "2021-10-12T22:51:53.898993",
     "exception": false,
     "start_time": "2021-10-12T22:51:53.872018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Reshape group to 80 timesteps for each breath ID\n",
    "train = train.reshape(-1, 80, train.shape[-1])\n",
    "test = test.reshape(-1, 80, train.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018324,
     "end_time": "2021-10-12T22:51:53.936054",
     "exception": false,
     "start_time": "2021-10-12T22:51:53.917730",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019072,
     "end_time": "2021-10-12T22:51:53.973846",
     "exception": false,
     "start_time": "2021-10-12T22:51:53.954774",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## From [Rescaling layer for discrete output in TensorFlow](https://www.kaggle.com/lucamassaron/rescaling-layer-for-discrete-output-in-tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018338,
     "end_time": "2021-10-12T22:51:54.011046",
     "exception": false,
     "start_time": "2021-10-12T22:51:53.992708",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Please notice the custom rounding round_with_gradients function since tf.round has no gradients and it won't be differentiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T22:51:54.058759Z",
     "iopub.status.busy": "2021-10-12T22:51:54.057878Z",
     "iopub.status.idle": "2021-10-12T22:51:54.060898Z",
     "shell.execute_reply": "2021-10-12T22:51:54.060292Z",
     "shell.execute_reply.started": "2021-10-12T21:00:24.428306Z"
    },
    "papermill": {
     "duration": 0.031369,
     "end_time": "2021-10-12T22:51:54.061043",
     "exception": false,
     "start_time": "2021-10-12T22:51:54.029674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def round_with_gradients(x):\n",
    "    def grad(dy):\n",
    "        return dy\n",
    "    return tf.round(x), grad\n",
    "\n",
    "class ScaleLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(ScaleLayer, self).__init__()\n",
    "        self.min = tf.constant(pressure_min, dtype=np.float32)\n",
    "        self.max = tf.constant(pressure_max, dtype=np.float32)\n",
    "        self.step = tf.constant(pressure_step, dtype=np.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        steps = tf.math.divide(tf.math.add(inputs, -self.min), self.step)\n",
    "        int_steps = round_with_gradients(steps)\n",
    "        rescaled_steps = tf.math.add(tf.math.multiply(int_steps, self.step), self.min)\n",
    "        clipped = tf.clip_by_value(rescaled_steps, self.min, self.max)\n",
    "        return clipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01833,
     "end_time": "2021-10-12T22:51:54.099242",
     "exception": false,
     "start_time": "2021-10-12T22:51:54.080912",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T22:51:54.141056Z",
     "iopub.status.busy": "2021-10-12T22:51:54.140308Z",
     "iopub.status.idle": "2021-10-13T01:34:15.223383Z",
     "shell.execute_reply": "2021-10-13T01:34:15.222643Z"
    },
    "papermill": {
     "duration": 9741.106527,
     "end_time": "2021-10-13T01:34:15.224536",
     "exception": false,
     "start_time": "2021-10-12T22:51:54.118009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- > Fold 1 < ---------------\n",
      "CNN: (None, 72, 256)\n",
      "LSTM: (None, 80, 256)\n",
      "Com: (None, 152, 256)\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 26s 202ms/step - loss: 3.6608 - val_loss: 0.8302\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.83021, saving model to folds0.hdf5\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.7632 - val_loss: 0.6312\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.83021 to 0.63115, saving model to folds0.hdf5\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.6275 - val_loss: 0.5968\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.63115 to 0.59682, saving model to folds0.hdf5\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.5580 - val_loss: 0.5181\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.59682 to 0.51810, saving model to folds0.hdf5\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.5036 - val_loss: 0.5242\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.51810\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4998 - val_loss: 0.4686\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.51810 to 0.46864, saving model to folds0.hdf5\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4548 - val_loss: 0.4528\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.46864 to 0.45276, saving model to folds0.hdf5\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4494 - val_loss: 0.4574\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45276\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4359 - val_loss: 0.4271\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.45276 to 0.42714, saving model to folds0.hdf5\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4282 - val_loss: 0.4111\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.42714 to 0.41105, saving model to folds0.hdf5\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4069 - val_loss: 0.4158\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.41105\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4043 - val_loss: 0.4000\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.41105 to 0.40003, saving model to folds0.hdf5\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3935 - val_loss: 0.4120\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.40003\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3882 - val_loss: 0.4135\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.40003\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3887 - val_loss: 0.3889\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.40003 to 0.38895, saving model to folds0.hdf5\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3791 - val_loss: 0.3769\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.38895 to 0.37686, saving model to folds0.hdf5\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3659 - val_loss: 0.3656\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.37686 to 0.36562, saving model to folds0.hdf5\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3834 - val_loss: 0.3652\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.36562 to 0.36522, saving model to folds0.hdf5\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3527 - val_loss: 0.3766\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.36522\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3622 - val_loss: 0.3685\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.36522\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3523 - val_loss: 0.3895\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.36522\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3535 - val_loss: 0.3607\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.36522 to 0.36071, saving model to folds0.hdf5\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3437 - val_loss: 0.3435\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.36071 to 0.34352, saving model to folds0.hdf5\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3364 - val_loss: 0.4040\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.34352\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3502 - val_loss: 0.3491\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.34352\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3278 - val_loss: 0.3478\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.34352\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3363 - val_loss: 0.3295\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.34352 to 0.32953, saving model to folds0.hdf5\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3231 - val_loss: 0.3909\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.32953\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3375 - val_loss: 0.3352\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.32953\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3208 - val_loss: 0.3493\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.32953\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3223 - val_loss: 0.3263\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.32953 to 0.32629, saving model to folds0.hdf5\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3087 - val_loss: 0.3198\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.32629 to 0.31984, saving model to folds0.hdf5\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.3154 - val_loss: 0.3432\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.31984\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3092 - val_loss: 0.3233\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.31984\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3070 - val_loss: 0.3449\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.31984\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3089 - val_loss: 0.3286\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.31984\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3055 - val_loss: 0.3131\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.31984 to 0.31310, saving model to folds0.hdf5\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2983 - val_loss: 0.3289\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.31310\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3022 - val_loss: 0.3190\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.31310\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2930 - val_loss: 0.3113\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.31310 to 0.31127, saving model to folds0.hdf5\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2856 - val_loss: 0.3065\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.31127 to 0.30647, saving model to folds0.hdf5\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2872 - val_loss: 0.3170\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.30647\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2887 - val_loss: 0.3117\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.30647\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2823 - val_loss: 0.3088\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.30647\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2837 - val_loss: 0.3101\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.30647\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2835 - val_loss: 0.3039\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.30647 to 0.30392, saving model to folds0.hdf5\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2809 - val_loss: 0.2966\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.30392 to 0.29661, saving model to folds0.hdf5\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2742 - val_loss: 0.3057\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.29661\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2754 - val_loss: 0.3037\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.29661\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2764 - val_loss: 0.2986\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.29661\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2697 - val_loss: 0.3057\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.29661\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2731 - val_loss: 0.3173\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.29661\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2748 - val_loss: 0.2865\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.29661 to 0.28650, saving model to folds0.hdf5\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2704 - val_loss: 0.2936\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.28650\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2673 - val_loss: 0.2926\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.28650\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2657 - val_loss: 0.2865\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.28650 to 0.28645, saving model to folds0.hdf5\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2591 - val_loss: 0.2843\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.28645 to 0.28428, saving model to folds0.hdf5\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2617 - val_loss: 0.2852\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.28428\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2588 - val_loss: 0.2872\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.28428\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2567 - val_loss: 0.2820\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.28428 to 0.28201, saving model to folds0.hdf5\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2562 - val_loss: 0.2914\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.28201\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2579 - val_loss: 0.2772\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.28201 to 0.27716, saving model to folds0.hdf5\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007387921, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2531 - val_loss: 0.2923\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.27716\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to tf.Tensor(0.00073519343, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2546 - val_loss: 0.2849\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.27716\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007316123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2550 - val_loss: 0.2811\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.27716\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007280487, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2491 - val_loss: 0.2756\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.27716 to 0.27557, saving model to folds0.hdf5\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007245024, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2475 - val_loss: 0.2773\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.27557\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007209733, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2482 - val_loss: 0.2714\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.27557 to 0.27144, saving model to folds0.hdf5\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071746146, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2432 - val_loss: 0.2887\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.27144\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007139667, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2486 - val_loss: 0.2721\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.27144\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071048894, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2411 - val_loss: 0.2892\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.27144\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007070282, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2513 - val_loss: 0.2723\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.27144\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007035842, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.2363 - val_loss: 0.2698\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.27144 to 0.26977, saving model to folds0.hdf5\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to tf.Tensor(0.00070015714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2390 - val_loss: 0.2744\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.26977\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006967467, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2428 - val_loss: 0.2739\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.26977\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to tf.Tensor(0.00069335283, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2419 - val_loss: 0.2853\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.26977\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006899755, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2371 - val_loss: 0.2679\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.26977 to 0.26795, saving model to folds0.hdf5\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068661466, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2333 - val_loss: 0.2769\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.26795\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068327016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2321 - val_loss: 0.2654\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.26795 to 0.26543, saving model to folds0.hdf5\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067994196, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2268 - val_loss: 0.2750\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.26543\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067663, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2313 - val_loss: 0.2647\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.26543 to 0.26475, saving model to folds0.hdf5\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006733342, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2302 - val_loss: 0.2754\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.26475\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067005435, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2299 - val_loss: 0.2590\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.26475 to 0.25899, saving model to folds0.hdf5\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006667905, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2244 - val_loss: 0.2668\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.25899\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006635426, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2250 - val_loss: 0.2590\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.25899\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006603105, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2219 - val_loss: 0.2619\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.25899\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006570942, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2279 - val_loss: 0.2682\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.25899\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065389345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2237 - val_loss: 0.2566\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.25899 to 0.25662, saving model to folds0.hdf5\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065070833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2196 - val_loss: 0.2565\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.25662 to 0.25653, saving model to folds0.hdf5\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to tf.Tensor(0.00064753875, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2165 - val_loss: 0.2644\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.25653\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006443846, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2218 - val_loss: 0.2547\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.25653 to 0.25469, saving model to folds0.hdf5\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006412458, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2189 - val_loss: 0.2582\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.25469\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063812226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2198 - val_loss: 0.2550\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.25469\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063501403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2229 - val_loss: 0.2507\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.25469 to 0.25067, saving model to folds0.hdf5\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006319209, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2141 - val_loss: 0.2581\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.25067\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006288428, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2170 - val_loss: 0.2516\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.25067\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to tf.Tensor(0.00062577974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2149 - val_loss: 0.2528\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.25067\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006227316, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2128 - val_loss: 0.2535\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.25067\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061969826, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2119 - val_loss: 0.2505\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.25067 to 0.25048, saving model to folds0.hdf5\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 00100: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006166797, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2104 - val_loss: 0.2593\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.25048\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 00101: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061367586, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2097 - val_loss: 0.2510\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.25048\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 00102: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061068666, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2123 - val_loss: 0.2482\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.25048 to 0.24823, saving model to folds0.hdf5\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 00103: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006077121, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2110 - val_loss: 0.2526\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.24823\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 00104: LearningRateScheduler reducing learning rate to tf.Tensor(0.00060475187, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2091 - val_loss: 0.2469\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.24823 to 0.24689, saving model to folds0.hdf5\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 00105: LearningRateScheduler reducing learning rate to tf.Tensor(0.00060180615, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2076 - val_loss: 0.2545\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.24689\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 00106: LearningRateScheduler reducing learning rate to tf.Tensor(0.00059887476, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2093 - val_loss: 0.2482\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.24689\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 00107: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005959577, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2028 - val_loss: 0.2460\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.24689 to 0.24597, saving model to folds0.hdf5\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 00108: LearningRateScheduler reducing learning rate to tf.Tensor(0.00059305475, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2033 - val_loss: 0.2442\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.24597 to 0.24425, saving model to folds0.hdf5\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 00109: LearningRateScheduler reducing learning rate to tf.Tensor(0.000590166, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2028 - val_loss: 0.2571\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.24425\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 00110: LearningRateScheduler reducing learning rate to tf.Tensor(0.00058729126, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.2044 - val_loss: 0.2539\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.24425\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 00111: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005844306, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2085 - val_loss: 0.2405\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.24425 to 0.24053, saving model to folds0.hdf5\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 00112: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005815838, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1990 - val_loss: 0.2403\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.24053 to 0.24033, saving model to folds0.hdf5\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 00113: LearningRateScheduler reducing learning rate to tf.Tensor(0.000578751, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1983 - val_loss: 0.2438\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.24033\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 00114: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057593186, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1989 - val_loss: 0.2408\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.24033\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 00115: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057312654, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2011 - val_loss: 0.2492\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.24033\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 00116: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057033484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2018 - val_loss: 0.2462\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.24033\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 00117: LearningRateScheduler reducing learning rate to tf.Tensor(0.00056755677, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1972 - val_loss: 0.2420\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.24033\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 00118: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005647922, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1970 - val_loss: 0.2475\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.24033\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 00119: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005620411, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1979 - val_loss: 0.2557\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.24033\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 00120: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055930344, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1996 - val_loss: 0.2425\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.24033\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 00121: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055657903, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1930 - val_loss: 0.2458\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.24033\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 00122: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055386795, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1963 - val_loss: 0.2467\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.24033\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 00123: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005511701, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1923 - val_loss: 0.2385\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.24033 to 0.23847, saving model to folds0.hdf5\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 00124: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005484854, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1940 - val_loss: 0.2385\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.23847 to 0.23846, saving model to folds0.hdf5\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 00125: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005458137, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1905 - val_loss: 0.2369\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.23846 to 0.23686, saving model to folds0.hdf5\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 00126: LearningRateScheduler reducing learning rate to tf.Tensor(0.00054315507, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1915 - val_loss: 0.2346\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.23686 to 0.23458, saving model to folds0.hdf5\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 00127: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005405093, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1894 - val_loss: 0.2419\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.23458\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 00128: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005378765, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1918 - val_loss: 0.2380\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.23458\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 00129: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005352565, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1892 - val_loss: 0.2368\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.23458\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 00130: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005326493, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1873 - val_loss: 0.2404\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.23458\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 00131: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005300548, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1907 - val_loss: 0.2367\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.23458\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 00132: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005274729, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1883 - val_loss: 0.2395\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.23458\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 00133: LearningRateScheduler reducing learning rate to tf.Tensor(0.00052490365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1979 - val_loss: 0.2325\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.23458 to 0.23254, saving model to folds0.hdf5\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 00134: LearningRateScheduler reducing learning rate to tf.Tensor(0.00052234676, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1857 - val_loss: 0.2349\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.23254\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 00135: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005198025, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1848 - val_loss: 0.2333\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.23254\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 00136: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005172705, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1863 - val_loss: 0.2354\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.23254\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 00137: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051475083, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1830 - val_loss: 0.2357\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.23254\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 00138: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051224354, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1858 - val_loss: 0.2330\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.23254\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 00139: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005097484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1791 - val_loss: 0.2314\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.23254 to 0.23139, saving model to folds0.hdf5\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 00140: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005072654, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1815 - val_loss: 0.2313\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.23139 to 0.23134, saving model to folds0.hdf5\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 00141: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005047946, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1819 - val_loss: 0.2290\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.23134 to 0.22895, saving model to folds0.hdf5\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 00142: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005023357, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1807 - val_loss: 0.2326\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.22895\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 00143: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049988885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1808 - val_loss: 0.2366\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.22895\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 00144: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004974539, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1804 - val_loss: 0.2339\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.22895\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 00145: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004950308, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1783 - val_loss: 0.2331\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.22895\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 00146: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004926195, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1808 - val_loss: 0.2324\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.22895\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 00147: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049022, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1775 - val_loss: 0.2318\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.22895\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 00148: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048783212, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.1784 - val_loss: 0.2301\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.22895\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 00149: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048545588, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1785 - val_loss: 0.2319\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.22895\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 00150: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048309125, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1774 - val_loss: 0.2305\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.22895\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 00151: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048073815, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1757 - val_loss: 0.2277\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.22895 to 0.22770, saving model to folds0.hdf5\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 00152: LearningRateScheduler reducing learning rate to tf.Tensor(0.00047839645, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1750 - val_loss: 0.2293\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.22770\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 00153: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004760662, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1737 - val_loss: 0.2296\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.22770\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 00154: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004737473, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1799 - val_loss: 0.2322\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.22770\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 00155: LearningRateScheduler reducing learning rate to tf.Tensor(0.00047143968, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1774 - val_loss: 0.2290\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.22770\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 00156: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004691433, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1735 - val_loss: 0.2295\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.22770\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 00157: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046685815, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1751 - val_loss: 0.2284\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.22770\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 00158: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046458407, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1721 - val_loss: 0.2278\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.22770\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 00159: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046232107, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1736 - val_loss: 0.2288\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.22770\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 00160: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046006907, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1737 - val_loss: 0.2265\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.22770 to 0.22651, saving model to folds0.hdf5\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 00161: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045782814, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1725 - val_loss: 0.2303\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.22651\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 00162: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045559806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1718 - val_loss: 0.2292\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.22651\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 00163: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045337883, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1712 - val_loss: 0.2296\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.22651\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 00164: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045117046, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1714 - val_loss: 0.2272\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.22651\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 00165: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044897277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1700 - val_loss: 0.2269\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.22651\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 00166: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044678585, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1726 - val_loss: 0.2306\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.22651\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 00167: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004446096, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1711 - val_loss: 0.2292\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.22651\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 00168: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004424439, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1698 - val_loss: 0.2298\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.22651\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 00169: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044028874, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1711 - val_loss: 0.2336\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.22651\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 00170: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043814414, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1708 - val_loss: 0.2248\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.22651 to 0.22483, saving model to folds0.hdf5\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 00171: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043600993, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1670 - val_loss: 0.2256\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.22483\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 00172: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043388613, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1653 - val_loss: 0.2235\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.22483 to 0.22345, saving model to folds0.hdf5\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 00173: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004317727, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1647 - val_loss: 0.2254\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.22345\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 00174: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004296695, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1632 - val_loss: 0.2240\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.22345\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 00175: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004275766, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1646 - val_loss: 0.2290\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.22345\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 00176: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042549393, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1669 - val_loss: 0.2230\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.22345 to 0.22296, saving model to folds0.hdf5\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 00177: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042342133, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1649 - val_loss: 0.2243\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.22296\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 00178: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042135885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1659 - val_loss: 0.2356\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.22296\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 00179: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041930642, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1678 - val_loss: 0.2262\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.22296\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 00180: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041726397, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1671 - val_loss: 0.2233\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.22296\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 00181: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041523148, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1623 - val_loss: 0.2256\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.22296\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 00182: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041320888, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1632 - val_loss: 0.2264\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.22296\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 00183: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041119618, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1623 - val_loss: 0.2226\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.22296 to 0.22261, saving model to folds0.hdf5\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 00184: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040919325, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1631 - val_loss: 0.2228\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.22261\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 00185: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040720004, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1625 - val_loss: 0.2237\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.22261\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 00186: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004052166, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1600 - val_loss: 0.2219\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.22261 to 0.22189, saving model to folds0.hdf5\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 00187: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004032428, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1621 - val_loss: 0.2225\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.22189\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 00188: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004012786, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1592 - val_loss: 0.2259\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.22189\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 00189: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039932402, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1604 - val_loss: 0.2323\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.22189\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 00190: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039737887, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1619 - val_loss: 0.2225\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.22189\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 00191: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039544326, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1579 - val_loss: 0.2251\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.22189\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 00192: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039351705, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1578 - val_loss: 0.2237\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.22189\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 00193: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039160028, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1573 - val_loss: 0.2231\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.22189\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 00194: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038969278, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1598 - val_loss: 0.2200\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.22189 to 0.22002, saving model to folds0.hdf5\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 00195: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003877946, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1556 - val_loss: 0.2245\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.22002\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 00196: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038590565, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1574 - val_loss: 0.2213\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.22002\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 00197: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003840259, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1587 - val_loss: 0.2221\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.22002\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 00198: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038215535, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1547 - val_loss: 0.2262\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.22002\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 00199: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038029387, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1577 - val_loss: 0.2227\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.22002\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 00200: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037844144, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.1563 - val_loss: 0.2218\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.22002\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 00201: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037659804, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1555 - val_loss: 0.2228\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.22002\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 00202: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037476368, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1552 - val_loss: 0.2213\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.22002\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 00203: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037293817, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1535 - val_loss: 0.2204\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.22002\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 00204: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003711216, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1549 - val_loss: 0.2220\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.22002\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 00205: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003693139, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1530 - val_loss: 0.2221\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.22002\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 00206: LearningRateScheduler reducing learning rate to tf.Tensor(0.000367515, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1570 - val_loss: 0.2191\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.22002 to 0.21913, saving model to folds0.hdf5\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 00207: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036572482, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1531 - val_loss: 0.2202\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.21913\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 00208: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003639434, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1534 - val_loss: 0.2208\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.21913\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 00209: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036217063, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1538 - val_loss: 0.2220\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.21913\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 00210: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036040647, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1554 - val_loss: 0.2208\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.21913\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 00211: LearningRateScheduler reducing learning rate to tf.Tensor(0.00035865093, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1531 - val_loss: 0.2219\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.21913\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 00212: LearningRateScheduler reducing learning rate to tf.Tensor(0.000356904, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1522 - val_loss: 0.2253\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.21913\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 00213: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003551655, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1550 - val_loss: 0.2203\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.21913\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 00214: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003534355, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1522 - val_loss: 0.2204\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.21913\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 00215: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003517139, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1513 - val_loss: 0.2213\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.21913\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 00216: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003500007, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1517 - val_loss: 0.2205\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.21913\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 00217: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034829587, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1503 - val_loss: 0.2223\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.21913\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 00218: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034659932, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1506 - val_loss: 0.2195\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.21913\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 00219: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034491107, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1494 - val_loss: 0.2192\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.21913\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 00220: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034323102, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1487 - val_loss: 0.2196\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.21913\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 00221: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034155912, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1494 - val_loss: 0.2202\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.21913\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 00222: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033989537, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1500 - val_loss: 0.2190\n",
      "\n",
      "Epoch 00222: val_loss improved from 0.21913 to 0.21897, saving model to folds0.hdf5\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 00223: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033823974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1515 - val_loss: 0.2193\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.21897\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 00224: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003365922, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1486 - val_loss: 0.2192\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.21897\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 00225: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033495267, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1484 - val_loss: 0.2189\n",
      "\n",
      "Epoch 00225: val_loss improved from 0.21897 to 0.21889, saving model to folds0.hdf5\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 00226: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003333211, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1483 - val_loss: 0.2198\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.21889\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 00227: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033169755, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1471 - val_loss: 0.2201\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.21889\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 00228: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033008185, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1501 - val_loss: 0.2186\n",
      "\n",
      "Epoch 00228: val_loss improved from 0.21889 to 0.21860, saving model to folds0.hdf5\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 00229: LearningRateScheduler reducing learning rate to tf.Tensor(0.000328474, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1468 - val_loss: 0.2182\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.21860 to 0.21818, saving model to folds0.hdf5\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 00230: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032687403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1463 - val_loss: 0.2195\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.21818\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 00231: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003252818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1471 - val_loss: 0.2180\n",
      "\n",
      "Epoch 00231: val_loss improved from 0.21818 to 0.21803, saving model to folds0.hdf5\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 00232: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032369737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1451 - val_loss: 0.2182\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.21803\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 00233: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032212064, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1464 - val_loss: 0.2183\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.21803\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 00234: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032055163, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1445 - val_loss: 0.2187\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.21803\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 00235: LearningRateScheduler reducing learning rate to tf.Tensor(0.00031899018, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 52ms/step - loss: 0.1467 - val_loss: 0.2187\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.21803\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 00236: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003174364, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1466 - val_loss: 0.2195\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.21803\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 00237: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003158902, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1453 - val_loss: 0.2188\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.21803\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 00238: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003143515, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1447 - val_loss: 0.2185\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.21803\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 00239: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003128203, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1441 - val_loss: 0.2178\n",
      "\n",
      "Epoch 00239: val_loss improved from 0.21803 to 0.21782, saving model to folds0.hdf5\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 00240: LearningRateScheduler reducing learning rate to tf.Tensor(0.00031129655, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1464 - val_loss: 0.2210\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.21782\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 00241: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003097802, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1465 - val_loss: 0.2188\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.21782\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 00242: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003082713, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1451 - val_loss: 0.2185\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.21782\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 00243: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003067697, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1446 - val_loss: 0.2189\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.21782\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 00244: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030527546, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1439 - val_loss: 0.2179\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.21782\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 00245: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030378843, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1423 - val_loss: 0.2216\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.21782\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 00246: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003023087, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1445 - val_loss: 0.2167\n",
      "\n",
      "Epoch 00246: val_loss improved from 0.21782 to 0.21668, saving model to folds0.hdf5\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 00247: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030083617, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1422 - val_loss: 0.2172\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.21668\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 00248: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002993708, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1413 - val_loss: 0.2175\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.21668\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 00249: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029791257, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1425 - val_loss: 0.2216\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.21668\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 00250: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029646145, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1423 - val_loss: 0.2171\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.21668\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 00251: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029501738, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1428 - val_loss: 0.2177\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.21668\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 00252: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029358038, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1415 - val_loss: 0.2179\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.21668\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 00253: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029215033, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1414 - val_loss: 0.2189\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.21668\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 00254: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029072727, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1406 - val_loss: 0.2178\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.21668\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 00255: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028931117, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1402 - val_loss: 0.2189\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.21668\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 00256: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028790193, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1412 - val_loss: 0.2172\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.21668\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 00257: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028649953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1404 - val_loss: 0.2167\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.21668\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 00258: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028510403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1421 - val_loss: 0.2182\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.21668\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 00259: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002837153, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1415 - val_loss: 0.2167\n",
      "\n",
      "Epoch 00259: val_loss improved from 0.21668 to 0.21667, saving model to folds0.hdf5\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 00260: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002823333, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1394 - val_loss: 0.2170\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.21667\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 00261: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028095808, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1381 - val_loss: 0.2159\n",
      "\n",
      "Epoch 00261: val_loss improved from 0.21667 to 0.21587, saving model to folds0.hdf5\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 00262: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027958953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1380 - val_loss: 0.2157\n",
      "\n",
      "Epoch 00262: val_loss improved from 0.21587 to 0.21574, saving model to folds0.hdf5\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 00263: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027822764, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1379 - val_loss: 0.2169\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.21574\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 00264: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027687242, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1384 - val_loss: 0.2161\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.21574\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 00265: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027552375, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1382 - val_loss: 0.2159\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.21574\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 00266: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002741817, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1389 - val_loss: 0.2155\n",
      "\n",
      "Epoch 00266: val_loss improved from 0.21574 to 0.21545, saving model to folds0.hdf5\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 00267: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027284614, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1376 - val_loss: 0.2168\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.21545\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 00268: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027151714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1380 - val_loss: 0.2197\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.21545\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 00269: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027019458, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1383 - val_loss: 0.2166\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.21545\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 00270: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026887844, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1385 - val_loss: 0.2156\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.21545\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 00271: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026756877, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1371 - val_loss: 0.2181\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.21545\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 00272: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026626544, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1389 - val_loss: 0.2165\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.21545\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 00273: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026496846, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1365 - val_loss: 0.2165\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.21545\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 00274: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026367782, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1380 - val_loss: 0.2187\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.21545\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 00275: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026239344, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1381 - val_loss: 0.2163\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.21545\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 00276: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026111532, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1366 - val_loss: 0.2166\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.21545\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 00277: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025984345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1359 - val_loss: 0.2192\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.21545\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 00278: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025857775, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1358 - val_loss: 0.2153\n",
      "\n",
      "Epoch 00278: val_loss improved from 0.21545 to 0.21533, saving model to folds0.hdf5\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 00279: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002573182, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1356 - val_loss: 0.2163\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.21533\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 00280: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025606484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1359 - val_loss: 0.2160\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.21533\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 00281: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025481754, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 50ms/step - loss: 0.1352 - val_loss: 0.2154\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.21533\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 00282: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025357632, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1339 - val_loss: 0.2172\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.21533\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 00283: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025234115, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1338 - val_loss: 0.2170\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.21533\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 00284: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025111204, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1348 - val_loss: 0.2163\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.21533\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 00285: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024988884, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1351 - val_loss: 0.2154\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.21533\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 00286: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024867163, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1354 - val_loss: 0.2152\n",
      "\n",
      "Epoch 00286: val_loss improved from 0.21533 to 0.21524, saving model to folds0.hdf5\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 00287: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024746038, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1345 - val_loss: 0.2162\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.21524\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 00288: LearningRateScheduler reducing learning rate to tf.Tensor(0.000246255, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1347 - val_loss: 0.2165\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.21524\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 00289: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024505547, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1329 - val_loss: 0.2158\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.21524\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 00290: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024386184, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1323 - val_loss: 0.2157\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.21524\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 00291: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024267398, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1332 - val_loss: 0.2149\n",
      "\n",
      "Epoch 00291: val_loss improved from 0.21524 to 0.21486, saving model to folds0.hdf5\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 00292: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024149191, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1322 - val_loss: 0.2160\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.21486\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 00293: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024031562, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1325 - val_loss: 0.2157\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.21486\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 00294: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023914504, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1325 - val_loss: 0.2175\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.21486\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 00295: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023798017, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1326 - val_loss: 0.2167\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.21486\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 00296: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023682097, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1330 - val_loss: 0.2153\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.21486\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 00297: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023566742, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1325 - val_loss: 0.2147\n",
      "\n",
      "Epoch 00297: val_loss improved from 0.21486 to 0.21466, saving model to folds0.hdf5\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 00298: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023451951, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1315 - val_loss: 0.2167\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.21466\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 00299: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023337714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1314 - val_loss: 0.2164\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.21466\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 00300: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023224037, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1319 - val_loss: 0.2150\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.21466\n",
      "(50300, 80)\n",
      "--------------- > Fold 2 < ---------------\n",
      "CNN: (None, 72, 256)\n",
      "LSTM: (None, 80, 256)\n",
      "Com: (None, 152, 256)\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 26s 208ms/step - loss: 3.5199 - val_loss: 0.8945\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.89449, saving model to folds1.hdf5\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.8079 - val_loss: 0.6500\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.89449 to 0.65003, saving model to folds1.hdf5\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.6147 - val_loss: 0.5308\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65003 to 0.53082, saving model to folds1.hdf5\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.5459 - val_loss: 0.5665\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.53082\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.5118 - val_loss: 0.5222\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.53082 to 0.52223, saving model to folds1.hdf5\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4823 - val_loss: 0.5330\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.52223\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4703 - val_loss: 0.4404\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.52223 to 0.44038, saving model to folds1.hdf5\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4435 - val_loss: 0.4253\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.44038 to 0.42526, saving model to folds1.hdf5\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4260 - val_loss: 0.4103\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.42526 to 0.41035, saving model to folds1.hdf5\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4256 - val_loss: 0.4196\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.41035\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4121 - val_loss: 0.4042\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.41035 to 0.40418, saving model to folds1.hdf5\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4040 - val_loss: 0.4091\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.40418\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4194 - val_loss: 0.3848\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.40418 to 0.38483, saving model to folds1.hdf5\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3886 - val_loss: 0.3865\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.38483\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3831 - val_loss: 0.3734\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.38483 to 0.37343, saving model to folds1.hdf5\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3762 - val_loss: 0.3725\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.37343 to 0.37246, saving model to folds1.hdf5\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3730 - val_loss: 0.4025\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.37246\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3690 - val_loss: 0.3682\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.37246 to 0.36824, saving model to folds1.hdf5\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3726 - val_loss: 0.3755\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.36824\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3551 - val_loss: 0.3551\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.36824 to 0.35515, saving model to folds1.hdf5\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3422 - val_loss: 0.3670\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.35515\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3515 - val_loss: 0.3416\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.35515 to 0.34160, saving model to folds1.hdf5\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3409 - val_loss: 0.3485\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.34160\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3358 - val_loss: 0.4002\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.34160\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3454 - val_loss: 0.3504\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.34160\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3257 - val_loss: 0.3378\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.34160 to 0.33780, saving model to folds1.hdf5\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3300 - val_loss: 0.3445\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33780\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3236 - val_loss: 0.3494\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33780\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3269 - val_loss: 0.3275\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.33780 to 0.32754, saving model to folds1.hdf5\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3194 - val_loss: 0.3287\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.32754\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3132 - val_loss: 0.3316\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.32754\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3203 - val_loss: 0.3192\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.32754 to 0.31918, saving model to folds1.hdf5\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3084 - val_loss: 0.3399\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.31918\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3137 - val_loss: 0.3242\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.31918\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3225 - val_loss: 0.3258\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.31918\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3068 - val_loss: 0.3201\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.31918\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3093 - val_loss: 0.3437\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.31918\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3005 - val_loss: 0.3121\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.31918 to 0.31205, saving model to folds1.hdf5\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3182 - val_loss: 0.3088\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.31205 to 0.30885, saving model to folds1.hdf5\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2927 - val_loss: 0.3081\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.30885 to 0.30811, saving model to folds1.hdf5\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.2965 - val_loss: 0.3218\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.30811\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2907 - val_loss: 0.3038\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.30811 to 0.30380, saving model to folds1.hdf5\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2849 - val_loss: 0.2989\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.30380 to 0.29887, saving model to folds1.hdf5\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2887 - val_loss: 0.3036\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.29887\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2782 - val_loss: 0.2925\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.29887 to 0.29245, saving model to folds1.hdf5\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2810 - val_loss: 0.3157\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.29245\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2902 - val_loss: 0.3240\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.29245\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2887 - val_loss: 0.3031\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.29245\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2790 - val_loss: 0.3101\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.29245\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2792 - val_loss: 0.2988\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.29245\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2734 - val_loss: 0.3018\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.29245\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2751 - val_loss: 0.3045\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.29245\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2798 - val_loss: 0.2862\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.29245 to 0.28618, saving model to folds1.hdf5\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2734 - val_loss: 0.2837\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.28618 to 0.28375, saving model to folds1.hdf5\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2712 - val_loss: 0.2942\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.28375\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2756 - val_loss: 0.2849\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.28375\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2645 - val_loss: 0.2920\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.28375\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2611 - val_loss: 0.2807\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.28375 to 0.28067, saving model to folds1.hdf5\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2557 - val_loss: 0.2864\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.28067\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2572 - val_loss: 0.2821\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.28067\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2600 - val_loss: 0.2852\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.28067\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2557 - val_loss: 0.2825\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.28067\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007387921, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2555 - val_loss: 0.2850\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.28067\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to tf.Tensor(0.00073519343, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2545 - val_loss: 0.2732\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.28067 to 0.27317, saving model to folds1.hdf5\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007316123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2561 - val_loss: 0.2699\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.27317 to 0.26989, saving model to folds1.hdf5\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007280487, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2450 - val_loss: 0.2773\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.26989\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007245024, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2543 - val_loss: 0.2756\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.26989\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007209733, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2446 - val_loss: 0.2757\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.26989\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071746146, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2489 - val_loss: 0.2663\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.26989 to 0.26630, saving model to folds1.hdf5\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007139667, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2461 - val_loss: 0.2849\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.26630\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071048894, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2481 - val_loss: 0.2719\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.26630\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007070282, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2440 - val_loss: 0.2856\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.26630\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007035842, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2411 - val_loss: 0.2696\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.26630\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to tf.Tensor(0.00070015714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2369 - val_loss: 0.2919\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.26630\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006967467, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2482 - val_loss: 0.2615\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.26630 to 0.26146, saving model to folds1.hdf5\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to tf.Tensor(0.00069335283, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2376 - val_loss: 0.2938\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.26146\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006899755, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2414 - val_loss: 0.2679\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.26146\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068661466, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2395 - val_loss: 0.2611\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.26146 to 0.26108, saving model to folds1.hdf5\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068327016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2340 - val_loss: 0.2646\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.26108\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067994196, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2270 - val_loss: 0.2684\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.26108\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067663, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2321 - val_loss: 0.2590\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.26108 to 0.25904, saving model to folds1.hdf5\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006733342, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2303 - val_loss: 0.2630\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.25904\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067005435, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2339 - val_loss: 0.2589\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.25904 to 0.25887, saving model to folds1.hdf5\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006667905, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2339 - val_loss: 0.2595\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.25887\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006635426, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2315 - val_loss: 0.2772\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.25887\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006603105, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2373 - val_loss: 0.2532\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.25887 to 0.25322, saving model to folds1.hdf5\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006570942, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2267 - val_loss: 0.2564\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.25322\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065389345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2267 - val_loss: 0.2516\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.25322 to 0.25159, saving model to folds1.hdf5\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065070833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2208 - val_loss: 0.2557\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.25159\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to tf.Tensor(0.00064753875, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2246 - val_loss: 0.2571\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.25159\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006443846, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2266 - val_loss: 0.2515\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.25159 to 0.25152, saving model to folds1.hdf5\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006412458, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.2179 - val_loss: 0.2596\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.25152\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063812226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2171 - val_loss: 0.2516\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.25152\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063501403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2192 - val_loss: 0.2506\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.25152 to 0.25058, saving model to folds1.hdf5\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006319209, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2173 - val_loss: 0.2477\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.25058 to 0.24767, saving model to folds1.hdf5\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006288428, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2113 - val_loss: 0.2520\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.24767\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to tf.Tensor(0.00062577974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2172 - val_loss: 0.2495\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.24767\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006227316, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2136 - val_loss: 0.2496\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.24767\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061969826, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2146 - val_loss: 0.2493\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.24767\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 00100: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006166797, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2156 - val_loss: 0.2497\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.24767\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 00101: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061367586, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2178 - val_loss: 0.2449\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.24767 to 0.24486, saving model to folds1.hdf5\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 00102: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061068666, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2086 - val_loss: 0.2478\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.24486\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 00103: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006077121, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2163 - val_loss: 0.2435\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.24486 to 0.24355, saving model to folds1.hdf5\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 00104: LearningRateScheduler reducing learning rate to tf.Tensor(0.00060475187, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2057 - val_loss: 0.2463\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.24355\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 00105: LearningRateScheduler reducing learning rate to tf.Tensor(0.00060180615, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2061 - val_loss: 0.2636\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.24355\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 00106: LearningRateScheduler reducing learning rate to tf.Tensor(0.00059887476, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2104 - val_loss: 0.2387\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.24355 to 0.23874, saving model to folds1.hdf5\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 00107: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005959577, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2025 - val_loss: 0.2427\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.23874\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 00108: LearningRateScheduler reducing learning rate to tf.Tensor(0.00059305475, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2099 - val_loss: 0.2449\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.23874\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 00109: LearningRateScheduler reducing learning rate to tf.Tensor(0.000590166, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2027 - val_loss: 0.2469\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.23874\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 00110: LearningRateScheduler reducing learning rate to tf.Tensor(0.00058729126, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2083 - val_loss: 0.2437\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.23874\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 00111: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005844306, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2002 - val_loss: 0.2574\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.23874\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 00112: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005815838, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2113 - val_loss: 0.2424\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.23874\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 00113: LearningRateScheduler reducing learning rate to tf.Tensor(0.000578751, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2060 - val_loss: 0.2420\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.23874\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 00114: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057593186, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2064 - val_loss: 0.2440\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.23874\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 00115: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057312654, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1991 - val_loss: 0.2361\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.23874 to 0.23615, saving model to folds1.hdf5\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 00116: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057033484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1978 - val_loss: 0.2451\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.23615\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 00117: LearningRateScheduler reducing learning rate to tf.Tensor(0.00056755677, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2017 - val_loss: 0.2381\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.23615\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 00118: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005647922, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2001 - val_loss: 0.2398\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.23615\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 00119: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005620411, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2008 - val_loss: 0.2376\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.23615\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 00120: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055930344, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1979 - val_loss: 0.2431\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.23615\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 00121: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055657903, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1968 - val_loss: 0.2409\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.23615\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 00122: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055386795, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1986 - val_loss: 0.2411\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.23615\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 00123: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005511701, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1959 - val_loss: 0.2429\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.23615\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 00124: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005484854, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1951 - val_loss: 0.2361\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.23615 to 0.23612, saving model to folds1.hdf5\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 00125: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005458137, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1958 - val_loss: 0.2437\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.23612\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 00126: LearningRateScheduler reducing learning rate to tf.Tensor(0.00054315507, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1979 - val_loss: 0.2396\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.23612\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 00127: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005405093, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1913 - val_loss: 0.2336\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.23612 to 0.23360, saving model to folds1.hdf5\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 00128: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005378765, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1911 - val_loss: 0.2333\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.23360 to 0.23332, saving model to folds1.hdf5\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 00129: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005352565, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1903 - val_loss: 0.2314\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.23332 to 0.23135, saving model to folds1.hdf5\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 00130: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005326493, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1895 - val_loss: 0.2388\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.23135\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 00131: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005300548, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1893 - val_loss: 0.2460\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.23135\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 00132: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005274729, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 50ms/step - loss: 0.2024 - val_loss: 0.2337\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.23135\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 00133: LearningRateScheduler reducing learning rate to tf.Tensor(0.00052490365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1894 - val_loss: 0.2362\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.23135\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 00134: LearningRateScheduler reducing learning rate to tf.Tensor(0.00052234676, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1883 - val_loss: 0.2348\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.23135\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 00135: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005198025, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1885 - val_loss: 0.2483\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.23135\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 00136: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005172705, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1913 - val_loss: 0.2364\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.23135\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 00137: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051475083, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1931 - val_loss: 0.2376\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.23135\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 00138: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051224354, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1887 - val_loss: 0.2397\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.23135\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 00139: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005097484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1870 - val_loss: 0.2320\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.23135\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 00140: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005072654, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1833 - val_loss: 0.2322\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.23135\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 00141: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005047946, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1837 - val_loss: 0.2304\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.23135 to 0.23036, saving model to folds1.hdf5\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 00142: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005023357, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1846 - val_loss: 0.2368\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.23036\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 00143: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049988885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1827 - val_loss: 0.2279\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.23036 to 0.22792, saving model to folds1.hdf5\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 00144: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004974539, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1798 - val_loss: 0.2303\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.22792\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 00145: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004950308, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1795 - val_loss: 0.2336\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.22792\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 00146: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004926195, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1825 - val_loss: 0.2354\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.22792\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 00147: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049022, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1840 - val_loss: 0.2317\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.22792\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 00148: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048783212, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1803 - val_loss: 0.2342\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.22792\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 00149: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048545588, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1805 - val_loss: 0.2306\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.22792\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 00150: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048309125, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1806 - val_loss: 0.2307\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.22792\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 00151: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048073815, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1778 - val_loss: 0.2286\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.22792\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 00152: LearningRateScheduler reducing learning rate to tf.Tensor(0.00047839645, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1781 - val_loss: 0.2285\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.22792\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 00153: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004760662, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1771 - val_loss: 0.2304\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.22792\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 00154: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004737473, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1777 - val_loss: 0.2260\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.22792 to 0.22597, saving model to folds1.hdf5\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 00155: LearningRateScheduler reducing learning rate to tf.Tensor(0.00047143968, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1770 - val_loss: 0.2300\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.22597\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 00156: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004691433, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1748 - val_loss: 0.2324\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.22597\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 00157: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046685815, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1783 - val_loss: 0.2380\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.22597\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 00158: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046458407, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1818 - val_loss: 0.2302\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.22597\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 00159: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046232107, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1773 - val_loss: 0.2274\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.22597\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 00160: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046006907, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1735 - val_loss: 0.2259\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.22597 to 0.22588, saving model to folds1.hdf5\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 00161: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045782814, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1757 - val_loss: 0.2329\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.22588\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 00162: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045559806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1769 - val_loss: 0.2269\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.22588\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 00163: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045337883, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.1722 - val_loss: 0.2294\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.22588\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 00164: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045117046, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1720 - val_loss: 0.2273\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.22588\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 00165: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044897277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1698 - val_loss: 0.2244\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.22588 to 0.22442, saving model to folds1.hdf5\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 00166: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044678585, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1734 - val_loss: 0.2306\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.22442\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 00167: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004446096, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1717 - val_loss: 0.2330\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.22442\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 00168: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004424439, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1737 - val_loss: 0.2218\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.22442 to 0.22179, saving model to folds1.hdf5\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 00169: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044028874, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1682 - val_loss: 0.2279\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.22179\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 00170: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043814414, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1681 - val_loss: 0.2252\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.22179\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 00171: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043600993, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1695 - val_loss: 0.2238\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.22179\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 00172: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043388613, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1700 - val_loss: 0.2253\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.22179\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 00173: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004317727, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1695 - val_loss: 0.2229\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.22179\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 00174: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004296695, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1685 - val_loss: 0.2262\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.22179\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 00175: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004275766, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1677 - val_loss: 0.2258\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.22179\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 00176: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042549393, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1667 - val_loss: 0.2228\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.22179\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 00177: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042342133, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1658 - val_loss: 0.2233\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.22179\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 00178: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042135885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1683 - val_loss: 0.2288\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.22179\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 00179: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041930642, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1695 - val_loss: 0.2252\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.22179\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 00180: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041726397, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1660 - val_loss: 0.2307\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.22179\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 00181: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041523148, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1686 - val_loss: 0.2229\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.22179\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 00182: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041320888, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1640 - val_loss: 0.2253\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.22179\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 00183: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041119618, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1634 - val_loss: 0.2228\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.22179\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 00184: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040919325, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1650 - val_loss: 0.2251\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.22179\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 00185: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040720004, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1641 - val_loss: 0.2267\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.22179\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 00186: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004052166, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1626 - val_loss: 0.2242\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.22179\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 00187: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004032428, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1622 - val_loss: 0.2233\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.22179\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 00188: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004012786, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1625 - val_loss: 0.2230\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.22179\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 00189: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039932402, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1612 - val_loss: 0.2215\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.22179 to 0.22150, saving model to folds1.hdf5\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 00190: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039737887, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1603 - val_loss: 0.2215\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.22150\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 00191: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039544326, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1578 - val_loss: 0.2220\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.22150\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 00192: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039351705, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1596 - val_loss: 0.2220\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.22150\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 00193: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039160028, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1584 - val_loss: 0.2241\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.22150\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 00194: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038969278, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1597 - val_loss: 0.2221\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.22150\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 00195: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003877946, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1594 - val_loss: 0.2215\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.22150 to 0.22146, saving model to folds1.hdf5\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 00196: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038590565, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1576 - val_loss: 0.2192\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.22146 to 0.21925, saving model to folds1.hdf5\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 00197: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003840259, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1583 - val_loss: 0.2213\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.21925\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 00198: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038215535, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1564 - val_loss: 0.2217\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.21925\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 00199: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038029387, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1575 - val_loss: 0.2199\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.21925\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 00200: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037844144, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1575 - val_loss: 0.2215\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.21925\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 00201: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037659804, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1556 - val_loss: 0.2204\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.21925\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 00202: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037476368, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1572 - val_loss: 0.2186\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.21925 to 0.21857, saving model to folds1.hdf5\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 00203: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037293817, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1555 - val_loss: 0.2205\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.21857\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 00204: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003711216, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 50ms/step - loss: 0.1540 - val_loss: 0.2225\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.21857\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 00205: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003693139, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1564 - val_loss: 0.2215\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.21857\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 00206: LearningRateScheduler reducing learning rate to tf.Tensor(0.000367515, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1549 - val_loss: 0.2205\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.21857\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 00207: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036572482, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1552 - val_loss: 0.2224\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.21857\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 00208: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003639434, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1547 - val_loss: 0.2221\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.21857\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 00209: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036217063, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1526 - val_loss: 0.2200\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.21857\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 00210: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036040647, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1530 - val_loss: 0.2206\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.21857\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 00211: LearningRateScheduler reducing learning rate to tf.Tensor(0.00035865093, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1528 - val_loss: 0.2183\n",
      "\n",
      "Epoch 00211: val_loss improved from 0.21857 to 0.21834, saving model to folds1.hdf5\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 00212: LearningRateScheduler reducing learning rate to tf.Tensor(0.000356904, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1522 - val_loss: 0.2197\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.21834\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 00213: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003551655, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1530 - val_loss: 0.2178\n",
      "\n",
      "Epoch 00213: val_loss improved from 0.21834 to 0.21784, saving model to folds1.hdf5\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 00214: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003534355, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1533 - val_loss: 0.2194\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.21784\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 00215: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003517139, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1516 - val_loss: 0.2254\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.21784\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 00216: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003500007, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1550 - val_loss: 0.2226\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.21784\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 00217: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034829587, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1545 - val_loss: 0.2222\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.21784\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 00218: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034659932, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1524 - val_loss: 0.2186\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.21784\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 00219: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034491107, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1515 - val_loss: 0.2264\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.21784\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 00220: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034323102, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1536 - val_loss: 0.2193\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.21784\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 00221: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034155912, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1505 - val_loss: 0.2188\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.21784\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 00222: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033989537, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1499 - val_loss: 0.2177\n",
      "\n",
      "Epoch 00222: val_loss improved from 0.21784 to 0.21774, saving model to folds1.hdf5\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 00223: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033823974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1490 - val_loss: 0.2193\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.21774\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 00224: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003365922, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1506 - val_loss: 0.2215\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.21774\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 00225: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033495267, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1487 - val_loss: 0.2218\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.21774\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 00226: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003333211, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1487 - val_loss: 0.2200\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.21774\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 00227: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033169755, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1498 - val_loss: 0.2171\n",
      "\n",
      "Epoch 00227: val_loss improved from 0.21774 to 0.21715, saving model to folds1.hdf5\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 00228: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033008185, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1466 - val_loss: 0.2196\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.21715\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 00229: LearningRateScheduler reducing learning rate to tf.Tensor(0.000328474, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1488 - val_loss: 0.2192\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.21715\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 00230: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032687403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1476 - val_loss: 0.2214\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.21715\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 00231: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003252818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1489 - val_loss: 0.2187\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.21715\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 00232: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032369737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1481 - val_loss: 0.2179\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.21715\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 00233: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032212064, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1472 - val_loss: 0.2199\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.21715\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 00234: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032055163, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1470 - val_loss: 0.2187\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.21715\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 00235: LearningRateScheduler reducing learning rate to tf.Tensor(0.00031899018, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1460 - val_loss: 0.2192\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.21715\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 00236: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003174364, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1463 - val_loss: 0.2189\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.21715\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 00237: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003158902, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1464 - val_loss: 0.2185\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.21715\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 00238: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003143515, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.1462 - val_loss: 0.2241\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.21715\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 00239: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003128203, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1480 - val_loss: 0.2198\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.21715\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 00240: LearningRateScheduler reducing learning rate to tf.Tensor(0.00031129655, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1470 - val_loss: 0.2184\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.21715\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 00241: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003097802, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1438 - val_loss: 0.2198\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.21715\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 00242: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003082713, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1477 - val_loss: 0.2188\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.21715\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 00243: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003067697, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1444 - val_loss: 0.2177\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.21715\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 00244: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030527546, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1436 - val_loss: 0.2169\n",
      "\n",
      "Epoch 00244: val_loss improved from 0.21715 to 0.21690, saving model to folds1.hdf5\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 00245: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030378843, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1435 - val_loss: 0.2177\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.21690\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 00246: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003023087, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1432 - val_loss: 0.2185\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.21690\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 00247: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030083617, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1443 - val_loss: 0.2208\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.21690\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 00248: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002993708, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1436 - val_loss: 0.2173\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.21690\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 00249: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029791257, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1432 - val_loss: 0.2167\n",
      "\n",
      "Epoch 00249: val_loss improved from 0.21690 to 0.21670, saving model to folds1.hdf5\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 00250: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029646145, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1434 - val_loss: 0.2183\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.21670\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 00251: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029501738, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1438 - val_loss: 0.2172\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.21670\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 00252: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029358038, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1430 - val_loss: 0.2169\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.21670\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 00253: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029215033, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1414 - val_loss: 0.2174\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.21670\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 00254: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029072727, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1407 - val_loss: 0.2163\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.21670 to 0.21634, saving model to folds1.hdf5\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 00255: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028931117, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1402 - val_loss: 0.2168\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.21634\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 00256: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028790193, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1408 - val_loss: 0.2162\n",
      "\n",
      "Epoch 00256: val_loss improved from 0.21634 to 0.21618, saving model to folds1.hdf5\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 00257: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028649953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1430 - val_loss: 0.2182\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.21618\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 00258: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028510403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1417 - val_loss: 0.2176\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.21618\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 00259: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002837153, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1398 - val_loss: 0.2163\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.21618\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 00260: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002823333, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1401 - val_loss: 0.2168\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.21618\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 00261: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028095808, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1417 - val_loss: 0.2176\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.21618\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 00262: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027958953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1399 - val_loss: 0.2207\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.21618\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 00263: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027822764, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1416 - val_loss: 0.2155\n",
      "\n",
      "Epoch 00263: val_loss improved from 0.21618 to 0.21548, saving model to folds1.hdf5\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 00264: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027687242, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1380 - val_loss: 0.2199\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.21548\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 00265: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027552375, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1384 - val_loss: 0.2173\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.21548\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 00266: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002741817, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1376 - val_loss: 0.2154\n",
      "\n",
      "Epoch 00266: val_loss improved from 0.21548 to 0.21544, saving model to folds1.hdf5\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 00267: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027284614, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1379 - val_loss: 0.2158\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.21544\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 00268: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027151714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1376 - val_loss: 0.2159\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.21544\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 00269: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027019458, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1374 - val_loss: 0.2189\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.21544\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 00270: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026887844, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1393 - val_loss: 0.2180\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.21544\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 00271: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026756877, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1377 - val_loss: 0.2168\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.21544\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 00272: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026626544, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1380 - val_loss: 0.2167\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.21544\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 00273: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026496846, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1365 - val_loss: 0.2163\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.21544\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 00274: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026367782, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1367 - val_loss: 0.2166\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.21544\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 00275: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026239344, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.1351 - val_loss: 0.2161\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.21544\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 00276: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026111532, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1357 - val_loss: 0.2167\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.21544\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 00277: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025984345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1366 - val_loss: 0.2175\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.21544\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 00278: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025857775, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1362 - val_loss: 0.2158\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.21544\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 00279: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002573182, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1359 - val_loss: 0.2207\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.21544\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 00280: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025606484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1377 - val_loss: 0.2172\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.21544\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 00281: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025481754, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1351 - val_loss: 0.2181\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.21544\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 00282: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025357632, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1360 - val_loss: 0.2159\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.21544\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 00283: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025234115, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1351 - val_loss: 0.2163\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.21544\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 00284: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025111204, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1342 - val_loss: 0.2162\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.21544\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 00285: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024988884, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1338 - val_loss: 0.2175\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.21544\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 00286: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024867163, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1350 - val_loss: 0.2169\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.21544\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 00287: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024746038, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1352 - val_loss: 0.2154\n",
      "\n",
      "Epoch 00287: val_loss improved from 0.21544 to 0.21535, saving model to folds1.hdf5\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 00288: LearningRateScheduler reducing learning rate to tf.Tensor(0.000246255, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1333 - val_loss: 0.2157\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.21535\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 00289: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024505547, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1328 - val_loss: 0.2159\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.21535\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 00290: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024386184, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1329 - val_loss: 0.2157\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.21535\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 00291: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024267398, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1357 - val_loss: 0.2174\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.21535\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 00292: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024149191, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1354 - val_loss: 0.2164\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.21535\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 00293: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024031562, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1338 - val_loss: 0.2151\n",
      "\n",
      "Epoch 00293: val_loss improved from 0.21535 to 0.21512, saving model to folds1.hdf5\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 00294: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023914504, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1331 - val_loss: 0.2163\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.21512\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 00295: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023798017, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1330 - val_loss: 0.2186\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.21512\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 00296: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023682097, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1344 - val_loss: 0.2153\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.21512\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 00297: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023566742, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1329 - val_loss: 0.2156\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.21512\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 00298: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023451951, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1328 - val_loss: 0.2169\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.21512\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 00299: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023337714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1329 - val_loss: 0.2157\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.21512\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 00300: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023224037, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 41ms/step - loss: 0.1320 - val_loss: 0.2150\n",
      "\n",
      "Epoch 00300: val_loss improved from 0.21512 to 0.21501, saving model to folds1.hdf5\n",
      "(50300, 80)\n",
      "--------------- > Fold 3 < ---------------\n",
      "CNN: (None, 72, 256)\n",
      "LSTM: (None, 80, 256)\n",
      "Com: (None, 152, 256)\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 26s 194ms/step - loss: 3.7421 - val_loss: 0.8471\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.84711, saving model to folds2.hdf5\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.7845 - val_loss: 0.6956\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.84711 to 0.69560, saving model to folds2.hdf5\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.6317 - val_loss: 0.5837\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.69560 to 0.58371, saving model to folds2.hdf5\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.5462 - val_loss: 0.6045\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.58371\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.5380 - val_loss: 0.5184\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.58371 to 0.51836, saving model to folds2.hdf5\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4826 - val_loss: 0.4694\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.51836 to 0.46938, saving model to folds2.hdf5\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4578 - val_loss: 0.5308\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.46938\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4636 - val_loss: 0.4358\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.46938 to 0.43581, saving model to folds2.hdf5\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4327 - val_loss: 0.4345\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.43581 to 0.43447, saving model to folds2.hdf5\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4218 - val_loss: 0.4293\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.43447 to 0.42934, saving model to folds2.hdf5\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4160 - val_loss: 0.4401\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.42934\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4015 - val_loss: 0.4274\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.42934 to 0.42741, saving model to folds2.hdf5\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3907 - val_loss: 0.4402\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.42741\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4114 - val_loss: 0.4155\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.42741 to 0.41548, saving model to folds2.hdf5\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3915 - val_loss: 0.3759\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.41548 to 0.37589, saving model to folds2.hdf5\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3636 - val_loss: 0.3898\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.37589\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3715 - val_loss: 0.3695\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.37589 to 0.36948, saving model to folds2.hdf5\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3531 - val_loss: 0.3565\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.36948 to 0.35647, saving model to folds2.hdf5\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3494 - val_loss: 0.3916\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.35647\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3563 - val_loss: 0.4175\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.35647\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3666 - val_loss: 0.3656\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.35647\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3491 - val_loss: 0.3464\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.35647 to 0.34640, saving model to folds2.hdf5\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3286 - val_loss: 0.3599\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.34640\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3506 - val_loss: 0.3601\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.34640\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3340 - val_loss: 0.3375\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.34640 to 0.33753, saving model to folds2.hdf5\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3255 - val_loss: 0.3439\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33753\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3194 - val_loss: 0.3517\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33753\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3201 - val_loss: 0.3550\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33753\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3177 - val_loss: 0.3420\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33753\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3216 - val_loss: 0.3292\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.33753 to 0.32915, saving model to folds2.hdf5\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3132 - val_loss: 0.3353\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.32915\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3217 - val_loss: 0.3358\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.32915\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3152 - val_loss: 0.3224\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.32915 to 0.32236, saving model to folds2.hdf5\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3003 - val_loss: 0.3143\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.32236 to 0.31433, saving model to folds2.hdf5\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2955 - val_loss: 0.3178\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.31433\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2976 - val_loss: 0.3263\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.31433\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3037 - val_loss: 0.3129\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.31433 to 0.31286, saving model to folds2.hdf5\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2926 - val_loss: 0.3076\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.31286 to 0.30762, saving model to folds2.hdf5\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2931 - val_loss: 0.3092\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.30762\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 49ms/step - loss: 0.2857 - val_loss: 0.3123\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.30762\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2883 - val_loss: 0.3227\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.30762\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2960 - val_loss: 0.3121\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.30762\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2838 - val_loss: 0.3096\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.30762\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2906 - val_loss: 0.3101\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.30762\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2862 - val_loss: 0.3086\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.30762\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2794 - val_loss: 0.2992\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.30762 to 0.29922, saving model to folds2.hdf5\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2789 - val_loss: 0.3260\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.29922\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2950 - val_loss: 0.3053\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.29922\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2710 - val_loss: 0.3032\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.29922\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2706 - val_loss: 0.2989\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.29922 to 0.29886, saving model to folds2.hdf5\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2686 - val_loss: 0.3026\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.29886\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2688 - val_loss: 0.3220\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.29886\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2706 - val_loss: 0.2963\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.29886 to 0.29632, saving model to folds2.hdf5\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2604 - val_loss: 0.3015\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.29632\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2694 - val_loss: 0.2987\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.29632\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2633 - val_loss: 0.2820\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.29632 to 0.28201, saving model to folds2.hdf5\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2612 - val_loss: 0.3175\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.28201\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2631 - val_loss: 0.2855\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.28201\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2574 - val_loss: 0.2839\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.28201\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2539 - val_loss: 0.2862\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.28201\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2630 - val_loss: 0.2856\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.28201\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2555 - val_loss: 0.3043\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.28201\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007387921, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2583 - val_loss: 0.2859\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.28201\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to tf.Tensor(0.00073519343, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2521 - val_loss: 0.2782\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.28201 to 0.27822, saving model to folds2.hdf5\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007316123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2468 - val_loss: 0.2735\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.27822 to 0.27351, saving model to folds2.hdf5\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007280487, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2452 - val_loss: 0.2948\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.27351\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007245024, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2496 - val_loss: 0.2745\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.27351\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007209733, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2457 - val_loss: 0.2820\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.27351\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071746146, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2425 - val_loss: 0.2837\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.27351\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007139667, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2440 - val_loss: 0.2765\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.27351\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071048894, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2399 - val_loss: 0.2803\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.27351\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007070282, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2383 - val_loss: 0.2760\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.27351\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007035842, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2430 - val_loss: 0.2780\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.27351\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to tf.Tensor(0.00070015714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 50ms/step - loss: 0.2390 - val_loss: 0.2703\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.27351 to 0.27034, saving model to folds2.hdf5\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006967467, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2386 - val_loss: 0.2746\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.27034\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to tf.Tensor(0.00069335283, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2329 - val_loss: 0.2780\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.27034\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006899755, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2360 - val_loss: 0.2660\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.27034 to 0.26596, saving model to folds2.hdf5\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068661466, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2331 - val_loss: 0.2720\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.26596\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068327016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2291 - val_loss: 0.2830\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.26596\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067994196, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2352 - val_loss: 0.2684\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.26596\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067663, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2303 - val_loss: 0.2719\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.26596\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006733342, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2342 - val_loss: 0.2625\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.26596 to 0.26253, saving model to folds2.hdf5\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067005435, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2255 - val_loss: 0.2670\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.26253\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006667905, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2250 - val_loss: 0.2810\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.26253\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006635426, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2312 - val_loss: 0.2633\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.26253\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006603105, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2252 - val_loss: 0.2660\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.26253\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006570942, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2227 - val_loss: 0.2641\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.26253\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065389345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2229 - val_loss: 0.2596\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.26253 to 0.25964, saving model to folds2.hdf5\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065070833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2204 - val_loss: 0.2638\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.25964\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to tf.Tensor(0.00064753875, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2203 - val_loss: 0.2613\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.25964\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006443846, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2186 - val_loss: 0.2659\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.25964\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006412458, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2197 - val_loss: 0.2572\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.25964 to 0.25718, saving model to folds2.hdf5\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063812226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2146 - val_loss: 0.2575\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.25718\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063501403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2141 - val_loss: 0.2654\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.25718\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006319209, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2161 - val_loss: 0.2604\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.25718\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006288428, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2128 - val_loss: 0.2577\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.25718\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to tf.Tensor(0.00062577974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2142 - val_loss: 0.2510\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.25718 to 0.25102, saving model to folds2.hdf5\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006227316, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2147 - val_loss: 0.2594\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.25102\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061969826, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2128 - val_loss: 0.2523\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.25102\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 00100: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006166797, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2106 - val_loss: 0.2722\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.25102\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 00101: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061367586, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2094 - val_loss: 0.2542\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.25102\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 00102: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061068666, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2116 - val_loss: 0.2526\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.25102\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 00103: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006077121, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2092 - val_loss: 0.2605\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.25102\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 00104: LearningRateScheduler reducing learning rate to tf.Tensor(0.00060475187, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2082 - val_loss: 0.2501\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.25102 to 0.25014, saving model to folds2.hdf5\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 00105: LearningRateScheduler reducing learning rate to tf.Tensor(0.00060180615, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2093 - val_loss: 0.2509\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.25014\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 00106: LearningRateScheduler reducing learning rate to tf.Tensor(0.00059887476, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2068 - val_loss: 0.2477\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.25014 to 0.24770, saving model to folds2.hdf5\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 00107: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005959577, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2051 - val_loss: 0.2595\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.24770\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 00108: LearningRateScheduler reducing learning rate to tf.Tensor(0.00059305475, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 50ms/step - loss: 0.2099 - val_loss: 0.2550\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.24770\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 00109: LearningRateScheduler reducing learning rate to tf.Tensor(0.000590166, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2038 - val_loss: 0.2533\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.24770\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 00110: LearningRateScheduler reducing learning rate to tf.Tensor(0.00058729126, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2027 - val_loss: 0.2558\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.24770\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 00111: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005844306, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2028 - val_loss: 0.2456\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.24770 to 0.24555, saving model to folds2.hdf5\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 00112: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005815838, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1976 - val_loss: 0.2470\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.24555\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 00113: LearningRateScheduler reducing learning rate to tf.Tensor(0.000578751, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2002 - val_loss: 0.2510\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.24555\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 00114: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057593186, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2023 - val_loss: 0.2462\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.24555\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 00115: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057312654, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1959 - val_loss: 0.2449\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.24555 to 0.24488, saving model to folds2.hdf5\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 00116: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057033484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1976 - val_loss: 0.2570\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.24488\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 00117: LearningRateScheduler reducing learning rate to tf.Tensor(0.00056755677, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2038 - val_loss: 0.2505\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.24488\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 00118: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005647922, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1964 - val_loss: 0.2548\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.24488\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 00119: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005620411, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2011 - val_loss: 0.2456\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.24488\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 00120: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055930344, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1946 - val_loss: 0.2446\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.24488 to 0.24465, saving model to folds2.hdf5\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 00121: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055657903, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1949 - val_loss: 0.2449\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.24465\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 00122: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055386795, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1981 - val_loss: 0.2436\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.24465 to 0.24357, saving model to folds2.hdf5\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 00123: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005511701, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1935 - val_loss: 0.2460\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.24357\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 00124: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005484854, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1941 - val_loss: 0.2433\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.24357 to 0.24327, saving model to folds2.hdf5\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 00125: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005458137, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1899 - val_loss: 0.2498\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.24327\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 00126: LearningRateScheduler reducing learning rate to tf.Tensor(0.00054315507, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1916 - val_loss: 0.2415\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.24327 to 0.24152, saving model to folds2.hdf5\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 00127: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005405093, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1892 - val_loss: 0.2409\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.24152 to 0.24086, saving model to folds2.hdf5\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 00128: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005378765, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1907 - val_loss: 0.2414\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.24086\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 00129: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005352565, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1888 - val_loss: 0.2410\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.24086\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 00130: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005326493, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1907 - val_loss: 0.2511\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.24086\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 00131: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005300548, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1911 - val_loss: 0.2438\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.24086\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 00132: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005274729, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1852 - val_loss: 0.2497\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.24086\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 00133: LearningRateScheduler reducing learning rate to tf.Tensor(0.00052490365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1945 - val_loss: 0.2434\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.24086\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 00134: LearningRateScheduler reducing learning rate to tf.Tensor(0.00052234676, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1865 - val_loss: 0.2448\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.24086\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 00135: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005198025, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1866 - val_loss: 0.2393\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.24086 to 0.23934, saving model to folds2.hdf5\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 00136: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005172705, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1864 - val_loss: 0.2490\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.23934\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 00137: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051475083, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1870 - val_loss: 0.2398\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.23934\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 00138: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051224354, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1810 - val_loss: 0.2395\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.23934\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 00139: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005097484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1855 - val_loss: 0.2420\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.23934\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 00140: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005072654, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1847 - val_loss: 0.2400\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.23934\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 00141: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005047946, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1823 - val_loss: 0.2362\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.23934 to 0.23621, saving model to folds2.hdf5\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 00142: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005023357, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.1796 - val_loss: 0.2379\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.23621\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 00143: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049988885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1809 - val_loss: 0.2371\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.23621\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 00144: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004974539, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1811 - val_loss: 0.2442\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.23621\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 00145: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004950308, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1820 - val_loss: 0.2394\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.23621\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 00146: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004926195, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1824 - val_loss: 0.2424\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.23621\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 00147: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049022, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1824 - val_loss: 0.2430\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.23621\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 00148: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048783212, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1800 - val_loss: 0.2407\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.23621\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 00149: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048545588, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1800 - val_loss: 0.2375\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.23621\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 00150: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048309125, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1758 - val_loss: 0.2327\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.23621 to 0.23269, saving model to folds2.hdf5\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 00151: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048073815, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1751 - val_loss: 0.2346\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.23269\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 00152: LearningRateScheduler reducing learning rate to tf.Tensor(0.00047839645, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1741 - val_loss: 0.2373\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.23269\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 00153: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004760662, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1780 - val_loss: 0.2340\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.23269\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 00154: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004737473, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1735 - val_loss: 0.2363\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.23269\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 00155: LearningRateScheduler reducing learning rate to tf.Tensor(0.00047143968, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1737 - val_loss: 0.2435\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.23269\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 00156: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004691433, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1773 - val_loss: 0.2350\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.23269\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 00157: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046685815, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1776 - val_loss: 0.2380\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.23269\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 00158: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046458407, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1734 - val_loss: 0.2443\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.23269\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 00159: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046232107, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1735 - val_loss: 0.2415\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.23269\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 00160: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046006907, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1756 - val_loss: 0.2333\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.23269\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 00161: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045782814, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1724 - val_loss: 0.2369\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.23269\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 00162: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045559806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1708 - val_loss: 0.2335\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.23269\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 00163: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045337883, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1701 - val_loss: 0.2410\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.23269\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 00164: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045117046, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1713 - val_loss: 0.2332\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.23269\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 00165: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044897277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1701 - val_loss: 0.2392\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.23269\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 00166: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044678585, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1706 - val_loss: 0.2319\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.23269 to 0.23190, saving model to folds2.hdf5\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 00167: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004446096, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1671 - val_loss: 0.2322\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.23190\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 00168: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004424439, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.1689 - val_loss: 0.2336\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.23190\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 00169: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044028874, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1688 - val_loss: 0.2360\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.23190\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 00170: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043814414, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1660 - val_loss: 0.2298\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.23190 to 0.22982, saving model to folds2.hdf5\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 00171: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043600993, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1655 - val_loss: 0.2299\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.22982\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 00172: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043388613, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1664 - val_loss: 0.2321\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.22982\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 00173: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004317727, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1664 - val_loss: 0.2315\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.22982\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 00174: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004296695, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1663 - val_loss: 0.2303\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.22982\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 00175: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004275766, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1666 - val_loss: 0.2326\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.22982\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 00176: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042549393, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1651 - val_loss: 0.2321\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.22982\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 00177: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042342133, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1642 - val_loss: 0.2307\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.22982\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 00178: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042135885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1628 - val_loss: 0.2335\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.22982\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 00179: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041930642, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1660 - val_loss: 0.2289\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.22982 to 0.22894, saving model to folds2.hdf5\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 00180: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041726397, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1627 - val_loss: 0.2321\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.22894\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 00181: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041523148, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1619 - val_loss: 0.2302\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.22894\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 00182: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041320888, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1625 - val_loss: 0.2314\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.22894\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 00183: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041119618, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1629 - val_loss: 0.2298\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.22894\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 00184: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040919325, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1624 - val_loss: 0.2315\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.22894\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 00185: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040720004, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1634 - val_loss: 0.2298\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.22894\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 00186: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004052166, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1601 - val_loss: 0.2284\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.22894 to 0.22841, saving model to folds2.hdf5\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 00187: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004032428, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1585 - val_loss: 0.2318\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.22841\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 00188: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004012786, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1614 - val_loss: 0.2289\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.22841\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 00189: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039932402, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1577 - val_loss: 0.2290\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.22841\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 00190: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039737887, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1582 - val_loss: 0.2301\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.22841\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 00191: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039544326, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1584 - val_loss: 0.2292\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.22841\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 00192: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039351705, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1620 - val_loss: 0.2287\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.22841\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 00193: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039160028, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1575 - val_loss: 0.2342\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.22841\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 00194: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038969278, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1600 - val_loss: 0.2316\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.22841\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 00195: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003877946, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1576 - val_loss: 0.2284\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.22841\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 00196: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038590565, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1560 - val_loss: 0.2339\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.22841\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 00197: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003840259, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1578 - val_loss: 0.2343\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.22841\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 00198: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038215535, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1587 - val_loss: 0.2300\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.22841\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 00199: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038029387, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1552 - val_loss: 0.2288\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.22841\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 00200: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037844144, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1562 - val_loss: 0.2293\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.22841\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 00201: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037659804, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1561 - val_loss: 0.2283\n",
      "\n",
      "Epoch 00201: val_loss improved from 0.22841 to 0.22834, saving model to folds2.hdf5\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 00202: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037476368, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1542 - val_loss: 0.2289\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.22834\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 00203: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037293817, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1532 - val_loss: 0.2320\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.22834\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 00204: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003711216, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1588 - val_loss: 0.2294\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.22834\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 00205: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003693139, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1544 - val_loss: 0.2306\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.22834\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 00206: LearningRateScheduler reducing learning rate to tf.Tensor(0.000367515, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1537 - val_loss: 0.2267\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.22834 to 0.22670, saving model to folds2.hdf5\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 00207: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036572482, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1527 - val_loss: 0.2258\n",
      "\n",
      "Epoch 00207: val_loss improved from 0.22670 to 0.22584, saving model to folds2.hdf5\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 00208: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003639434, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1525 - val_loss: 0.2280\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.22584\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 00209: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036217063, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1518 - val_loss: 0.2269\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.22584\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 00210: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036040647, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1519 - val_loss: 0.2277\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.22584\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 00211: LearningRateScheduler reducing learning rate to tf.Tensor(0.00035865093, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1509 - val_loss: 0.2253\n",
      "\n",
      "Epoch 00211: val_loss improved from 0.22584 to 0.22528, saving model to folds2.hdf5\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 00212: LearningRateScheduler reducing learning rate to tf.Tensor(0.000356904, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1515 - val_loss: 0.2269\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.22528\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 00213: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003551655, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1519 - val_loss: 0.2277\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.22528\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 00214: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003534355, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1521 - val_loss: 0.2271\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.22528\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 00215: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003517139, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1512 - val_loss: 0.2269\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.22528\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 00216: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003500007, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1495 - val_loss: 0.2253\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.22528\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 00217: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034829587, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1488 - val_loss: 0.2267\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.22528\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 00218: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034659932, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1521 - val_loss: 0.2317\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.22528\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 00219: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034491107, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1503 - val_loss: 0.2276\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.22528\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 00220: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034323102, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1478 - val_loss: 0.2256\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.22528\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 00221: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034155912, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1494 - val_loss: 0.2265\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.22528\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 00222: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033989537, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1471 - val_loss: 0.2254\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.22528\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 00223: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033823974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1465 - val_loss: 0.2254\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.22528\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 00224: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003365922, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1483 - val_loss: 0.2243\n",
      "\n",
      "Epoch 00224: val_loss improved from 0.22528 to 0.22435, saving model to folds2.hdf5\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 00225: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033495267, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1473 - val_loss: 0.2243\n",
      "\n",
      "Epoch 00225: val_loss improved from 0.22435 to 0.22429, saving model to folds2.hdf5\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 00226: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003333211, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 50ms/step - loss: 0.1474 - val_loss: 0.2274\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.22429\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 00227: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033169755, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1484 - val_loss: 0.2323\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.22429\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 00228: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033008185, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1493 - val_loss: 0.2266\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.22429\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 00229: LearningRateScheduler reducing learning rate to tf.Tensor(0.000328474, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1457 - val_loss: 0.2269\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.22429\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 00230: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032687403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1466 - val_loss: 0.2276\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.22429\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 00231: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003252818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1458 - val_loss: 0.2259\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.22429\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 00232: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032369737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1459 - val_loss: 0.2260\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.22429\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 00233: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032212064, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1457 - val_loss: 0.2250\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.22429\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 00234: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032055163, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1457 - val_loss: 0.2262\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.22429\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 00235: LearningRateScheduler reducing learning rate to tf.Tensor(0.00031899018, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1445 - val_loss: 0.2250\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.22429\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 00236: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003174364, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1463 - val_loss: 0.2252\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.22429\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 00237: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003158902, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1452 - val_loss: 0.2251\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.22429\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 00238: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003143515, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1439 - val_loss: 0.2250\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.22429\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 00239: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003128203, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1444 - val_loss: 0.2255\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.22429\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 00240: LearningRateScheduler reducing learning rate to tf.Tensor(0.00031129655, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1453 - val_loss: 0.2241\n",
      "\n",
      "Epoch 00240: val_loss improved from 0.22429 to 0.22413, saving model to folds2.hdf5\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 00241: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003097802, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1427 - val_loss: 0.2291\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.22413\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 00242: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003082713, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1442 - val_loss: 0.2310\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.22413\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 00243: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003067697, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1452 - val_loss: 0.2262\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.22413\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 00244: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030527546, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1428 - val_loss: 0.2249\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.22413\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 00245: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030378843, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1418 - val_loss: 0.2246\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.22413\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 00246: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003023087, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1422 - val_loss: 0.2232\n",
      "\n",
      "Epoch 00246: val_loss improved from 0.22413 to 0.22316, saving model to folds2.hdf5\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 00247: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030083617, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1408 - val_loss: 0.2269\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.22316\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 00248: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002993708, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1424 - val_loss: 0.2244\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.22316\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 00249: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029791257, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1420 - val_loss: 0.2241\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.22316\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 00250: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029646145, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1413 - val_loss: 0.2250\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.22316\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 00251: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029501738, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1408 - val_loss: 0.2248\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.22316\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 00252: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029358038, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1402 - val_loss: 0.2235\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.22316\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 00253: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029215033, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1396 - val_loss: 0.2252\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.22316\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 00254: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029072727, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1444 - val_loss: 0.2264\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.22316\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 00255: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028931117, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1417 - val_loss: 0.2247\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.22316\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 00256: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028790193, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1405 - val_loss: 0.2234\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.22316\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 00257: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028649953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1409 - val_loss: 0.2252\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.22316\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 00258: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028510403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1413 - val_loss: 0.2234\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.22316\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 00259: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002837153, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1394 - val_loss: 0.2240\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.22316\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 00260: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002823333, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 50ms/step - loss: 0.1388 - val_loss: 0.2249\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.22316\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 00261: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028095808, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1411 - val_loss: 0.2234\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.22316\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 00262: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027958953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1381 - val_loss: 0.2244\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.22316\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 00263: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027822764, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1390 - val_loss: 0.2249\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.22316\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 00264: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027687242, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1385 - val_loss: 0.2229\n",
      "\n",
      "Epoch 00264: val_loss improved from 0.22316 to 0.22287, saving model to folds2.hdf5\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 00265: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027552375, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1363 - val_loss: 0.2225\n",
      "\n",
      "Epoch 00265: val_loss improved from 0.22287 to 0.22250, saving model to folds2.hdf5\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 00266: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002741817, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1362 - val_loss: 0.2238\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.22250\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 00267: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027284614, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1364 - val_loss: 0.2240\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.22250\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 00268: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027151714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1381 - val_loss: 0.2254\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.22250\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 00269: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027019458, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1382 - val_loss: 0.2236\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.22250\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 00270: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026887844, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1363 - val_loss: 0.2269\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.22250\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 00271: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026756877, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1378 - val_loss: 0.2244\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.22250\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 00272: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026626544, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1365 - val_loss: 0.2238\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.22250\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 00273: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026496846, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1361 - val_loss: 0.2235\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.22250\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 00274: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026367782, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1351 - val_loss: 0.2236\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.22250\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 00275: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026239344, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1364 - val_loss: 0.2225\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.22250\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 00276: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026111532, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1348 - val_loss: 0.2235\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.22250\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 00277: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025984345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1356 - val_loss: 0.2254\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.22250\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 00278: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025857775, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1354 - val_loss: 0.2229\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.22250\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 00279: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002573182, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1339 - val_loss: 0.2261\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.22250\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 00280: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025606484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1348 - val_loss: 0.2219\n",
      "\n",
      "Epoch 00280: val_loss improved from 0.22250 to 0.22193, saving model to folds2.hdf5\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 00281: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025481754, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1338 - val_loss: 0.2242\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.22193\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 00282: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025357632, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1343 - val_loss: 0.2256\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.22193\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 00283: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025234115, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1342 - val_loss: 0.2245\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.22193\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 00284: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025111204, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1334 - val_loss: 0.2215\n",
      "\n",
      "Epoch 00284: val_loss improved from 0.22193 to 0.22153, saving model to folds2.hdf5\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 00285: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024988884, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1329 - val_loss: 0.2219\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.22153\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 00286: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024867163, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1326 - val_loss: 0.2228\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.22153\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 00287: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024746038, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1334 - val_loss: 0.2239\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.22153\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 00288: LearningRateScheduler reducing learning rate to tf.Tensor(0.000246255, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1346 - val_loss: 0.2230\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.22153\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 00289: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024505547, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1323 - val_loss: 0.2225\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.22153\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 00290: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024386184, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1316 - val_loss: 0.2227\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.22153\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 00291: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024267398, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1326 - val_loss: 0.2243\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.22153\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 00292: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024149191, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1340 - val_loss: 0.2245\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.22153\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 00293: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024031562, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1325 - val_loss: 0.2236\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.22153\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 00294: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023914504, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1320 - val_loss: 0.2226\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.22153\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 00295: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023798017, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1318 - val_loss: 0.2231\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.22153\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 00296: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023682097, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1314 - val_loss: 0.2233\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.22153\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 00297: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023566742, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 50ms/step - loss: 0.1313 - val_loss: 0.2223\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.22153\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 00298: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023451951, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1307 - val_loss: 0.2234\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.22153\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 00299: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023337714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1317 - val_loss: 0.2226\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.22153\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 00300: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023224037, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 41ms/step - loss: 0.1314 - val_loss: 0.2233\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.22153\n",
      "(50300, 80)\n",
      "--------------- > Fold 4 < ---------------\n",
      "CNN: (None, 72, 256)\n",
      "LSTM: (None, 80, 256)\n",
      "Com: (None, 152, 256)\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 26s 195ms/step - loss: 3.7245 - val_loss: 0.8512\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.85117, saving model to folds3.hdf5\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.7926 - val_loss: 0.6207\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.85117 to 0.62073, saving model to folds3.hdf5\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.6160 - val_loss: 0.5886\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.62073 to 0.58863, saving model to folds3.hdf5\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.5867 - val_loss: 0.5603\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.58863 to 0.56027, saving model to folds3.hdf5\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.5037 - val_loss: 0.5031\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.56027 to 0.50305, saving model to folds3.hdf5\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4840 - val_loss: 0.4918\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.50305 to 0.49180, saving model to folds3.hdf5\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4589 - val_loss: 0.4839\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.49180 to 0.48390, saving model to folds3.hdf5\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4434 - val_loss: 0.4311\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.48390 to 0.43108, saving model to folds3.hdf5\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4242 - val_loss: 0.4586\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.43108\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4280 - val_loss: 0.4062\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.43108 to 0.40621, saving model to folds3.hdf5\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4022 - val_loss: 0.4211\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.40621\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4095 - val_loss: 0.4105\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.40621\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4002 - val_loss: 0.3941\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.40621 to 0.39406, saving model to folds3.hdf5\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3830 - val_loss: 0.3861\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.39406 to 0.38608, saving model to folds3.hdf5\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3779 - val_loss: 0.3822\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.38608 to 0.38221, saving model to folds3.hdf5\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3884 - val_loss: 0.4092\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.38221\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3684 - val_loss: 0.3938\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.38221\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3638 - val_loss: 0.4044\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.38221\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3717 - val_loss: 0.3920\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.38221\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3586 - val_loss: 0.3668\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.38221 to 0.36681, saving model to folds3.hdf5\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3454 - val_loss: 0.3632\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.36681 to 0.36317, saving model to folds3.hdf5\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3416 - val_loss: 0.3676\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.36317\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3452 - val_loss: 0.4071\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.36317\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3491 - val_loss: 0.3458\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.36317 to 0.34576, saving model to folds3.hdf5\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3464 - val_loss: 0.3399\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.34576 to 0.33990, saving model to folds3.hdf5\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 48ms/step - loss: 0.3266 - val_loss: 0.3456\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33990\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3356 - val_loss: 0.3331\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.33990 to 0.33310, saving model to folds3.hdf5\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3198 - val_loss: 0.3357\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33310\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3148 - val_loss: 0.3553\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33310\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3237 - val_loss: 0.3507\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33310\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3236 - val_loss: 0.3324\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.33310 to 0.33236, saving model to folds3.hdf5\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3177 - val_loss: 0.3785\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33236\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3149 - val_loss: 0.3284\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.33236 to 0.32841, saving model to folds3.hdf5\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3078 - val_loss: 0.3350\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.32841\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3136 - val_loss: 0.3182\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.32841 to 0.31819, saving model to folds3.hdf5\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2997 - val_loss: 0.3215\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.31819\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2982 - val_loss: 0.3164\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.31819 to 0.31637, saving model to folds3.hdf5\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2943 - val_loss: 0.3150\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.31637 to 0.31499, saving model to folds3.hdf5\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2908 - val_loss: 0.3154\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.31499\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2916 - val_loss: 0.3603\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.31499\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3036 - val_loss: 0.3091\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.31499 to 0.30906, saving model to folds3.hdf5\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2910 - val_loss: 0.3380\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.30906\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2935 - val_loss: 0.3197\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.30906\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2858 - val_loss: 0.3106\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.30906\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2825 - val_loss: 0.3176\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.30906\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2807 - val_loss: 0.3020\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.30906 to 0.30195, saving model to folds3.hdf5\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2916 - val_loss: 0.3368\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.30195\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2990 - val_loss: 0.3066\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.30195\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2801 - val_loss: 0.3015\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.30195 to 0.30146, saving model to folds3.hdf5\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2688 - val_loss: 0.3015\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.30146\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2760 - val_loss: 0.3013\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.30146 to 0.30133, saving model to folds3.hdf5\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2679 - val_loss: 0.2992\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.30133 to 0.29916, saving model to folds3.hdf5\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2750 - val_loss: 0.3051\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.29916\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2645 - val_loss: 0.3053\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.29916\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2681 - val_loss: 0.2908\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.29916 to 0.29082, saving model to folds3.hdf5\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2647 - val_loss: 0.2969\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.29082\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2594 - val_loss: 0.2945\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.29082\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2681 - val_loss: 0.2964\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.29082\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2605 - val_loss: 0.2918\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.29082\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2628 - val_loss: 0.2881\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.29082 to 0.28811, saving model to folds3.hdf5\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2543 - val_loss: 0.2842\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.28811 to 0.28424, saving model to folds3.hdf5\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2546 - val_loss: 0.3069\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.28424\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007387921, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 50ms/step - loss: 0.2597 - val_loss: 0.2925\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.28424\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to tf.Tensor(0.00073519343, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2525 - val_loss: 0.2891\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.28424\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007316123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2520 - val_loss: 0.2861\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.28424\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007280487, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2488 - val_loss: 0.2803\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.28424 to 0.28030, saving model to folds3.hdf5\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007245024, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2438 - val_loss: 0.3093\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.28030\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007209733, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2533 - val_loss: 0.2889\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.28030\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071746146, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2483 - val_loss: 0.2817\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.28030\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007139667, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2458 - val_loss: 0.2792\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.28030 to 0.27919, saving model to folds3.hdf5\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071048894, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2454 - val_loss: 0.2752\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.27919 to 0.27516, saving model to folds3.hdf5\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007070282, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2395 - val_loss: 0.2781\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.27516\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007035842, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2391 - val_loss: 0.2758\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.27516\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to tf.Tensor(0.00070015714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2422 - val_loss: 0.2765\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.27516\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006967467, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2389 - val_loss: 0.2787\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.27516\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to tf.Tensor(0.00069335283, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2379 - val_loss: 0.2708\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.27516 to 0.27076, saving model to folds3.hdf5\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006899755, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2385 - val_loss: 0.2741\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.27076\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068661466, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2335 - val_loss: 0.2742\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.27076\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068327016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2301 - val_loss: 0.2705\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.27076 to 0.27047, saving model to folds3.hdf5\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067994196, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2279 - val_loss: 0.2697\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.27047 to 0.26968, saving model to folds3.hdf5\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067663, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2290 - val_loss: 0.2728\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.26968\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006733342, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2289 - val_loss: 0.2727\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.26968\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067005435, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2318 - val_loss: 0.2736\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.26968\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006667905, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2291 - val_loss: 0.2703\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.26968\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006635426, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2265 - val_loss: 0.2655\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.26968 to 0.26554, saving model to folds3.hdf5\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006603105, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2287 - val_loss: 0.2682\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.26554\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006570942, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2311 - val_loss: 0.2791\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.26554\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065389345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2244 - val_loss: 0.2658\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.26554\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065070833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2188 - val_loss: 0.2656\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.26554\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to tf.Tensor(0.00064753875, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2187 - val_loss: 0.2606\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.26554 to 0.26060, saving model to folds3.hdf5\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006443846, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2161 - val_loss: 0.2723\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.26060\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006412458, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2226 - val_loss: 0.2653\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.26060\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063812226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2197 - val_loss: 0.2625\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.26060\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063501403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2133 - val_loss: 0.2582\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.26060 to 0.25816, saving model to folds3.hdf5\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006319209, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2113 - val_loss: 0.2617\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.25816\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006288428, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2149 - val_loss: 0.2604\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.25816\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to tf.Tensor(0.00062577974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 50ms/step - loss: 0.2129 - val_loss: 0.2592\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.25816\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006227316, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2138 - val_loss: 0.2582\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.25816\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061969826, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2116 - val_loss: 0.2579\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.25816 to 0.25790, saving model to folds3.hdf5\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 00100: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006166797, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2095 - val_loss: 0.2565\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.25790 to 0.25654, saving model to folds3.hdf5\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 00101: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061367586, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2109 - val_loss: 0.2572\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.25654\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 00102: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061068666, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2069 - val_loss: 0.2559\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.25654 to 0.25588, saving model to folds3.hdf5\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 00103: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006077121, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2056 - val_loss: 0.2585\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.25588\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 00104: LearningRateScheduler reducing learning rate to tf.Tensor(0.00060475187, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2102 - val_loss: 0.2632\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.25588\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 00105: LearningRateScheduler reducing learning rate to tf.Tensor(0.00060180615, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2117 - val_loss: 0.2590\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.25588\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 00106: LearningRateScheduler reducing learning rate to tf.Tensor(0.00059887476, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2105 - val_loss: 0.2609\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.25588\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 00107: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005959577, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2072 - val_loss: 0.2588\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.25588\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 00108: LearningRateScheduler reducing learning rate to tf.Tensor(0.00059305475, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2020 - val_loss: 0.2614\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.25588\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 00109: LearningRateScheduler reducing learning rate to tf.Tensor(0.000590166, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2041 - val_loss: 0.2550\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.25588 to 0.25498, saving model to folds3.hdf5\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 00110: LearningRateScheduler reducing learning rate to tf.Tensor(0.00058729126, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2028 - val_loss: 0.2516\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.25498 to 0.25165, saving model to folds3.hdf5\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 00111: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005844306, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1999 - val_loss: 0.2500\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.25165 to 0.24999, saving model to folds3.hdf5\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 00112: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005815838, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1996 - val_loss: 0.2542\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.24999\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 00113: LearningRateScheduler reducing learning rate to tf.Tensor(0.000578751, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1984 - val_loss: 0.2507\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.24999\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 00114: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057593186, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1988 - val_loss: 0.2549\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.24999\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 00115: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057312654, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1990 - val_loss: 0.2532\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.24999\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 00116: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057033484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1971 - val_loss: 0.2550\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.24999\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 00117: LearningRateScheduler reducing learning rate to tf.Tensor(0.00056755677, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1976 - val_loss: 0.2504\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.24999\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 00118: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005647922, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1975 - val_loss: 0.2530\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.24999\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 00119: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005620411, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1962 - val_loss: 0.2477\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.24999 to 0.24772, saving model to folds3.hdf5\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 00120: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055930344, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1940 - val_loss: 0.2498\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.24772\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 00121: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055657903, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1947 - val_loss: 0.2588\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.24772\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 00122: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055386795, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1936 - val_loss: 0.2487\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.24772\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 00123: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005511701, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1941 - val_loss: 0.2490\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.24772\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 00124: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005484854, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1919 - val_loss: 0.2591\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.24772\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 00125: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005458137, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2108 - val_loss: 0.2476\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.24772 to 0.24764, saving model to folds3.hdf5\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 00126: LearningRateScheduler reducing learning rate to tf.Tensor(0.00054315507, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1940 - val_loss: 0.2595\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.24764\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 00127: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005405093, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2018 - val_loss: 0.2615\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.24764\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 00128: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005378765, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1951 - val_loss: 0.2515\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.24764\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 00129: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005352565, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1917 - val_loss: 0.2514\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.24764\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 00130: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005326493, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1876 - val_loss: 0.2450\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.24764 to 0.24504, saving model to folds3.hdf5\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 00131: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005300548, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 49ms/step - loss: 0.1856 - val_loss: 0.2424\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.24504 to 0.24243, saving model to folds3.hdf5\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 00132: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005274729, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1860 - val_loss: 0.2499\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.24243\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 00133: LearningRateScheduler reducing learning rate to tf.Tensor(0.00052490365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1899 - val_loss: 0.2435\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.24243\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 00134: LearningRateScheduler reducing learning rate to tf.Tensor(0.00052234676, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1848 - val_loss: 0.2491\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.24243\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 00135: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005198025, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1849 - val_loss: 0.2436\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.24243\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 00136: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005172705, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1826 - val_loss: 0.2471\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.24243\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 00137: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051475083, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1836 - val_loss: 0.2542\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.24243\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 00138: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051224354, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1873 - val_loss: 0.2449\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.24243\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 00139: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005097484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1812 - val_loss: 0.2439\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.24243\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 00140: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005072654, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1834 - val_loss: 0.2454\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.24243\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 00141: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005047946, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1856 - val_loss: 0.2419\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.24243 to 0.24189, saving model to folds3.hdf5\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 00142: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005023357, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1805 - val_loss: 0.2424\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.24189\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 00143: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049988885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1815 - val_loss: 0.2442\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.24189\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 00144: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004974539, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1825 - val_loss: 0.2426\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.24189\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 00145: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004950308, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1794 - val_loss: 0.2417\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.24189 to 0.24170, saving model to folds3.hdf5\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 00146: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004926195, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1773 - val_loss: 0.2388\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.24170 to 0.23883, saving model to folds3.hdf5\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 00147: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049022, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1761 - val_loss: 0.2415\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.23883\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 00148: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048783212, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1767 - val_loss: 0.2390\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.23883\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 00149: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048545588, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1791 - val_loss: 0.2397\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.23883\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 00150: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048309125, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1765 - val_loss: 0.2420\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.23883\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 00151: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048073815, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1755 - val_loss: 0.2519\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.23883\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 00152: LearningRateScheduler reducing learning rate to tf.Tensor(0.00047839645, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1796 - val_loss: 0.2401\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.23883\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 00153: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004760662, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1733 - val_loss: 0.2408\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.23883\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 00154: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004737473, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1742 - val_loss: 0.2404\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.23883\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 00155: LearningRateScheduler reducing learning rate to tf.Tensor(0.00047143968, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1719 - val_loss: 0.2394\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.23883\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 00156: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004691433, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1738 - val_loss: 0.2423\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.23883\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 00157: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046685815, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1731 - val_loss: 0.2381\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.23883 to 0.23806, saving model to folds3.hdf5\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 00158: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046458407, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1723 - val_loss: 0.2378\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.23806 to 0.23778, saving model to folds3.hdf5\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 00159: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046232107, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1708 - val_loss: 0.2408\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.23778\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 00160: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046006907, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1714 - val_loss: 0.2392\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.23778\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 00161: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045782814, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1720 - val_loss: 0.2373\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.23778 to 0.23726, saving model to folds3.hdf5\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 00162: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045559806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1695 - val_loss: 0.2524\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.23726\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 00163: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045337883, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.1773 - val_loss: 0.2374\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.23726\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 00164: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045117046, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1679 - val_loss: 0.2380\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.23726\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 00165: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044897277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1720 - val_loss: 0.2444\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.23726\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 00166: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044678585, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1735 - val_loss: 0.2378\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.23726\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 00167: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004446096, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1708 - val_loss: 0.2356\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.23726 to 0.23563, saving model to folds3.hdf5\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 00168: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004424439, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1675 - val_loss: 0.2382\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.23563\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 00169: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044028874, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1681 - val_loss: 0.2371\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.23563\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 00170: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043814414, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1696 - val_loss: 0.2374\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.23563\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 00171: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043600993, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1657 - val_loss: 0.2398\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.23563\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 00172: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043388613, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1682 - val_loss: 0.2371\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.23563\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 00173: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004317727, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1661 - val_loss: 0.2450\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.23563\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 00174: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004296695, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1696 - val_loss: 0.2331\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.23563 to 0.23313, saving model to folds3.hdf5\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 00175: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004275766, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1621 - val_loss: 0.2392\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.23313\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 00176: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042549393, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1667 - val_loss: 0.2355\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.23313\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 00177: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042342133, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1653 - val_loss: 0.2348\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.23313\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 00178: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042135885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1611 - val_loss: 0.2354\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.23313\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 00179: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041930642, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1626 - val_loss: 0.2400\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.23313\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 00180: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041726397, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1655 - val_loss: 0.2384\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.23313\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 00181: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041523148, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1654 - val_loss: 0.2377\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.23313\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 00182: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041320888, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1633 - val_loss: 0.2335\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.23313\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 00183: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041119618, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1602 - val_loss: 0.2351\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.23313\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 00184: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040919325, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1598 - val_loss: 0.2337\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.23313\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 00185: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040720004, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1601 - val_loss: 0.2367\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.23313\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 00186: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004052166, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1600 - val_loss: 0.2381\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.23313\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 00187: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004032428, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1622 - val_loss: 0.2351\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.23313\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 00188: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004012786, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1587 - val_loss: 0.2350\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.23313\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 00189: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039932402, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1608 - val_loss: 0.2375\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.23313\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 00190: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039737887, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1588 - val_loss: 0.2332\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.23313\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 00191: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039544326, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1576 - val_loss: 0.2341\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.23313\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 00192: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039351705, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1567 - val_loss: 0.2329\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.23313 to 0.23288, saving model to folds3.hdf5\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 00193: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039160028, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1562 - val_loss: 0.2349\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.23288\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 00194: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038969278, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1589 - val_loss: 0.2327\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.23288 to 0.23273, saving model to folds3.hdf5\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 00195: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003877946, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1592 - val_loss: 0.2342\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.23273\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 00196: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038590565, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1578 - val_loss: 0.2337\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.23273\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 00197: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003840259, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 50ms/step - loss: 0.1571 - val_loss: 0.2351\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.23273\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 00198: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038215535, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1565 - val_loss: 0.2309\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.23273 to 0.23086, saving model to folds3.hdf5\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 00199: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038029387, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1556 - val_loss: 0.2357\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.23086\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 00200: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037844144, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1572 - val_loss: 0.2325\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.23086\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 00201: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037659804, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1549 - val_loss: 0.2344\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.23086\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 00202: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037476368, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1546 - val_loss: 0.2364\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.23086\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 00203: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037293817, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1565 - val_loss: 0.2330\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.23086\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 00204: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003711216, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1536 - val_loss: 0.2313\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.23086\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 00205: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003693139, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1534 - val_loss: 0.2310\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.23086\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 00206: LearningRateScheduler reducing learning rate to tf.Tensor(0.000367515, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1518 - val_loss: 0.2322\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.23086\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 00207: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036572482, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1517 - val_loss: 0.2331\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.23086\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 00208: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003639434, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1561 - val_loss: 0.2322\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.23086\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 00209: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036217063, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1537 - val_loss: 0.2315\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.23086\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 00210: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036040647, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1533 - val_loss: 0.2300\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.23086 to 0.22998, saving model to folds3.hdf5\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 00211: LearningRateScheduler reducing learning rate to tf.Tensor(0.00035865093, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1503 - val_loss: 0.2321\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.22998\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 00212: LearningRateScheduler reducing learning rate to tf.Tensor(0.000356904, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1525 - val_loss: 0.2318\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.22998\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 00213: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003551655, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1506 - val_loss: 0.2297\n",
      "\n",
      "Epoch 00213: val_loss improved from 0.22998 to 0.22966, saving model to folds3.hdf5\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 00214: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003534355, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1505 - val_loss: 0.2303\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.22966\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 00215: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003517139, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1498 - val_loss: 0.2327\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.22966\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 00216: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003500007, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1503 - val_loss: 0.2334\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.22966\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 00217: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034829587, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1509 - val_loss: 0.2317\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.22966\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 00218: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034659932, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1513 - val_loss: 0.2310\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.22966\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 00219: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034491107, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1482 - val_loss: 0.2306\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.22966\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 00220: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034323102, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1481 - val_loss: 0.2314\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.22966\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 00221: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034155912, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1483 - val_loss: 0.2329\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.22966\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 00222: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033989537, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1486 - val_loss: 0.2303\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.22966\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 00223: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033823974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1483 - val_loss: 0.2337\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.22966\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 00224: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003365922, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1520 - val_loss: 0.2317\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.22966\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 00225: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033495267, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1477 - val_loss: 0.2308\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.22966\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 00226: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003333211, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1472 - val_loss: 0.2313\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.22966\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 00227: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033169755, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1468 - val_loss: 0.2294\n",
      "\n",
      "Epoch 00227: val_loss improved from 0.22966 to 0.22942, saving model to folds3.hdf5\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 00228: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033008185, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1461 - val_loss: 0.2306\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.22942\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 00229: LearningRateScheduler reducing learning rate to tf.Tensor(0.000328474, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1482 - val_loss: 0.2281\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.22942 to 0.22806, saving model to folds3.hdf5\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 00230: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032687403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1452 - val_loss: 0.2325\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.22806\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 00231: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003252818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1489 - val_loss: 0.2301\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.22806\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 00232: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032369737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1460 - val_loss: 0.2296\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.22806\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 00233: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032212064, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1449 - val_loss: 0.2300\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.22806\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 00234: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032055163, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1450 - val_loss: 0.2343\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.22806\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 00235: LearningRateScheduler reducing learning rate to tf.Tensor(0.00031899018, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1470 - val_loss: 0.2313\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.22806\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 00236: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003174364, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1445 - val_loss: 0.2290\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.22806\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 00237: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003158902, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1436 - val_loss: 0.2297\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.22806\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 00238: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003143515, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1438 - val_loss: 0.2293\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.22806\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 00239: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003128203, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1426 - val_loss: 0.2304\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.22806\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 00240: LearningRateScheduler reducing learning rate to tf.Tensor(0.00031129655, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1435 - val_loss: 0.2299\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.22806\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 00241: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003097802, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1450 - val_loss: 0.2291\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.22806\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 00242: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003082713, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1426 - val_loss: 0.2282\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.22806\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 00243: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003067697, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1412 - val_loss: 0.2311\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.22806\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 00244: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030527546, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1427 - val_loss: 0.2316\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.22806\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 00245: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030378843, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.1413 - val_loss: 0.2290\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.22806\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 00246: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003023087, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1416 - val_loss: 0.2292\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.22806\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 00247: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030083617, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1432 - val_loss: 0.2313\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.22806\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 00248: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002993708, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1448 - val_loss: 0.2301\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.22806\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 00249: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029791257, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1413 - val_loss: 0.2316\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.22806\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 00250: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029646145, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1435 - val_loss: 0.2299\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.22806\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 00251: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029501738, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1409 - val_loss: 0.2277\n",
      "\n",
      "Epoch 00251: val_loss improved from 0.22806 to 0.22771, saving model to folds3.hdf5\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 00252: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029358038, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1400 - val_loss: 0.2285\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.22771\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 00253: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029215033, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1388 - val_loss: 0.2270\n",
      "\n",
      "Epoch 00253: val_loss improved from 0.22771 to 0.22700, saving model to folds3.hdf5\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 00254: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029072727, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1393 - val_loss: 0.2287\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.22700\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 00255: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028931117, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1391 - val_loss: 0.2290\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.22700\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 00256: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028790193, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1394 - val_loss: 0.2289\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.22700\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 00257: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028649953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1386 - val_loss: 0.2286\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.22700\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 00258: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028510403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1389 - val_loss: 0.2284\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.22700\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 00259: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002837153, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1390 - val_loss: 0.2300\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.22700\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 00260: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002823333, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1394 - val_loss: 0.2280\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.22700\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 00261: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028095808, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1382 - val_loss: 0.2295\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.22700\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 00262: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027958953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1422 - val_loss: 0.2281\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.22700\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 00263: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027822764, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1388 - val_loss: 0.2304\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.22700\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 00264: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027687242, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1381 - val_loss: 0.2272\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.22700\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 00265: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027552375, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1363 - val_loss: 0.2290\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.22700\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 00266: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002741817, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1412 - val_loss: 0.2286\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.22700\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 00267: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027284614, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1387 - val_loss: 0.2302\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.22700\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 00268: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027151714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1370 - val_loss: 0.2284\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.22700\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 00269: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027019458, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1356 - val_loss: 0.2288\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.22700\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 00270: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026887844, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1360 - val_loss: 0.2274\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.22700\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 00271: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026756877, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1351 - val_loss: 0.2279\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.22700\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 00272: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026626544, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1356 - val_loss: 0.2277\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.22700\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 00273: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026496846, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1360 - val_loss: 0.2272\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.22700\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 00274: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026367782, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1352 - val_loss: 0.2293\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.22700\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 00275: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026239344, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1355 - val_loss: 0.2275\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.22700\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 00276: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026111532, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1363 - val_loss: 0.2281\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.22700\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 00277: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025984345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1354 - val_loss: 0.2285\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.22700\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 00278: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025857775, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1360 - val_loss: 0.2288\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.22700\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 00279: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002573182, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1344 - val_loss: 0.2279\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.22700\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 00280: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025606484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1354 - val_loss: 0.2279\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.22700\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 00281: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025481754, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1339 - val_loss: 0.2280\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.22700\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 00282: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025357632, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1359 - val_loss: 0.2278\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.22700\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 00283: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025234115, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1349 - val_loss: 0.2277\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.22700\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 00284: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025111204, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1333 - val_loss: 0.2280\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.22700\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 00285: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024988884, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1333 - val_loss: 0.2279\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.22700\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 00286: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024867163, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1345 - val_loss: 0.2282\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.22700\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 00287: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024746038, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1347 - val_loss: 0.2276\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.22700\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 00288: LearningRateScheduler reducing learning rate to tf.Tensor(0.000246255, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1323 - val_loss: 0.2274\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.22700\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 00289: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024505547, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1318 - val_loss: 0.2282\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.22700\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 00290: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024386184, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1322 - val_loss: 0.2262\n",
      "\n",
      "Epoch 00290: val_loss improved from 0.22700 to 0.22621, saving model to folds3.hdf5\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 00291: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024267398, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1320 - val_loss: 0.2268\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.22621\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 00292: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024149191, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1340 - val_loss: 0.2276\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.22621\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 00293: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024031562, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 50ms/step - loss: 0.1314 - val_loss: 0.2271\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.22621\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 00294: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023914504, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1329 - val_loss: 0.2274\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.22621\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 00295: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023798017, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1315 - val_loss: 0.2276\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.22621\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 00296: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023682097, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1307 - val_loss: 0.2263\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.22621\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 00297: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023566742, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1306 - val_loss: 0.2276\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.22621\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 00298: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023451951, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1310 - val_loss: 0.2260\n",
      "\n",
      "Epoch 00298: val_loss improved from 0.22621 to 0.22601, saving model to folds3.hdf5\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 00299: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023337714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1306 - val_loss: 0.2274\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.22601\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 00300: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023224037, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 41ms/step - loss: 0.1306 - val_loss: 0.2274\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.22601\n",
      "(50300, 80)\n",
      "--------------- > Fold 5 < ---------------\n",
      "CNN: (None, 72, 256)\n",
      "LSTM: (None, 80, 256)\n",
      "Com: (None, 152, 256)\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 26s 193ms/step - loss: 3.6531 - val_loss: 0.8495\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.84949, saving model to folds4.hdf5\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.7694 - val_loss: 0.6308\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.84949 to 0.63079, saving model to folds4.hdf5\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.6065 - val_loss: 0.6116\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.63079 to 0.61158, saving model to folds4.hdf5\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.5549 - val_loss: 0.4990\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.61158 to 0.49903, saving model to folds4.hdf5\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.5085 - val_loss: 0.5398\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.49903\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4993 - val_loss: 0.4912\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.49903 to 0.49116, saving model to folds4.hdf5\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4611 - val_loss: 0.4407\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.49116 to 0.44075, saving model to folds4.hdf5\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4497 - val_loss: 0.4421\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.44075\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4340 - val_loss: 0.4720\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.44075\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4362 - val_loss: 0.4276\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.44075 to 0.42756, saving model to folds4.hdf5\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4049 - val_loss: 0.4236\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.42756 to 0.42360, saving model to folds4.hdf5\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4121 - val_loss: 0.4044\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.42360 to 0.40445, saving model to folds4.hdf5\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3903 - val_loss: 0.3937\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.40445 to 0.39371, saving model to folds4.hdf5\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3886 - val_loss: 0.4020\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.39371\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3774 - val_loss: 0.4004\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.39371\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3830 - val_loss: 0.3941\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.39371\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3812 - val_loss: 0.3990\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.39371\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3693 - val_loss: 0.3664\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.39371 to 0.36642, saving model to folds4.hdf5\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3684 - val_loss: 0.3663\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.36642 to 0.36626, saving model to folds4.hdf5\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3493 - val_loss: 0.3545\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.36626 to 0.35450, saving model to folds4.hdf5\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3425 - val_loss: 0.3655\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.35450\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 49ms/step - loss: 0.3591 - val_loss: 0.3448\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.35450 to 0.34482, saving model to folds4.hdf5\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3464 - val_loss: 0.3421\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.34482 to 0.34209, saving model to folds4.hdf5\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3474 - val_loss: 0.3575\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.34209\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3379 - val_loss: 0.3664\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.34209\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3385 - val_loss: 0.3335\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.34209 to 0.33351, saving model to folds4.hdf5\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3232 - val_loss: 0.3765\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33351\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3405 - val_loss: 0.3428\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33351\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3185 - val_loss: 0.3486\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33351\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3249 - val_loss: 0.3179\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.33351 to 0.31791, saving model to folds4.hdf5\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3105 - val_loss: 0.3197\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.31791\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3192 - val_loss: 0.3239\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.31791\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3063 - val_loss: 0.3161\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.31791 to 0.31607, saving model to folds4.hdf5\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3038 - val_loss: 0.3455\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.31607\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3151 - val_loss: 0.3127\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.31607 to 0.31269, saving model to folds4.hdf5\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3039 - val_loss: 0.3188\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.31269\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3026 - val_loss: 0.3057\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.31269 to 0.30570, saving model to folds4.hdf5\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2986 - val_loss: 0.3048\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.30570 to 0.30480, saving model to folds4.hdf5\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2958 - val_loss: 0.3192\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.30480\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3034 - val_loss: 0.3100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.30480\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2877 - val_loss: 0.3095\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.30480\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2869 - val_loss: 0.3154\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.30480\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2893 - val_loss: 0.3201\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.30480\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2898 - val_loss: 0.3092\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.30480\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2831 - val_loss: 0.3049\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.30480\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2847 - val_loss: 0.3098\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.30480\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3007 - val_loss: 0.3032\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.30480 to 0.30319, saving model to folds4.hdf5\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2782 - val_loss: 0.2935\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.30319 to 0.29345, saving model to folds4.hdf5\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2769 - val_loss: 0.2934\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.29345 to 0.29336, saving model to folds4.hdf5\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2755 - val_loss: 0.3035\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.29336\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2768 - val_loss: 0.2930\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.29336 to 0.29296, saving model to folds4.hdf5\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2700 - val_loss: 0.2943\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.29296\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2742 - val_loss: 0.2884\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.29296 to 0.28839, saving model to folds4.hdf5\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2687 - val_loss: 0.2862\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.28839 to 0.28618, saving model to folds4.hdf5\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2646 - val_loss: 0.2951\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.28618\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2734 - val_loss: 0.2937\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.28618\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2717 - val_loss: 0.2824\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.28618 to 0.28240, saving model to folds4.hdf5\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2609 - val_loss: 0.2878\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.28240\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2598 - val_loss: 0.2818\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.28240 to 0.28182, saving model to folds4.hdf5\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.2588 - val_loss: 0.2913\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.28182\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2631 - val_loss: 0.2876\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.28182\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2612 - val_loss: 0.2760\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.28182 to 0.27604, saving model to folds4.hdf5\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007387921, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2551 - val_loss: 0.2795\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.27604\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to tf.Tensor(0.00073519343, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2536 - val_loss: 0.2756\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.27604 to 0.27558, saving model to folds4.hdf5\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007316123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2533 - val_loss: 0.2761\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.27558\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007280487, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2477 - val_loss: 0.2704\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.27558 to 0.27038, saving model to folds4.hdf5\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007245024, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2479 - val_loss: 0.2727\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.27038\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007209733, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2440 - val_loss: 0.2721\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.27038\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071746146, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2483 - val_loss: 0.2833\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.27038\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007139667, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2448 - val_loss: 0.2856\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.27038\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071048894, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2545 - val_loss: 0.2777\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.27038\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007070282, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2496 - val_loss: 0.2654\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.27038 to 0.26541, saving model to folds4.hdf5\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007035842, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2432 - val_loss: 0.2780\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.26541\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to tf.Tensor(0.00070015714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2465 - val_loss: 0.2646\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.26541 to 0.26459, saving model to folds4.hdf5\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006967467, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2345 - val_loss: 0.2648\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.26459\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to tf.Tensor(0.00069335283, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2378 - val_loss: 0.2562\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.26459 to 0.25620, saving model to folds4.hdf5\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006899755, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2383 - val_loss: 0.2726\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.25620\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068661466, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2375 - val_loss: 0.2787\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.25620\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068327016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2442 - val_loss: 0.2602\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.25620\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067994196, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2301 - val_loss: 0.2737\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.25620\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067663, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2313 - val_loss: 0.2585\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.25620\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006733342, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2293 - val_loss: 0.2566\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.25620\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067005435, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2272 - val_loss: 0.2579\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.25620\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006667905, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2263 - val_loss: 0.2606\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.25620\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006635426, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2261 - val_loss: 0.2665\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.25620\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006603105, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2345 - val_loss: 0.2596\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.25620\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006570942, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2247 - val_loss: 0.2510\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.25620 to 0.25100, saving model to folds4.hdf5\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065389345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2245 - val_loss: 0.2572\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.25100\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065070833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2226 - val_loss: 0.2500\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.25100 to 0.25003, saving model to folds4.hdf5\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to tf.Tensor(0.00064753875, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2201 - val_loss: 0.2613\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.25003\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006443846, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2230 - val_loss: 0.2523\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.25003\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006412458, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2177 - val_loss: 0.2633\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.25003\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063812226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2192 - val_loss: 0.2555\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.25003\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063501403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2134 - val_loss: 0.2492\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.25003 to 0.24916, saving model to folds4.hdf5\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006319209, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2138 - val_loss: 0.2560\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.24916\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006288428, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2202 - val_loss: 0.2486\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.24916 to 0.24864, saving model to folds4.hdf5\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to tf.Tensor(0.00062577974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2143 - val_loss: 0.2582\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.24864\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006227316, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2134 - val_loss: 0.2438\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.24864 to 0.24378, saving model to folds4.hdf5\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061969826, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2124 - val_loss: 0.2621\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.24378\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 00100: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006166797, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2163 - val_loss: 0.2458\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.24378\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 00101: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061367586, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2094 - val_loss: 0.2519\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.24378\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 00102: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061068666, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2128 - val_loss: 0.2499\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.24378\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 00103: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006077121, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2088 - val_loss: 0.2458\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.24378\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 00104: LearningRateScheduler reducing learning rate to tf.Tensor(0.00060475187, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2068 - val_loss: 0.2438\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.24378 to 0.24376, saving model to folds4.hdf5\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 00105: LearningRateScheduler reducing learning rate to tf.Tensor(0.00060180615, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2037 - val_loss: 0.2420\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.24376 to 0.24201, saving model to folds4.hdf5\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 00106: LearningRateScheduler reducing learning rate to tf.Tensor(0.00059887476, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2074 - val_loss: 0.2443\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.24201\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 00107: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005959577, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2047 - val_loss: 0.2442\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.24201\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 00108: LearningRateScheduler reducing learning rate to tf.Tensor(0.00059305475, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2037 - val_loss: 0.2525\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.24201\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 00109: LearningRateScheduler reducing learning rate to tf.Tensor(0.000590166, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2084 - val_loss: 0.2433\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.24201\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 00110: LearningRateScheduler reducing learning rate to tf.Tensor(0.00058729126, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2007 - val_loss: 0.2415\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.24201 to 0.24154, saving model to folds4.hdf5\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 00111: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005844306, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.2055 - val_loss: 0.2536\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.24154\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 00112: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005815838, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2138 - val_loss: 0.2552\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.24154\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 00113: LearningRateScheduler reducing learning rate to tf.Tensor(0.000578751, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2123 - val_loss: 0.2416\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.24154\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 00114: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057593186, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2018 - val_loss: 0.2399\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.24154 to 0.23994, saving model to folds4.hdf5\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 00115: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057312654, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1985 - val_loss: 0.2363\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.23994 to 0.23631, saving model to folds4.hdf5\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 00116: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057033484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1953 - val_loss: 0.2384\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.23631\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 00117: LearningRateScheduler reducing learning rate to tf.Tensor(0.00056755677, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1998 - val_loss: 0.2387\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.23631\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 00118: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005647922, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2000 - val_loss: 0.2463\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.23631\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 00119: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005620411, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2074 - val_loss: 0.2462\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.23631\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 00120: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055930344, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2006 - val_loss: 0.2409\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.23631\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 00121: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055657903, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1965 - val_loss: 0.2503\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.23631\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 00122: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055386795, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1978 - val_loss: 0.2374\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.23631\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 00123: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005511701, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1963 - val_loss: 0.2404\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.23631\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 00124: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005484854, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1965 - val_loss: 0.2339\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.23631 to 0.23392, saving model to folds4.hdf5\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 00125: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005458137, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1923 - val_loss: 0.2335\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.23392 to 0.23355, saving model to folds4.hdf5\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 00126: LearningRateScheduler reducing learning rate to tf.Tensor(0.00054315507, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1883 - val_loss: 0.2422\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.23355\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 00127: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005405093, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1979 - val_loss: 0.2352\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.23355\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 00128: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005378765, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1875 - val_loss: 0.2363\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.23355\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 00129: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005352565, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1917 - val_loss: 0.2343\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.23355\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 00130: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005326493, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1866 - val_loss: 0.2533\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.23355\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 00131: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005300548, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1908 - val_loss: 0.2393\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.23355\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 00132: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005274729, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1883 - val_loss: 0.2322\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.23355 to 0.23223, saving model to folds4.hdf5\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 00133: LearningRateScheduler reducing learning rate to tf.Tensor(0.00052490365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1894 - val_loss: 0.2404\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.23223\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 00134: LearningRateScheduler reducing learning rate to tf.Tensor(0.00052234676, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1848 - val_loss: 0.2342\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.23223\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 00135: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005198025, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1885 - val_loss: 0.2300\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.23223 to 0.23001, saving model to folds4.hdf5\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 00136: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005172705, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1824 - val_loss: 0.2339\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.23001\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 00137: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051475083, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1845 - val_loss: 0.2343\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.23001\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 00138: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051224354, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1841 - val_loss: 0.2342\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.23001\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 00139: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005097484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1845 - val_loss: 0.2306\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.23001\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 00140: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005072654, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1836 - val_loss: 0.2345\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.23001\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 00141: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005047946, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1852 - val_loss: 0.2315\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.23001\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 00142: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005023357, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1805 - val_loss: 0.2317\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.23001\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 00143: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049988885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1800 - val_loss: 0.2341\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.23001\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 00144: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004974539, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 52ms/step - loss: 0.1813 - val_loss: 0.2294\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.23001 to 0.22936, saving model to folds4.hdf5\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 00145: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004950308, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1793 - val_loss: 0.2290\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.22936 to 0.22895, saving model to folds4.hdf5\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 00146: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004926195, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1780 - val_loss: 0.2405\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.22895\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 00147: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049022, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1802 - val_loss: 0.2353\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.22895\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 00148: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048783212, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1814 - val_loss: 0.2327\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.22895\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 00149: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048545588, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1786 - val_loss: 0.2263\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.22895 to 0.22629, saving model to folds4.hdf5\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 00150: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048309125, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1759 - val_loss: 0.2299\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.22629\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 00151: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048073815, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1753 - val_loss: 0.2276\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.22629\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 00152: LearningRateScheduler reducing learning rate to tf.Tensor(0.00047839645, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1773 - val_loss: 0.2270\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.22629\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 00153: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004760662, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1749 - val_loss: 0.2263\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.22629\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 00154: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004737473, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1740 - val_loss: 0.2310\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.22629\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 00155: LearningRateScheduler reducing learning rate to tf.Tensor(0.00047143968, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1768 - val_loss: 0.2263\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.22629 to 0.22626, saving model to folds4.hdf5\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 00156: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004691433, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1718 - val_loss: 0.2263\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.22626\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 00157: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046685815, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1751 - val_loss: 0.2266\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.22626\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 00158: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046458407, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1770 - val_loss: 0.2251\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.22626 to 0.22508, saving model to folds4.hdf5\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 00159: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046232107, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1709 - val_loss: 0.2258\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.22508\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 00160: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046006907, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1723 - val_loss: 0.2285\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.22508\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 00161: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045782814, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1732 - val_loss: 0.2226\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.22508 to 0.22257, saving model to folds4.hdf5\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 00162: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045559806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1693 - val_loss: 0.2265\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.22257\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 00163: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045337883, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1678 - val_loss: 0.2272\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.22257\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 00164: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045117046, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1702 - val_loss: 0.2226\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.22257 to 0.22255, saving model to folds4.hdf5\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 00165: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044897277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1713 - val_loss: 0.2238\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.22255\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 00166: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044678585, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1685 - val_loss: 0.2261\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.22255\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 00167: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004446096, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1682 - val_loss: 0.2268\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.22255\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 00168: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004424439, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1676 - val_loss: 0.2301\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.22255\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 00169: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044028874, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1746 - val_loss: 0.2264\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.22255\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 00170: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043814414, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1698 - val_loss: 0.2262\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.22255\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 00171: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043600993, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1711 - val_loss: 0.2240\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.22255\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 00172: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043388613, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1662 - val_loss: 0.2247\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.22255\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 00173: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004317727, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1690 - val_loss: 0.2220\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.22255 to 0.22198, saving model to folds4.hdf5\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 00174: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004296695, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1649 - val_loss: 0.2313\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.22198\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 00175: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004275766, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1681 - val_loss: 0.2266\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.22198\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 00176: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042549393, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1659 - val_loss: 0.2236\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.22198\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 00177: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042342133, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1632 - val_loss: 0.2254\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.22198\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 00178: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042135885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1685 - val_loss: 0.2236\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.22198\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 00179: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041930642, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1647 - val_loss: 0.2265\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.22198\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 00180: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041726397, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1630 - val_loss: 0.2279\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.22198\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 00181: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041523148, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1639 - val_loss: 0.2227\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.22198\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 00182: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041320888, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1608 - val_loss: 0.2223\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.22198\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 00183: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041119618, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1614 - val_loss: 0.2225\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.22198\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 00184: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040919325, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1607 - val_loss: 0.2270\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.22198\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 00185: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040720004, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1617 - val_loss: 0.2230\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.22198\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 00186: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004052166, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1624 - val_loss: 0.2236\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.22198\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 00187: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004032428, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1609 - val_loss: 0.2239\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.22198\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 00188: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004012786, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1607 - val_loss: 0.2271\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.22198\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 00189: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039932402, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.1650 - val_loss: 0.2253\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.22198\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 00190: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039737887, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1607 - val_loss: 0.2220\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.22198\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 00191: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039544326, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1607 - val_loss: 0.2215\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.22198 to 0.22152, saving model to folds4.hdf5\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 00192: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039351705, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1602 - val_loss: 0.2229\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.22152\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 00193: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039160028, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1583 - val_loss: 0.2205\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.22152 to 0.22055, saving model to folds4.hdf5\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 00194: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038969278, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1567 - val_loss: 0.2215\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.22055\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 00195: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003877946, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1591 - val_loss: 0.2269\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.22055\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 00196: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038590565, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1593 - val_loss: 0.2210\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.22055\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 00197: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003840259, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1576 - val_loss: 0.2242\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.22055\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 00198: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038215535, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1572 - val_loss: 0.2219\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.22055\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 00199: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038029387, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1574 - val_loss: 0.2201\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.22055 to 0.22010, saving model to folds4.hdf5\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 00200: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037844144, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1550 - val_loss: 0.2212\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.22010\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 00201: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037659804, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1549 - val_loss: 0.2225\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.22010\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 00202: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037476368, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1554 - val_loss: 0.2199\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.22010 to 0.21991, saving model to folds4.hdf5\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 00203: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037293817, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1563 - val_loss: 0.2193\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.21991 to 0.21930, saving model to folds4.hdf5\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 00204: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003711216, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1536 - val_loss: 0.2213\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.21930\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 00205: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003693139, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1556 - val_loss: 0.2211\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.21930\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 00206: LearningRateScheduler reducing learning rate to tf.Tensor(0.000367515, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1555 - val_loss: 0.2201\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.21930\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 00207: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036572482, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1536 - val_loss: 0.2189\n",
      "\n",
      "Epoch 00207: val_loss improved from 0.21930 to 0.21892, saving model to folds4.hdf5\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 00208: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003639434, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1547 - val_loss: 0.2200\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.21892\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 00209: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036217063, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1534 - val_loss: 0.2192\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.21892\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 00210: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036040647, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1553 - val_loss: 0.2209\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.21892\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 00211: LearningRateScheduler reducing learning rate to tf.Tensor(0.00035865093, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1524 - val_loss: 0.2223\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.21892\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 00212: LearningRateScheduler reducing learning rate to tf.Tensor(0.000356904, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1567 - val_loss: 0.2219\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.21892\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 00213: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003551655, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1521 - val_loss: 0.2211\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.21892\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 00214: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003534355, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1529 - val_loss: 0.2188\n",
      "\n",
      "Epoch 00214: val_loss improved from 0.21892 to 0.21877, saving model to folds4.hdf5\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 00215: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003517139, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1510 - val_loss: 0.2177\n",
      "\n",
      "Epoch 00215: val_loss improved from 0.21877 to 0.21772, saving model to folds4.hdf5\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 00216: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003500007, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1513 - val_loss: 0.2205\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.21772\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 00217: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034829587, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 46ms/step - loss: 0.1488 - val_loss: 0.2174\n",
      "\n",
      "Epoch 00217: val_loss improved from 0.21772 to 0.21736, saving model to folds4.hdf5\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 00218: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034659932, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1489 - val_loss: 0.2177\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.21736\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 00219: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034491107, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1496 - val_loss: 0.2206\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.21736\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 00220: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034323102, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1515 - val_loss: 0.2180\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.21736\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 00221: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034155912, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1486 - val_loss: 0.2173\n",
      "\n",
      "Epoch 00221: val_loss improved from 0.21736 to 0.21727, saving model to folds4.hdf5\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 00222: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033989537, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1489 - val_loss: 0.2203\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.21727\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 00223: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033823974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1500 - val_loss: 0.2181\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.21727\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 00224: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003365922, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1485 - val_loss: 0.2193\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.21727\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 00225: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033495267, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1495 - val_loss: 0.2185\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.21727\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 00226: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003333211, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1478 - val_loss: 0.2220\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.21727\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 00227: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033169755, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1491 - val_loss: 0.2195\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.21727\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 00228: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033008185, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.1478 - val_loss: 0.2204\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.21727\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 00229: LearningRateScheduler reducing learning rate to tf.Tensor(0.000328474, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1486 - val_loss: 0.2196\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.21727\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 00230: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032687403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1501 - val_loss: 0.2160\n",
      "\n",
      "Epoch 00230: val_loss improved from 0.21727 to 0.21599, saving model to folds4.hdf5\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 00231: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003252818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1453 - val_loss: 0.2202\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.21599\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 00232: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032369737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1473 - val_loss: 0.2177\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.21599\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 00233: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032212064, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1464 - val_loss: 0.2170\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.21599\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 00234: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032055163, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1472 - val_loss: 0.2202\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.21599\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 00235: LearningRateScheduler reducing learning rate to tf.Tensor(0.00031899018, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1458 - val_loss: 0.2170\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.21599\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 00236: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003174364, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1444 - val_loss: 0.2220\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.21599\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 00237: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003158902, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1450 - val_loss: 0.2163\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.21599\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 00238: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003143515, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1437 - val_loss: 0.2197\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.21599\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 00239: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003128203, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1448 - val_loss: 0.2179\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.21599\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 00240: LearningRateScheduler reducing learning rate to tf.Tensor(0.00031129655, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1457 - val_loss: 0.2176\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.21599\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 00241: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003097802, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1438 - val_loss: 0.2166\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.21599\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 00242: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003082713, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1430 - val_loss: 0.2196\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.21599\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 00243: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003067697, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1446 - val_loss: 0.2161\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.21599\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 00244: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030527546, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1425 - val_loss: 0.2153\n",
      "\n",
      "Epoch 00244: val_loss improved from 0.21599 to 0.21533, saving model to folds4.hdf5\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 00245: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030378843, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1424 - val_loss: 0.2170\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.21533\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 00246: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003023087, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1419 - val_loss: 0.2164\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.21533\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 00247: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030083617, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1416 - val_loss: 0.2169\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.21533\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 00248: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002993708, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1425 - val_loss: 0.2174\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.21533\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 00249: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029791257, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1414 - val_loss: 0.2168\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.21533\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 00250: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029646145, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1418 - val_loss: 0.2180\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.21533\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 00251: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029501738, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1416 - val_loss: 0.2150\n",
      "\n",
      "Epoch 00251: val_loss improved from 0.21533 to 0.21497, saving model to folds4.hdf5\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 00252: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029358038, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1407 - val_loss: 0.2167\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.21497\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 00253: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029215033, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1409 - val_loss: 0.2164\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.21497\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 00254: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029072727, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1413 - val_loss: 0.2157\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.21497\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 00255: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028931117, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1401 - val_loss: 0.2194\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.21497\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 00256: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028790193, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1417 - val_loss: 0.2177\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.21497\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 00257: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028649953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1411 - val_loss: 0.2158\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.21497\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 00258: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028510403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1414 - val_loss: 0.2178\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.21497\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 00259: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002837153, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1401 - val_loss: 0.2158\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.21497\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 00260: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002823333, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1401 - val_loss: 0.2159\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.21497\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 00261: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028095808, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1396 - val_loss: 0.2153\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.21497\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 00262: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027958953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1382 - val_loss: 0.2188\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.21497\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 00263: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027822764, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1405 - val_loss: 0.2160\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.21497\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 00264: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027687242, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1381 - val_loss: 0.2151\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.21497\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 00265: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027552375, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1377 - val_loss: 0.2183\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.21497\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 00266: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002741817, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1398 - val_loss: 0.2168\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.21497\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 00267: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027284614, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1376 - val_loss: 0.2154\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.21497\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 00268: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027151714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1364 - val_loss: 0.2167\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.21497\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 00269: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027019458, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1368 - val_loss: 0.2171\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.21497\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 00270: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026887844, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1380 - val_loss: 0.2164\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.21497\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 00271: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026756877, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1374 - val_loss: 0.2154\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.21497\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 00272: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026626544, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1360 - val_loss: 0.2149\n",
      "\n",
      "Epoch 00272: val_loss improved from 0.21497 to 0.21492, saving model to folds4.hdf5\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 00273: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026496846, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1372 - val_loss: 0.2171\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.21492\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 00274: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026367782, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1381 - val_loss: 0.2180\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.21492\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 00275: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026239344, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1376 - val_loss: 0.2158\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.21492\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 00276: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026111532, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1360 - val_loss: 0.2154\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.21492\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 00277: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025984345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1356 - val_loss: 0.2145\n",
      "\n",
      "Epoch 00277: val_loss improved from 0.21492 to 0.21453, saving model to folds4.hdf5\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 00278: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025857775, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.1349 - val_loss: 0.2156\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.21453\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 00279: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002573182, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1354 - val_loss: 0.2171\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.21453\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 00280: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025606484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1348 - val_loss: 0.2149\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.21453\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 00281: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025481754, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1340 - val_loss: 0.2164\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.21453\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 00282: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025357632, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1361 - val_loss: 0.2152\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.21453\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 00283: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025234115, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1349 - val_loss: 0.2152\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.21453\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 00284: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025111204, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1338 - val_loss: 0.2146\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.21453\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 00285: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024988884, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1338 - val_loss: 0.2145\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.21453\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 00286: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024867163, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1345 - val_loss: 0.2187\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.21453\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 00287: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024746038, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1356 - val_loss: 0.2147\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.21453\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 00288: LearningRateScheduler reducing learning rate to tf.Tensor(0.000246255, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1324 - val_loss: 0.2144\n",
      "\n",
      "Epoch 00288: val_loss improved from 0.21453 to 0.21445, saving model to folds4.hdf5\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 00289: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024505547, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1328 - val_loss: 0.2153\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.21445\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 00290: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024386184, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1323 - val_loss: 0.2159\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.21445\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 00291: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024267398, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1333 - val_loss: 0.2150\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.21445\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 00292: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024149191, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1325 - val_loss: 0.2143\n",
      "\n",
      "Epoch 00292: val_loss improved from 0.21445 to 0.21430, saving model to folds4.hdf5\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 00293: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024031562, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1322 - val_loss: 0.2135\n",
      "\n",
      "Epoch 00293: val_loss improved from 0.21430 to 0.21351, saving model to folds4.hdf5\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 00294: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023914504, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1320 - val_loss: 0.2162\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.21351\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 00295: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023798017, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1321 - val_loss: 0.2145\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.21351\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 00296: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023682097, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1310 - val_loss: 0.2146\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.21351\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 00297: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023566742, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1310 - val_loss: 0.2156\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.21351\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 00298: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023451951, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1329 - val_loss: 0.2147\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.21351\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 00299: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023337714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1318 - val_loss: 0.2161\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.21351\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 00300: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023224037, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1328 - val_loss: 0.2141\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.21351\n",
      "(50300, 80)\n",
      "--------------- > Fold 6 < ---------------\n",
      "CNN: (None, 72, 256)\n",
      "LSTM: (None, 80, 256)\n",
      "Com: (None, 152, 256)\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 26s 209ms/step - loss: 3.8414 - val_loss: 0.8638\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.86378, saving model to folds5.hdf5\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.7803 - val_loss: 0.6541\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.86378 to 0.65406, saving model to folds5.hdf5\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.6284 - val_loss: 0.5420\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65406 to 0.54204, saving model to folds5.hdf5\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.5355 - val_loss: 0.5365\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.54204 to 0.53647, saving model to folds5.hdf5\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.5047 - val_loss: 0.6492\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.53647\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.5220 - val_loss: 0.4484\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.53647 to 0.44840, saving model to folds5.hdf5\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4407 - val_loss: 0.4884\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.44840\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4463 - val_loss: 0.4348\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.44840 to 0.43479, saving model to folds5.hdf5\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4326 - val_loss: 0.4186\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.43479 to 0.41862, saving model to folds5.hdf5\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4114 - val_loss: 0.4867\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.41862\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.4219 - val_loss: 0.4004\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.41862 to 0.40039, saving model to folds5.hdf5\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3995 - val_loss: 0.4497\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.40039\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4075 - val_loss: 0.3868\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.40039 to 0.38680, saving model to folds5.hdf5\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3802 - val_loss: 0.3780\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.38680 to 0.37796, saving model to folds5.hdf5\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3750 - val_loss: 0.4594\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.37796\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4014 - val_loss: 0.4339\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.37796\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3735 - val_loss: 0.3599\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.37796 to 0.35990, saving model to folds5.hdf5\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3628 - val_loss: 0.3772\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.35990\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3527 - val_loss: 0.3684\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.35990\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3536 - val_loss: 0.3650\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.35990\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3516 - val_loss: 0.3384\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.35990 to 0.33839, saving model to folds5.hdf5\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3367 - val_loss: 0.3376\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.33839 to 0.33764, saving model to folds5.hdf5\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3321 - val_loss: 0.3465\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33764\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3384 - val_loss: 0.3451\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33764\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3289 - val_loss: 0.3495\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33764\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3349 - val_loss: 0.3417\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33764\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3282 - val_loss: 0.3370\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.33764 to 0.33697, saving model to folds5.hdf5\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3155 - val_loss: 0.3518\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33697\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 45ms/step - loss: 0.3292 - val_loss: 0.3220\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.33697 to 0.32203, saving model to folds5.hdf5\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3203 - val_loss: 0.3246\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.32203\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3126 - val_loss: 0.3276\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.32203\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3135 - val_loss: 0.3168\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.32203 to 0.31678, saving model to folds5.hdf5\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3025 - val_loss: 0.3290\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.31678\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3049 - val_loss: 0.3193\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.31678\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3049 - val_loss: 0.3219\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.31678\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3027 - val_loss: 0.3072\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.31678 to 0.30720, saving model to folds5.hdf5\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3005 - val_loss: 0.3116\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.30720\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2994 - val_loss: 0.3184\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.30720\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2922 - val_loss: 0.3028\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.30720 to 0.30282, saving model to folds5.hdf5\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2864 - val_loss: 0.3081\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.30282\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2923 - val_loss: 0.2961\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.30282 to 0.29609, saving model to folds5.hdf5\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2843 - val_loss: 0.2986\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.29609\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 4s 53ms/step - loss: 0.2803 - val_loss: 0.2980\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.29609\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2795 - val_loss: 0.3058\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.29609\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2830 - val_loss: 0.3109\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.29609\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2848 - val_loss: 0.3050\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.29609\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2808 - val_loss: 0.3043\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.29609\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2747 - val_loss: 0.2919\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.29609 to 0.29193, saving model to folds5.hdf5\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2681 - val_loss: 0.2951\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.29193\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2735 - val_loss: 0.3247\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.29193\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2894 - val_loss: 0.2976\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.29193\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2696 - val_loss: 0.2984\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.29193\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2640 - val_loss: 0.2863\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.29193 to 0.28634, saving model to folds5.hdf5\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2631 - val_loss: 0.2855\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.28634 to 0.28554, saving model to folds5.hdf5\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2658 - val_loss: 0.2974\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.28554\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2702 - val_loss: 0.2919\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.28554\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2649 - val_loss: 0.2882\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.28554\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2607 - val_loss: 0.2804\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.28554 to 0.28043, saving model to folds5.hdf5\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2564 - val_loss: 0.2773\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.28043 to 0.27733, saving model to folds5.hdf5\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2534 - val_loss: 0.2746\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.27733 to 0.27455, saving model to folds5.hdf5\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2516 - val_loss: 0.2769\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.27455\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2452 - val_loss: 0.2757\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.27455\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007387921, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2496 - val_loss: 0.2995\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.27455\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to tf.Tensor(0.00073519343, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2553 - val_loss: 0.2679\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.27455 to 0.26791, saving model to folds5.hdf5\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007316123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2443 - val_loss: 0.2766\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.26791\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007280487, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2466 - val_loss: 0.2770\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.26791\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007245024, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2471 - val_loss: 0.2748\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.26791\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007209733, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2535 - val_loss: 0.2688\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.26791\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071746146, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2408 - val_loss: 0.2699\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.26791\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007139667, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2377 - val_loss: 0.2638\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.26791 to 0.26379, saving model to folds5.hdf5\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071048894, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2411 - val_loss: 0.2650\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.26379\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007070282, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2433 - val_loss: 0.2819\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.26379\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007035842, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2423 - val_loss: 0.2656\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.26379\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to tf.Tensor(0.00070015714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2387 - val_loss: 0.2639\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.26379\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006967467, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2321 - val_loss: 0.2959\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.26379\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to tf.Tensor(0.00069335283, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2528 - val_loss: 0.2575\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.26379 to 0.25753, saving model to folds5.hdf5\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006899755, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2281 - val_loss: 0.2688\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.25753\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068661466, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2345 - val_loss: 0.2678\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.25753\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068327016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2334 - val_loss: 0.2569\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.25753 to 0.25688, saving model to folds5.hdf5\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067994196, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2262 - val_loss: 0.2674\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.25688\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067663, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2291 - val_loss: 0.2652\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.25688\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006733342, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2259 - val_loss: 0.2688\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.25688\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067005435, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2227 - val_loss: 0.2524\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.25688 to 0.25244, saving model to folds5.hdf5\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006667905, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2286 - val_loss: 0.2560\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.25244\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006635426, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2237 - val_loss: 0.2517\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.25244 to 0.25165, saving model to folds5.hdf5\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006603105, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2233 - val_loss: 0.2526\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.25165\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006570942, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2220 - val_loss: 0.2518\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.25165\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065389345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2149 - val_loss: 0.2578\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.25165\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065070833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2182 - val_loss: 0.2568\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.25165\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to tf.Tensor(0.00064753875, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.2181 - val_loss: 0.2516\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.25165 to 0.25160, saving model to folds5.hdf5\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006443846, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2167 - val_loss: 0.2547\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.25160\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006412458, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2205 - val_loss: 0.2649\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.25160\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063812226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2168 - val_loss: 0.2563\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.25160\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063501403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2183 - val_loss: 0.2467\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.25160 to 0.24666, saving model to folds5.hdf5\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006319209, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2106 - val_loss: 0.2478\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.24666\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006288428, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2089 - val_loss: 0.2529\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.24666\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to tf.Tensor(0.00062577974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2129 - val_loss: 0.2558\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.24666\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006227316, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2120 - val_loss: 0.2556\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.24666\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061969826, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2126 - val_loss: 0.2398\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.24666 to 0.23981, saving model to folds5.hdf5\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 00100: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006166797, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2088 - val_loss: 0.2433\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.23981\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 00101: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061367586, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2044 - val_loss: 0.2464\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.23981\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 00102: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061068666, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2089 - val_loss: 0.2439\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.23981\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 00103: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006077121, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2062 - val_loss: 0.2526\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.23981\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 00104: LearningRateScheduler reducing learning rate to tf.Tensor(0.00060475187, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2091 - val_loss: 0.2420\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.23981\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 00105: LearningRateScheduler reducing learning rate to tf.Tensor(0.00060180615, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2081 - val_loss: 0.2545\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.23981\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 00106: LearningRateScheduler reducing learning rate to tf.Tensor(0.00059887476, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2052 - val_loss: 0.2474\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.23981\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 00107: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005959577, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2050 - val_loss: 0.2415\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.23981\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 00108: LearningRateScheduler reducing learning rate to tf.Tensor(0.00059305475, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2029 - val_loss: 0.2425\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.23981\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 00109: LearningRateScheduler reducing learning rate to tf.Tensor(0.000590166, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2010 - val_loss: 0.2484\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.23981\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 00110: LearningRateScheduler reducing learning rate to tf.Tensor(0.00058729126, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2006 - val_loss: 0.2403\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.23981\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 00111: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005844306, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2006 - val_loss: 0.2375\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.23981 to 0.23754, saving model to folds5.hdf5\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 00112: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005815838, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1984 - val_loss: 0.2481\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.23754\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 00113: LearningRateScheduler reducing learning rate to tf.Tensor(0.000578751, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1983 - val_loss: 0.2369\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.23754 to 0.23694, saving model to folds5.hdf5\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 00114: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057593186, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1930 - val_loss: 0.2366\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.23694 to 0.23665, saving model to folds5.hdf5\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 00115: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057312654, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1957 - val_loss: 0.2381\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.23665\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 00116: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057033484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1961 - val_loss: 0.2415\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.23665\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 00117: LearningRateScheduler reducing learning rate to tf.Tensor(0.00056755677, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1955 - val_loss: 0.2384\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.23665\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 00118: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005647922, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1923 - val_loss: 0.2386\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.23665\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 00119: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005620411, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1944 - val_loss: 0.2374\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.23665\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 00120: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055930344, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1969 - val_loss: 0.2438\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.23665\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 00121: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055657903, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2007 - val_loss: 0.2342\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.23665 to 0.23418, saving model to folds5.hdf5\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 00122: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055386795, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1969 - val_loss: 0.2371\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.23418\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 00123: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005511701, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1937 - val_loss: 0.2326\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.23418 to 0.23256, saving model to folds5.hdf5\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 00124: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005484854, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1916 - val_loss: 0.2375\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.23256\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 00125: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005458137, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1879 - val_loss: 0.2335\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.23256\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 00126: LearningRateScheduler reducing learning rate to tf.Tensor(0.00054315507, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1878 - val_loss: 0.2325\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.23256 to 0.23250, saving model to folds5.hdf5\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 00127: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005405093, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 52ms/step - loss: 0.1900 - val_loss: 0.2388\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.23250\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 00128: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005378765, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1939 - val_loss: 0.2340\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.23250\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 00129: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005352565, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1880 - val_loss: 0.2291\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.23250 to 0.22913, saving model to folds5.hdf5\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 00130: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005326493, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1825 - val_loss: 0.2291\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.22913 to 0.22906, saving model to folds5.hdf5\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 00131: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005300548, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1827 - val_loss: 0.2399\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.22906\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 00132: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005274729, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1845 - val_loss: 0.2296\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.22906\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 00133: LearningRateScheduler reducing learning rate to tf.Tensor(0.00052490365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1849 - val_loss: 0.2310\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.22906\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 00134: LearningRateScheduler reducing learning rate to tf.Tensor(0.00052234676, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1824 - val_loss: 0.2320\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.22906\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 00135: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005198025, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1806 - val_loss: 0.2309\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.22906\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 00136: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005172705, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1836 - val_loss: 0.2323\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.22906\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 00137: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051475083, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1824 - val_loss: 0.2301\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.22906\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 00138: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051224354, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1831 - val_loss: 0.2276\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.22906 to 0.22763, saving model to folds5.hdf5\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 00139: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005097484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1852 - val_loss: 0.2333\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.22763\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 00140: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005072654, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1809 - val_loss: 0.2286\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.22763\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 00141: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005047946, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1768 - val_loss: 0.2274\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.22763 to 0.22736, saving model to folds5.hdf5\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 00142: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005023357, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1762 - val_loss: 0.2291\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.22736\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 00143: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049988885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1765 - val_loss: 0.2281\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.22736\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 00144: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004974539, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1788 - val_loss: 0.2286\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.22736\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 00145: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004950308, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1784 - val_loss: 0.2305\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.22736\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 00146: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004926195, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1758 - val_loss: 0.2265\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.22736 to 0.22647, saving model to folds5.hdf5\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 00147: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049022, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1823 - val_loss: 0.2313\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.22647\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 00148: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048783212, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1766 - val_loss: 0.2247\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.22647 to 0.22474, saving model to folds5.hdf5\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 00149: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048545588, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1740 - val_loss: 0.2519\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.22474\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 00150: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048309125, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1953 - val_loss: 0.2311\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.22474\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 00151: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048073815, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1805 - val_loss: 0.2255\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.22474\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 00152: LearningRateScheduler reducing learning rate to tf.Tensor(0.00047839645, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1750 - val_loss: 0.2288\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.22474\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 00153: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004760662, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1757 - val_loss: 0.2244\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.22474 to 0.22444, saving model to folds5.hdf5\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 00154: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004737473, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 46ms/step - loss: 0.1753 - val_loss: 0.2236\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.22444 to 0.22362, saving model to folds5.hdf5\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 00155: LearningRateScheduler reducing learning rate to tf.Tensor(0.00047143968, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1710 - val_loss: 0.2221\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.22362 to 0.22212, saving model to folds5.hdf5\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 00156: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004691433, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1724 - val_loss: 0.2280\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.22212\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 00157: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046685815, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1753 - val_loss: 0.2243\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.22212\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 00158: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046458407, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1731 - val_loss: 0.2246\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.22212\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 00159: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046232107, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1722 - val_loss: 0.2270\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.22212\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 00160: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046006907, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1712 - val_loss: 0.2220\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.22212 to 0.22198, saving model to folds5.hdf5\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 00161: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045782814, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1672 - val_loss: 0.2236\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.22198\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 00162: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045559806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1702 - val_loss: 0.2202\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.22198 to 0.22020, saving model to folds5.hdf5\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 00163: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045337883, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1670 - val_loss: 0.2231\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.22020\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 00164: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045117046, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.1686 - val_loss: 0.2232\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.22020\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 00165: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044897277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1727 - val_loss: 0.2225\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.22020\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 00166: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044678585, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1683 - val_loss: 0.2293\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.22020\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 00167: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004446096, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1721 - val_loss: 0.2229\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.22020\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 00168: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004424439, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1661 - val_loss: 0.2241\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.22020\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 00169: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044028874, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1653 - val_loss: 0.2226\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.22020\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 00170: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043814414, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1642 - val_loss: 0.2202\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.22020\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 00171: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043600993, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1642 - val_loss: 0.2271\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.22020\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 00172: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043388613, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1654 - val_loss: 0.2211\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.22020\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 00173: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004317727, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1659 - val_loss: 0.2236\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.22020\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 00174: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004296695, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1648 - val_loss: 0.2203\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.22020\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 00175: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004275766, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1625 - val_loss: 0.2228\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.22020\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 00176: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042549393, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1632 - val_loss: 0.2232\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.22020\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 00177: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042342133, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1634 - val_loss: 0.2198\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.22020 to 0.21985, saving model to folds5.hdf5\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 00178: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042135885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1627 - val_loss: 0.2208\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.21985\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 00179: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041930642, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1630 - val_loss: 0.2203\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.21985\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 00180: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041726397, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1608 - val_loss: 0.2194\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.21985 to 0.21939, saving model to folds5.hdf5\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 00181: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041523148, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1602 - val_loss: 0.2206\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.21939\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 00182: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041320888, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1592 - val_loss: 0.2209\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.21939\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 00183: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041119618, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1593 - val_loss: 0.2193\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.21939 to 0.21931, saving model to folds5.hdf5\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 00184: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040919325, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1599 - val_loss: 0.2218\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.21931\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 00185: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040720004, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1601 - val_loss: 0.2217\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.21931\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 00186: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004052166, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1592 - val_loss: 0.2181\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.21931 to 0.21815, saving model to folds5.hdf5\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 00187: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004032428, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1596 - val_loss: 0.2206\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.21815\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 00188: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004012786, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1591 - val_loss: 0.2221\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.21815\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 00189: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039932402, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1574 - val_loss: 0.2205\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.21815\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 00190: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039737887, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1597 - val_loss: 0.2191\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.21815\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 00191: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039544326, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1570 - val_loss: 0.2185\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.21815\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 00192: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039351705, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1569 - val_loss: 0.2216\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.21815\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 00193: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039160028, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1572 - val_loss: 0.2175\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.21815 to 0.21755, saving model to folds5.hdf5\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 00194: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038969278, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1555 - val_loss: 0.2166\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.21755 to 0.21657, saving model to folds5.hdf5\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 00195: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003877946, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 4s 53ms/step - loss: 0.1548 - val_loss: 0.2189\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.21657\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 00196: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038590565, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1550 - val_loss: 0.2206\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.21657\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 00197: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003840259, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1553 - val_loss: 0.2186\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.21657\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 00198: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038215535, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1569 - val_loss: 0.2234\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.21657\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 00199: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038029387, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1597 - val_loss: 0.2205\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.21657\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 00200: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037844144, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1578 - val_loss: 0.2255\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.21657\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 00201: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037659804, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1626 - val_loss: 0.2168\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.21657\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 00202: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037476368, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1547 - val_loss: 0.2177\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.21657\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 00203: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037293817, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1535 - val_loss: 0.2164\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.21657 to 0.21639, saving model to folds5.hdf5\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 00204: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003711216, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1542 - val_loss: 0.2161\n",
      "\n",
      "Epoch 00204: val_loss improved from 0.21639 to 0.21606, saving model to folds5.hdf5\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 00205: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003693139, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1520 - val_loss: 0.2190\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.21606\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 00206: LearningRateScheduler reducing learning rate to tf.Tensor(0.000367515, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1517 - val_loss: 0.2211\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.21606\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 00207: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036572482, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1537 - val_loss: 0.2171\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.21606\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 00208: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003639434, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1511 - val_loss: 0.2168\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.21606\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 00209: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036217063, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1508 - val_loss: 0.2165\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.21606\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 00210: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036040647, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1498 - val_loss: 0.2161\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.21606\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 00211: LearningRateScheduler reducing learning rate to tf.Tensor(0.00035865093, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1495 - val_loss: 0.2181\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.21606\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 00212: LearningRateScheduler reducing learning rate to tf.Tensor(0.000356904, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1516 - val_loss: 0.2196\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.21606\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 00213: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003551655, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1509 - val_loss: 0.2165\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.21606\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 00214: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003534355, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1500 - val_loss: 0.2197\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.21606\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 00215: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003517139, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1501 - val_loss: 0.2164\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.21606\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 00216: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003500007, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1478 - val_loss: 0.2150\n",
      "\n",
      "Epoch 00216: val_loss improved from 0.21606 to 0.21500, saving model to folds5.hdf5\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 00217: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034829587, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1476 - val_loss: 0.2159\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.21500\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 00218: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034659932, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1507 - val_loss: 0.2142\n",
      "\n",
      "Epoch 00218: val_loss improved from 0.21500 to 0.21421, saving model to folds5.hdf5\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 00219: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034491107, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1472 - val_loss: 0.2140\n",
      "\n",
      "Epoch 00219: val_loss improved from 0.21421 to 0.21400, saving model to folds5.hdf5\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 00220: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034323102, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1479 - val_loss: 0.2145\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.21400\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 00221: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034155912, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1482 - val_loss: 0.2215\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.21400\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 00222: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033989537, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1489 - val_loss: 0.2159\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.21400\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 00223: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033823974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1483 - val_loss: 0.2138\n",
      "\n",
      "Epoch 00223: val_loss improved from 0.21400 to 0.21383, saving model to folds5.hdf5\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 00224: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003365922, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1470 - val_loss: 0.2149\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.21383\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 00225: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033495267, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1450 - val_loss: 0.2172\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.21383\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 00226: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003333211, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1462 - val_loss: 0.2156\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.21383\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 00227: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033169755, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1476 - val_loss: 0.2198\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.21383\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 00228: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033008185, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1450 - val_loss: 0.2156\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.21383\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 00229: LearningRateScheduler reducing learning rate to tf.Tensor(0.000328474, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1448 - val_loss: 0.2139\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.21383\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 00230: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032687403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1446 - val_loss: 0.2153\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.21383\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 00231: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003252818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1440 - val_loss: 0.2144\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.21383\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 00232: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032369737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1437 - val_loss: 0.2174\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.21383\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 00233: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032212064, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1463 - val_loss: 0.2159\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.21383\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 00234: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032055163, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1448 - val_loss: 0.2163\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.21383\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 00235: LearningRateScheduler reducing learning rate to tf.Tensor(0.00031899018, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1438 - val_loss: 0.2155\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.21383\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 00236: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003174364, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.1440 - val_loss: 0.2182\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.21383\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 00237: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003158902, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1450 - val_loss: 0.2156\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.21383\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 00238: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003143515, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1430 - val_loss: 0.2168\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.21383\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 00239: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003128203, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1443 - val_loss: 0.2153\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.21383\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 00240: LearningRateScheduler reducing learning rate to tf.Tensor(0.00031129655, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1437 - val_loss: 0.2141\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.21383\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 00241: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003097802, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1420 - val_loss: 0.2156\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.21383\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 00242: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003082713, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1416 - val_loss: 0.2132\n",
      "\n",
      "Epoch 00242: val_loss improved from 0.21383 to 0.21319, saving model to folds5.hdf5\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 00243: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003067697, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1400 - val_loss: 0.2145\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.21319\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 00244: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030527546, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1404 - val_loss: 0.2140\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.21319\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 00245: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030378843, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1409 - val_loss: 0.2163\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.21319\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 00246: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003023087, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1417 - val_loss: 0.2159\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.21319\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 00247: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030083617, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1402 - val_loss: 0.2162\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.21319\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 00248: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002993708, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1426 - val_loss: 0.2172\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.21319\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 00249: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029791257, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1430 - val_loss: 0.2148\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.21319\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 00250: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029646145, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1391 - val_loss: 0.2153\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.21319\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 00251: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029501738, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1388 - val_loss: 0.2184\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.21319\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 00252: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029358038, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1421 - val_loss: 0.2158\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.21319\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 00253: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029215033, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1403 - val_loss: 0.2149\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.21319\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 00254: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029072727, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1391 - val_loss: 0.2148\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.21319\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 00255: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028931117, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1396 - val_loss: 0.2141\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.21319\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 00256: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028790193, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1373 - val_loss: 0.2181\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.21319\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 00257: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028649953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1397 - val_loss: 0.2137\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.21319\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 00258: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028510403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1377 - val_loss: 0.2132\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.21319\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 00259: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002837153, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1387 - val_loss: 0.2162\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.21319\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 00260: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002823333, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1379 - val_loss: 0.2136\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.21319\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 00261: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028095808, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1365 - val_loss: 0.2156\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.21319\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 00262: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027958953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1373 - val_loss: 0.2145\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.21319\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 00263: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027822764, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1373 - val_loss: 0.2137\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.21319\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 00264: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027687242, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1362 - val_loss: 0.2136\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.21319\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 00265: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027552375, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1356 - val_loss: 0.2143\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.21319\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 00266: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002741817, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1362 - val_loss: 0.2187\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.21319\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 00267: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027284614, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1363 - val_loss: 0.2148\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.21319\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 00268: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027151714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1364 - val_loss: 0.2155\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.21319\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 00269: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027019458, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.1359 - val_loss: 0.2136\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.21319\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 00270: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026887844, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1350 - val_loss: 0.2163\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.21319\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 00271: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026756877, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1350 - val_loss: 0.2163\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.21319\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 00272: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026626544, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1355 - val_loss: 0.2156\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.21319\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 00273: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026496846, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1361 - val_loss: 0.2142\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.21319\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 00274: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026367782, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1348 - val_loss: 0.2134\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.21319\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 00275: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026239344, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1350 - val_loss: 0.2135\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.21319\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 00276: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026111532, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1348 - val_loss: 0.2154\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.21319\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 00277: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025984345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1339 - val_loss: 0.2139\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.21319\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 00278: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025857775, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1342 - val_loss: 0.2157\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.21319\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 00279: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002573182, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1331 - val_loss: 0.2147\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.21319\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 00280: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025606484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1334 - val_loss: 0.2135\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.21319\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 00281: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025481754, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1329 - val_loss: 0.2153\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.21319\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 00282: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025357632, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1335 - val_loss: 0.2154\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.21319\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 00283: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025234115, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1326 - val_loss: 0.2135\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.21319\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 00284: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025111204, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1326 - val_loss: 0.2129\n",
      "\n",
      "Epoch 00284: val_loss improved from 0.21319 to 0.21286, saving model to folds5.hdf5\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 00285: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024988884, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1310 - val_loss: 0.2142\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.21286\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 00286: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024867163, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1321 - val_loss: 0.2141\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.21286\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 00287: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024746038, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1313 - val_loss: 0.2168\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.21286\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 00288: LearningRateScheduler reducing learning rate to tf.Tensor(0.000246255, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1329 - val_loss: 0.2162\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.21286\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 00289: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024505547, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1332 - val_loss: 0.2153\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.21286\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 00290: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024386184, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1322 - val_loss: 0.2138\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.21286\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 00291: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024267398, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1314 - val_loss: 0.2125\n",
      "\n",
      "Epoch 00291: val_loss improved from 0.21286 to 0.21255, saving model to folds5.hdf5\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 00292: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024149191, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1309 - val_loss: 0.2148\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.21255\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 00293: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024031562, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1315 - val_loss: 0.2130\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.21255\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 00294: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023914504, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 49ms/step - loss: 0.1305 - val_loss: 0.2138\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.21255\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 00295: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023798017, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1312 - val_loss: 0.2143\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.21255\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 00296: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023682097, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1311 - val_loss: 0.2158\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.21255\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 00297: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023566742, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1312 - val_loss: 0.2137\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.21255\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 00298: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023451951, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1306 - val_loss: 0.2144\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.21255\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 00299: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023337714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1298 - val_loss: 0.2137\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.21255\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 00300: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023224037, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1294 - val_loss: 0.2138\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.21255\n",
      "(50300, 80)\n",
      "--------------- > Fold 7 < ---------------\n",
      "CNN: (None, 72, 256)\n",
      "LSTM: (None, 80, 256)\n",
      "Com: (None, 152, 256)\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 26s 210ms/step - loss: 3.7332 - val_loss: 0.8654\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.86537, saving model to folds6.hdf5\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 45ms/step - loss: 0.7678 - val_loss: 0.6541\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.86537 to 0.65407, saving model to folds6.hdf5\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.6230 - val_loss: 0.5240\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65407 to 0.52398, saving model to folds6.hdf5\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.5525 - val_loss: 0.5203\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.52398 to 0.52028, saving model to folds6.hdf5\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.5111 - val_loss: 0.5485\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.52028\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.5049 - val_loss: 0.4726\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.52028 to 0.47265, saving model to folds6.hdf5\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4592 - val_loss: 0.4377\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.47265 to 0.43770, saving model to folds6.hdf5\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4487 - val_loss: 0.4243\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.43770 to 0.42429, saving model to folds6.hdf5\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4311 - val_loss: 0.4404\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.42429\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4233 - val_loss: 0.4132\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.42429 to 0.41316, saving model to folds6.hdf5\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4067 - val_loss: 0.3963\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.41316 to 0.39626, saving model to folds6.hdf5\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4059 - val_loss: 0.4257\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.39626\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4026 - val_loss: 0.4055\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.39626\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3871 - val_loss: 0.3811\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.39626 to 0.38106, saving model to folds6.hdf5\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3849 - val_loss: 0.3776\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.38106 to 0.37763, saving model to folds6.hdf5\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3732 - val_loss: 0.3640\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.37763 to 0.36402, saving model to folds6.hdf5\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3597 - val_loss: 0.3676\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.36402\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3634 - val_loss: 0.3733\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.36402\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3612 - val_loss: 0.3650\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.36402\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3568 - val_loss: 0.3639\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.36402 to 0.36387, saving model to folds6.hdf5\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3505 - val_loss: 0.3588\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.36387 to 0.35876, saving model to folds6.hdf5\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3472 - val_loss: 0.4026\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.35876\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3488 - val_loss: 0.3540\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.35876 to 0.35401, saving model to folds6.hdf5\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3434 - val_loss: 0.3475\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.35401 to 0.34748, saving model to folds6.hdf5\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3424 - val_loss: 0.3393\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.34748 to 0.33933, saving model to folds6.hdf5\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3266 - val_loss: 0.3720\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33933\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3305 - val_loss: 0.3542\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33933\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3264 - val_loss: 0.3336\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.33933 to 0.33364, saving model to folds6.hdf5\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3291 - val_loss: 0.3467\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33364\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3256 - val_loss: 0.3239\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.33364 to 0.32386, saving model to folds6.hdf5\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3150 - val_loss: 0.3232\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.32386 to 0.32319, saving model to folds6.hdf5\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3132 - val_loss: 0.3239\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.32319\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3091 - val_loss: 0.3439\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.32319\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3081 - val_loss: 0.3386\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.32319\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3032 - val_loss: 0.3300\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.32319\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3127 - val_loss: 0.3136\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.32319 to 0.31364, saving model to folds6.hdf5\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3062 - val_loss: 0.3210\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.31364\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.2965 - val_loss: 0.3285\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.31364\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3018 - val_loss: 0.3175\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.31364\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2952 - val_loss: 0.3020\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.31364 to 0.30200, saving model to folds6.hdf5\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2941 - val_loss: 0.3099\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.30200\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2882 - val_loss: 0.3013\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.30200 to 0.30128, saving model to folds6.hdf5\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2876 - val_loss: 0.3013\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.30128 to 0.30128, saving model to folds6.hdf5\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2880 - val_loss: 0.3273\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.30128\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2895 - val_loss: 0.3012\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.30128 to 0.30117, saving model to folds6.hdf5\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2820 - val_loss: 0.3300\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.30117\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2984 - val_loss: 0.2995\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.30117 to 0.29946, saving model to folds6.hdf5\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2800 - val_loss: 0.2942\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.29946 to 0.29415, saving model to folds6.hdf5\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2731 - val_loss: 0.2929\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.29415 to 0.29287, saving model to folds6.hdf5\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2794 - val_loss: 0.3189\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.29287\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2761 - val_loss: 0.2894\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.29287 to 0.28940, saving model to folds6.hdf5\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2688 - val_loss: 0.3069\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.28940\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2763 - val_loss: 0.2891\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.28940 to 0.28909, saving model to folds6.hdf5\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2671 - val_loss: 0.2944\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.28909\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2707 - val_loss: 0.2975\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.28909\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2679 - val_loss: 0.3033\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.28909\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2653 - val_loss: 0.3180\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.28909\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2706 - val_loss: 0.2939\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.28909\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2607 - val_loss: 0.2825\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.28909 to 0.28249, saving model to folds6.hdf5\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2606 - val_loss: 0.2931\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.28249\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2580 - val_loss: 0.2996\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.28249\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2567 - val_loss: 0.2892\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.28249\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007387921, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2592 - val_loss: 0.2821\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.28249 to 0.28208, saving model to folds6.hdf5\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to tf.Tensor(0.00073519343, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2577 - val_loss: 0.2909\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.28208\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007316123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2536 - val_loss: 0.2724\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.28208 to 0.27243, saving model to folds6.hdf5\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007280487, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2462 - val_loss: 0.2756\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.27243\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007245024, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2479 - val_loss: 0.2810\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.27243\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007209733, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2478 - val_loss: 0.2800\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.27243\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071746146, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2508 - val_loss: 0.2767\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.27243\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007139667, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2478 - val_loss: 0.2704\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.27243 to 0.27036, saving model to folds6.hdf5\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071048894, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2421 - val_loss: 0.2759\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.27036\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007070282, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2442 - val_loss: 0.2699\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.27036 to 0.26989, saving model to folds6.hdf5\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007035842, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2365 - val_loss: 0.2749\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.26989\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to tf.Tensor(0.00070015714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2401 - val_loss: 0.2965\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.26989\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006967467, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2482 - val_loss: 0.2660\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.26989 to 0.26600, saving model to folds6.hdf5\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to tf.Tensor(0.00069335283, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2362 - val_loss: 0.2666\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.26600\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006899755, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2387 - val_loss: 0.2749\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.26600\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068661466, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2355 - val_loss: 0.2790\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.26600\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068327016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2449 - val_loss: 0.2646\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.26600 to 0.26458, saving model to folds6.hdf5\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067994196, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2310 - val_loss: 0.2709\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.26458\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067663, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2337 - val_loss: 0.2664\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.26458\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006733342, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2331 - val_loss: 0.2727\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.26458\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067005435, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2367 - val_loss: 0.2706\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.26458\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006667905, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2338 - val_loss: 0.2652\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.26458\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006635426, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.2296 - val_loss: 0.2604\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.26458 to 0.26041, saving model to folds6.hdf5\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006603105, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2261 - val_loss: 0.2632\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.26041\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006570942, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2266 - val_loss: 0.2553\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.26041 to 0.25527, saving model to folds6.hdf5\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065389345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2254 - val_loss: 0.2677\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.25527\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065070833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2287 - val_loss: 0.2555\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.25527\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to tf.Tensor(0.00064753875, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2200 - val_loss: 0.2560\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.25527\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006443846, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2182 - val_loss: 0.2568\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.25527\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006412458, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2220 - val_loss: 0.2617\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.25527\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063812226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2196 - val_loss: 0.2509\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.25527 to 0.25091, saving model to folds6.hdf5\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063501403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2221 - val_loss: 0.2550\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.25091\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006319209, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2164 - val_loss: 0.2532\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.25091\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006288428, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2173 - val_loss: 0.2489\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.25091 to 0.24888, saving model to folds6.hdf5\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to tf.Tensor(0.00062577974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2151 - val_loss: 0.2510\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.24888\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006227316, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2111 - val_loss: 0.2487\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.24888 to 0.24866, saving model to folds6.hdf5\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061969826, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2110 - val_loss: 0.2540\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.24866\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 00100: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006166797, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2110 - val_loss: 0.2529\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.24866\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 00101: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061367586, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2093 - val_loss: 0.2536\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.24866\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 00102: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061068666, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2104 - val_loss: 0.2511\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.24866\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 00103: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006077121, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2115 - val_loss: 0.2611\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.24866\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 00104: LearningRateScheduler reducing learning rate to tf.Tensor(0.00060475187, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2131 - val_loss: 0.2469\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.24866 to 0.24687, saving model to folds6.hdf5\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 00105: LearningRateScheduler reducing learning rate to tf.Tensor(0.00060180615, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2065 - val_loss: 0.2492\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.24687\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 00106: LearningRateScheduler reducing learning rate to tf.Tensor(0.00059887476, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 45ms/step - loss: 0.2056 - val_loss: 0.2643\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.24687\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 00107: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005959577, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2160 - val_loss: 0.2465\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.24687 to 0.24653, saving model to folds6.hdf5\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 00108: LearningRateScheduler reducing learning rate to tf.Tensor(0.00059305475, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2041 - val_loss: 0.2475\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.24653\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 00109: LearningRateScheduler reducing learning rate to tf.Tensor(0.000590166, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2063 - val_loss: 0.2677\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.24653\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 00110: LearningRateScheduler reducing learning rate to tf.Tensor(0.00058729126, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2106 - val_loss: 0.2445\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.24653 to 0.24451, saving model to folds6.hdf5\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 00111: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005844306, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2044 - val_loss: 0.2564\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.24451\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 00112: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005815838, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2068 - val_loss: 0.2436\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.24451 to 0.24357, saving model to folds6.hdf5\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 00113: LearningRateScheduler reducing learning rate to tf.Tensor(0.000578751, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1982 - val_loss: 0.2445\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.24357\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 00114: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057593186, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2039 - val_loss: 0.2441\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.24357\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 00115: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057312654, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1970 - val_loss: 0.2456\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.24357\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 00116: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057033484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2034 - val_loss: 0.2486\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.24357\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 00117: LearningRateScheduler reducing learning rate to tf.Tensor(0.00056755677, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2028 - val_loss: 0.2435\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.24357 to 0.24352, saving model to folds6.hdf5\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 00118: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005647922, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1975 - val_loss: 0.2481\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.24352\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 00119: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005620411, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1959 - val_loss: 0.2419\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.24352 to 0.24194, saving model to folds6.hdf5\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 00120: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055930344, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1958 - val_loss: 0.2416\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.24194 to 0.24161, saving model to folds6.hdf5\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 00121: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055657903, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1979 - val_loss: 0.2480\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.24161\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 00122: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055386795, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1940 - val_loss: 0.2475\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.24161\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 00123: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005511701, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1951 - val_loss: 0.2402\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.24161 to 0.24023, saving model to folds6.hdf5\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 00124: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005484854, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1917 - val_loss: 0.2400\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.24023 to 0.24002, saving model to folds6.hdf5\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 00125: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005458137, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1902 - val_loss: 0.2395\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.24002 to 0.23948, saving model to folds6.hdf5\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 00126: LearningRateScheduler reducing learning rate to tf.Tensor(0.00054315507, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 52ms/step - loss: 0.1919 - val_loss: 0.2397\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.23948\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 00127: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005405093, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1916 - val_loss: 0.2407\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.23948\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 00128: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005378765, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1914 - val_loss: 0.2411\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.23948\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 00129: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005352565, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1932 - val_loss: 0.2390\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.23948 to 0.23900, saving model to folds6.hdf5\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 00130: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005326493, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1903 - val_loss: 0.2490\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.23900\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 00131: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005300548, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1944 - val_loss: 0.2361\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.23900 to 0.23614, saving model to folds6.hdf5\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 00132: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005274729, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1862 - val_loss: 0.2369\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.23614\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 00133: LearningRateScheduler reducing learning rate to tf.Tensor(0.00052490365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1857 - val_loss: 0.2396\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.23614\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 00134: LearningRateScheduler reducing learning rate to tf.Tensor(0.00052234676, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1866 - val_loss: 0.2371\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.23614\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 00135: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005198025, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1859 - val_loss: 0.2402\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.23614\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 00136: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005172705, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1857 - val_loss: 0.2410\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.23614\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 00137: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051475083, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1887 - val_loss: 0.2373\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.23614\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 00138: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051224354, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1853 - val_loss: 0.2413\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.23614\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 00139: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005097484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1887 - val_loss: 0.2441\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.23614\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 00140: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005072654, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1928 - val_loss: 0.2404\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.23614\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 00141: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005047946, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1875 - val_loss: 0.2369\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.23614\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 00142: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005023357, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1832 - val_loss: 0.2406\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.23614\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 00143: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049988885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1840 - val_loss: 0.2364\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.23614\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 00144: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004974539, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1794 - val_loss: 0.2352\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.23614 to 0.23521, saving model to folds6.hdf5\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 00145: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004950308, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1828 - val_loss: 0.2319\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.23521 to 0.23187, saving model to folds6.hdf5\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 00146: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004926195, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1791 - val_loss: 0.2348\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.23187\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 00147: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049022, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1789 - val_loss: 0.2323\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.23187\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 00148: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048783212, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1771 - val_loss: 0.2345\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.23187\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 00149: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048545588, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1841 - val_loss: 0.2365\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.23187\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 00150: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048309125, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1773 - val_loss: 0.2341\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.23187\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 00151: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048073815, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1772 - val_loss: 0.2332\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.23187\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 00152: LearningRateScheduler reducing learning rate to tf.Tensor(0.00047839645, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1756 - val_loss: 0.2392\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.23187\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 00153: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004760662, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1787 - val_loss: 0.2335\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.23187\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 00154: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004737473, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1738 - val_loss: 0.2329\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.23187\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 00155: LearningRateScheduler reducing learning rate to tf.Tensor(0.00047143968, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1753 - val_loss: 0.2340\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.23187\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 00156: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004691433, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1767 - val_loss: 0.2325\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.23187\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 00157: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046685815, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1754 - val_loss: 0.2309\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.23187 to 0.23091, saving model to folds6.hdf5\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 00158: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046458407, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1742 - val_loss: 0.2339\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.23091\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 00159: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046232107, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1747 - val_loss: 0.2311\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.23091\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 00160: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046006907, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1718 - val_loss: 0.2340\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.23091\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 00161: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045782814, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1719 - val_loss: 0.2330\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.23091\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 00162: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045559806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.1739 - val_loss: 0.2308\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.23091 to 0.23076, saving model to folds6.hdf5\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 00163: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045337883, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1733 - val_loss: 0.2383\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.23076\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 00164: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045117046, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1714 - val_loss: 0.2318\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.23076\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 00165: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044897277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1711 - val_loss: 0.2326\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.23076\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 00166: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044678585, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1696 - val_loss: 0.2313\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.23076\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 00167: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004446096, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1730 - val_loss: 0.2292\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.23076 to 0.22917, saving model to folds6.hdf5\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 00168: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004424439, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1734 - val_loss: 0.2328\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.22917\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 00169: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044028874, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1710 - val_loss: 0.2305\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.22917\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 00170: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043814414, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1664 - val_loss: 0.2296\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.22917\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 00171: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043600993, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1703 - val_loss: 0.2282\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.22917 to 0.22817, saving model to folds6.hdf5\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 00172: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043388613, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1681 - val_loss: 0.2299\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.22817\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 00173: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004317727, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1671 - val_loss: 0.2286\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.22817\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 00174: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004296695, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1680 - val_loss: 0.2319\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.22817\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 00175: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004275766, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1675 - val_loss: 0.2270\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.22817 to 0.22696, saving model to folds6.hdf5\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 00176: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042549393, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1673 - val_loss: 0.2313\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.22696\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 00177: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042342133, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1661 - val_loss: 0.2297\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.22696\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 00178: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042135885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1652 - val_loss: 0.2304\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.22696\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 00179: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041930642, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1673 - val_loss: 0.2317\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.22696\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 00180: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041726397, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1618 - val_loss: 0.2294\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.22696\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 00181: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041523148, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1622 - val_loss: 0.2280\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.22696\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 00182: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041320888, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1669 - val_loss: 0.2303\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.22696\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 00183: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041119618, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1622 - val_loss: 0.2295\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.22696\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 00184: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040919325, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1634 - val_loss: 0.2309\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.22696\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 00185: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040720004, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1643 - val_loss: 0.2302\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.22696\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 00186: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004052166, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1639 - val_loss: 0.2286\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.22696\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 00187: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004032428, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1638 - val_loss: 0.2296\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.22696\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 00188: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004012786, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1606 - val_loss: 0.2339\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.22696\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 00189: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039932402, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1621 - val_loss: 0.2271\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.22696\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 00190: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039737887, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1611 - val_loss: 0.2286\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.22696\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 00191: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039544326, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1603 - val_loss: 0.2280\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.22696\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 00192: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039351705, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1589 - val_loss: 0.2269\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.22696 to 0.22690, saving model to folds6.hdf5\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 00193: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039160028, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1652 - val_loss: 0.2291\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.22690\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 00194: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038969278, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1621 - val_loss: 0.2271\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.22690\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 00195: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003877946, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1607 - val_loss: 0.2321\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.22690\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 00196: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038590565, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 52ms/step - loss: 0.1619 - val_loss: 0.2264\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.22690 to 0.22640, saving model to folds6.hdf5\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 00197: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003840259, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1576 - val_loss: 0.2268\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.22640\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 00198: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038215535, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1563 - val_loss: 0.2255\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.22640 to 0.22553, saving model to folds6.hdf5\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 00199: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038029387, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1569 - val_loss: 0.2249\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.22553 to 0.22487, saving model to folds6.hdf5\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 00200: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037844144, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1569 - val_loss: 0.2256\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.22487\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 00201: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037659804, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1577 - val_loss: 0.2274\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.22487\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 00202: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037476368, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1582 - val_loss: 0.2364\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.22487\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 00203: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037293817, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1618 - val_loss: 0.2264\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.22487\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 00204: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003711216, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1564 - val_loss: 0.2248\n",
      "\n",
      "Epoch 00204: val_loss improved from 0.22487 to 0.22479, saving model to folds6.hdf5\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 00205: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003693139, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1530 - val_loss: 0.2326\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.22479\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 00206: LearningRateScheduler reducing learning rate to tf.Tensor(0.000367515, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1560 - val_loss: 0.2237\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.22479 to 0.22370, saving model to folds6.hdf5\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 00207: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036572482, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1533 - val_loss: 0.2290\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.22370\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 00208: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003639434, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1557 - val_loss: 0.2243\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.22370\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 00209: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036217063, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1536 - val_loss: 0.2242\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.22370\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 00210: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036040647, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1528 - val_loss: 0.2242\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.22370\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 00211: LearningRateScheduler reducing learning rate to tf.Tensor(0.00035865093, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1527 - val_loss: 0.2256\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.22370\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 00212: LearningRateScheduler reducing learning rate to tf.Tensor(0.000356904, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1527 - val_loss: 0.2257\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.22370\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 00213: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003551655, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1535 - val_loss: 0.2230\n",
      "\n",
      "Epoch 00213: val_loss improved from 0.22370 to 0.22299, saving model to folds6.hdf5\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 00214: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003534355, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1513 - val_loss: 0.2243\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.22299\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 00215: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003517139, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1538 - val_loss: 0.2242\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.22299\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 00216: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003500007, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1530 - val_loss: 0.2255\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.22299\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 00217: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034829587, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1533 - val_loss: 0.2268\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.22299\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 00218: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034659932, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1503 - val_loss: 0.2255\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.22299\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 00219: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034491107, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1506 - val_loss: 0.2240\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.22299\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 00220: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034323102, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1519 - val_loss: 0.2237\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.22299\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 00221: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034155912, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1505 - val_loss: 0.2283\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.22299\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 00222: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033989537, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1536 - val_loss: 0.2256\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.22299\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 00223: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033823974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1506 - val_loss: 0.2243\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.22299\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 00224: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003365922, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1511 - val_loss: 0.2244\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.22299\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 00225: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033495267, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1493 - val_loss: 0.2242\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.22299\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 00226: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003333211, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1481 - val_loss: 0.2238\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.22299\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 00227: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033169755, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1476 - val_loss: 0.2233\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.22299\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 00228: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033008185, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1482 - val_loss: 0.2272\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.22299\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 00229: LearningRateScheduler reducing learning rate to tf.Tensor(0.000328474, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1498 - val_loss: 0.2218\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.22299 to 0.22177, saving model to folds6.hdf5\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 00230: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032687403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1485 - val_loss: 0.2248\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.22177\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 00231: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003252818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1488 - val_loss: 0.2237\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.22177\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 00232: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032369737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1477 - val_loss: 0.2245\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.22177\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 00233: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032212064, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1452 - val_loss: 0.2218\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.22177\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 00234: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032055163, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 52ms/step - loss: 0.1466 - val_loss: 0.2292\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.22177\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 00235: LearningRateScheduler reducing learning rate to tf.Tensor(0.00031899018, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1478 - val_loss: 0.2220\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.22177\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 00236: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003174364, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1458 - val_loss: 0.2229\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.22177\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 00237: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003158902, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1443 - val_loss: 0.2241\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.22177\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 00238: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003143515, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1469 - val_loss: 0.2228\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.22177\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 00239: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003128203, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1446 - val_loss: 0.2235\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.22177\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 00240: LearningRateScheduler reducing learning rate to tf.Tensor(0.00031129655, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1464 - val_loss: 0.2225\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.22177\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 00241: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003097802, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1444 - val_loss: 0.2241\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.22177\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 00242: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003082713, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1432 - val_loss: 0.2240\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.22177\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 00243: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003067697, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1444 - val_loss: 0.2228\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.22177\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 00244: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030527546, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1433 - val_loss: 0.2234\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.22177\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 00245: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030378843, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1450 - val_loss: 0.2239\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.22177\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 00246: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003023087, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1441 - val_loss: 0.2223\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.22177\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 00247: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030083617, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1461 - val_loss: 0.2232\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.22177\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 00248: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002993708, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1432 - val_loss: 0.2216\n",
      "\n",
      "Epoch 00248: val_loss improved from 0.22177 to 0.22162, saving model to folds6.hdf5\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 00249: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029791257, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1416 - val_loss: 0.2211\n",
      "\n",
      "Epoch 00249: val_loss improved from 0.22162 to 0.22114, saving model to folds6.hdf5\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 00250: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029646145, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1404 - val_loss: 0.2240\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.22114\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 00251: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029501738, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1422 - val_loss: 0.2237\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.22114\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 00252: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029358038, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1430 - val_loss: 0.2255\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.22114\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 00253: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029215033, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1433 - val_loss: 0.2225\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.22114\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 00254: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029072727, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1400 - val_loss: 0.2218\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.22114\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 00255: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028931117, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1401 - val_loss: 0.2220\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.22114\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 00256: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028790193, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1425 - val_loss: 0.2214\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.22114\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 00257: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028649953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1412 - val_loss: 0.2220\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.22114\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 00258: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028510403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1404 - val_loss: 0.2215\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.22114\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 00259: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002837153, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1403 - val_loss: 0.2251\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.22114\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 00260: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002823333, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1420 - val_loss: 0.2222\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.22114\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 00261: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028095808, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1393 - val_loss: 0.2218\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.22114\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 00262: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027958953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1395 - val_loss: 0.2208\n",
      "\n",
      "Epoch 00262: val_loss improved from 0.22114 to 0.22081, saving model to folds6.hdf5\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 00263: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027822764, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1387 - val_loss: 0.2213\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.22081\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 00264: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027687242, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1391 - val_loss: 0.2206\n",
      "\n",
      "Epoch 00264: val_loss improved from 0.22081 to 0.22063, saving model to folds6.hdf5\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 00265: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027552375, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1393 - val_loss: 0.2217\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.22063\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 00266: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002741817, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1395 - val_loss: 0.2214\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.22063\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 00267: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027284614, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1393 - val_loss: 0.2242\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.22063\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 00268: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027151714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1395 - val_loss: 0.2211\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.22063\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 00269: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027019458, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1390 - val_loss: 0.2235\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.22063\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 00270: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026887844, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1377 - val_loss: 0.2225\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.22063\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 00271: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026756877, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1376 - val_loss: 0.2210\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.22063\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 00272: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026626544, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1385 - val_loss: 0.2204\n",
      "\n",
      "Epoch 00272: val_loss improved from 0.22063 to 0.22043, saving model to folds6.hdf5\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 00273: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026496846, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1374 - val_loss: 0.2214\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.22043\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 00274: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026367782, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1379 - val_loss: 0.2236\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.22043\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 00275: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026239344, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1378 - val_loss: 0.2211\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.22043\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 00276: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026111532, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1361 - val_loss: 0.2206\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.22043\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 00277: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025984345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1360 - val_loss: 0.2204\n",
      "\n",
      "Epoch 00277: val_loss improved from 0.22043 to 0.22037, saving model to folds6.hdf5\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 00278: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025857775, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1356 - val_loss: 0.2212\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.22037\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 00279: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002573182, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1358 - val_loss: 0.2212\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.22037\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 00280: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025606484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1370 - val_loss: 0.2230\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.22037\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 00281: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025481754, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.1356 - val_loss: 0.2213\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.22037\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 00282: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025357632, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1351 - val_loss: 0.2234\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.22037\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 00283: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025234115, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1363 - val_loss: 0.2198\n",
      "\n",
      "Epoch 00283: val_loss improved from 0.22037 to 0.21976, saving model to folds6.hdf5\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 00284: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025111204, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1342 - val_loss: 0.2224\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.21976\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 00285: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024988884, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1358 - val_loss: 0.2221\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.21976\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 00286: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024867163, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1352 - val_loss: 0.2215\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.21976\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 00287: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024746038, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1357 - val_loss: 0.2217\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.21976\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 00288: LearningRateScheduler reducing learning rate to tf.Tensor(0.000246255, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1345 - val_loss: 0.2219\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.21976\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 00289: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024505547, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1335 - val_loss: 0.2203\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.21976\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 00290: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024386184, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1333 - val_loss: 0.2207\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.21976\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 00291: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024267398, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1328 - val_loss: 0.2211\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.21976\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 00292: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024149191, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1336 - val_loss: 0.2224\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.21976\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 00293: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024031562, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1326 - val_loss: 0.2207\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.21976\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 00294: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023914504, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1342 - val_loss: 0.2211\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.21976\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 00295: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023798017, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1324 - val_loss: 0.2197\n",
      "\n",
      "Epoch 00295: val_loss improved from 0.21976 to 0.21967, saving model to folds6.hdf5\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 00296: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023682097, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1327 - val_loss: 0.2211\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.21967\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 00297: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023566742, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 45ms/step - loss: 0.1331 - val_loss: 0.2204\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.21967\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 00298: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023451951, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1319 - val_loss: 0.2196\n",
      "\n",
      "Epoch 00298: val_loss improved from 0.21967 to 0.21959, saving model to folds6.hdf5\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 00299: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023337714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1317 - val_loss: 0.2207\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.21959\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 00300: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023224037, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1322 - val_loss: 0.2213\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.21959\n",
      "(50300, 80)\n",
      "--------------- > Fold 8 < ---------------\n",
      "CNN: (None, 72, 256)\n",
      "LSTM: (None, 80, 256)\n",
      "Com: (None, 152, 256)\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 27s 200ms/step - loss: 3.5957 - val_loss: 0.8202\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.82020, saving model to folds7.hdf5\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.7696 - val_loss: 0.7075\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.82020 to 0.70754, saving model to folds7.hdf5\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.6285 - val_loss: 0.5399\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.70754 to 0.53992, saving model to folds7.hdf5\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.5395 - val_loss: 0.5773\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.53992\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.5223 - val_loss: 0.5073\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.53992 to 0.50730, saving model to folds7.hdf5\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4822 - val_loss: 0.4828\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.50730 to 0.48276, saving model to folds7.hdf5\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4676 - val_loss: 0.4723\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.48276 to 0.47227, saving model to folds7.hdf5\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4491 - val_loss: 0.4469\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.47227 to 0.44692, saving model to folds7.hdf5\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4378 - val_loss: 0.4296\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.44692 to 0.42957, saving model to folds7.hdf5\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4219 - val_loss: 0.4370\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.42957\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4143 - val_loss: 0.4283\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.42957 to 0.42832, saving model to folds7.hdf5\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.4055 - val_loss: 0.3985\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.42832 to 0.39853, saving model to folds7.hdf5\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3925 - val_loss: 0.4017\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.39853\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 48ms/step - loss: 0.3892 - val_loss: 0.4596\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.39853\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3864 - val_loss: 0.3749\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.39853 to 0.37493, saving model to folds7.hdf5\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3681 - val_loss: 0.3733\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.37493 to 0.37326, saving model to folds7.hdf5\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3612 - val_loss: 0.3959\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.37326\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3669 - val_loss: 0.3838\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.37326\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3679 - val_loss: 0.3679\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.37326 to 0.36787, saving model to folds7.hdf5\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3555 - val_loss: 0.3599\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.36787 to 0.35994, saving model to folds7.hdf5\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3563 - val_loss: 0.3578\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.35994 to 0.35785, saving model to folds7.hdf5\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3407 - val_loss: 0.3429\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.35785 to 0.34287, saving model to folds7.hdf5\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3350 - val_loss: 0.3496\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.34287\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3367 - val_loss: 0.3438\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.34287\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3394 - val_loss: 0.3422\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.34287 to 0.34221, saving model to folds7.hdf5\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3374 - val_loss: 0.3852\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.34221\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3324 - val_loss: 0.3292\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.34221 to 0.32923, saving model to folds7.hdf5\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3201 - val_loss: 0.3380\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.32923\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3196 - val_loss: 0.3247\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.32923 to 0.32473, saving model to folds7.hdf5\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3176 - val_loss: 0.3364\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.32473\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3209 - val_loss: 0.3264\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.32473\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3120 - val_loss: 0.3339\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.32473\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3063 - val_loss: 0.3240\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.32473 to 0.32399, saving model to folds7.hdf5\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3113 - val_loss: 0.3157\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.32399 to 0.31574, saving model to folds7.hdf5\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3002 - val_loss: 0.3372\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.31574\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2997 - val_loss: 0.3110\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.31574 to 0.31098, saving model to folds7.hdf5\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2933 - val_loss: 0.3215\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.31098\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2966 - val_loss: 0.3103\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.31098 to 0.31035, saving model to folds7.hdf5\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2964 - val_loss: 0.3062\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.31035 to 0.30623, saving model to folds7.hdf5\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2916 - val_loss: 0.3160\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.30623\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2979 - val_loss: 0.3085\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.30623\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2922 - val_loss: 0.3130\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.30623\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2853 - val_loss: 0.3042\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.30623 to 0.30416, saving model to folds7.hdf5\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2915 - val_loss: 0.3143\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.30416\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2836 - val_loss: 0.3078\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.30416\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2787 - val_loss: 0.3067\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.30416\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2797 - val_loss: 0.2981\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.30416 to 0.29812, saving model to folds7.hdf5\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2741 - val_loss: 0.3056\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.29812\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2772 - val_loss: 0.3373\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.29812\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2822 - val_loss: 0.3003\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.29812\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2690 - val_loss: 0.2930\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.29812 to 0.29298, saving model to folds7.hdf5\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2709 - val_loss: 0.2866\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.29298 to 0.28657, saving model to folds7.hdf5\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2718 - val_loss: 0.3046\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.28657\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2641 - val_loss: 0.2925\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.28657\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.2604 - val_loss: 0.3047\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.28657\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2759 - val_loss: 0.3071\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.28657\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2605 - val_loss: 0.2861\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.28657 to 0.28606, saving model to folds7.hdf5\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2584 - val_loss: 0.2845\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.28606 to 0.28447, saving model to folds7.hdf5\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2682 - val_loss: 0.2784\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.28447 to 0.27839, saving model to folds7.hdf5\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2631 - val_loss: 0.2833\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.27839\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2527 - val_loss: 0.2874\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.27839\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2588 - val_loss: 0.2846\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.27839\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007387921, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2510 - val_loss: 0.2759\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.27839 to 0.27593, saving model to folds7.hdf5\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to tf.Tensor(0.00073519343, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2509 - val_loss: 0.2791\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.27593\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007316123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2552 - val_loss: 0.2817\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.27593\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007280487, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2540 - val_loss: 0.2839\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.27593\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007245024, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2466 - val_loss: 0.2725\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.27593 to 0.27255, saving model to folds7.hdf5\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007209733, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2456 - val_loss: 0.2959\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.27255\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071746146, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2503 - val_loss: 0.2767\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.27255\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007139667, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2401 - val_loss: 0.2784\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.27255\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071048894, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2437 - val_loss: 0.2785\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.27255\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007070282, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2469 - val_loss: 0.2704\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.27255 to 0.27040, saving model to folds7.hdf5\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007035842, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2422 - val_loss: 0.2754\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.27040\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to tf.Tensor(0.00070015714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2374 - val_loss: 0.2633\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.27040 to 0.26332, saving model to folds7.hdf5\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006967467, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2299 - val_loss: 0.2741\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.26332\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to tf.Tensor(0.00069335283, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2356 - val_loss: 0.2721\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.26332\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006899755, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2369 - val_loss: 0.2661\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.26332\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068661466, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2291 - val_loss: 0.2636\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.26332\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068327016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2327 - val_loss: 0.2732\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.26332\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067994196, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2349 - val_loss: 0.2702\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.26332\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067663, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2308 - val_loss: 0.2723\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.26332\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006733342, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2315 - val_loss: 0.2650\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.26332\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067005435, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2257 - val_loss: 0.2641\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.26332\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006667905, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2278 - val_loss: 0.2655\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.26332\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006635426, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2282 - val_loss: 0.2607\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.26332 to 0.26074, saving model to folds7.hdf5\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006603105, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2224 - val_loss: 0.2585\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.26074 to 0.25846, saving model to folds7.hdf5\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006570942, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2197 - val_loss: 0.2640\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.25846\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065389345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2262 - val_loss: 0.2609\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.25846\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065070833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 52ms/step - loss: 0.2207 - val_loss: 0.2740\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.25846\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to tf.Tensor(0.00064753875, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2282 - val_loss: 0.2579\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.25846 to 0.25786, saving model to folds7.hdf5\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006443846, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2183 - val_loss: 0.2528\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.25786 to 0.25283, saving model to folds7.hdf5\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006412458, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2180 - val_loss: 0.2618\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.25283\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063812226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2174 - val_loss: 0.2584\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.25283\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063501403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2179 - val_loss: 0.2555\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.25283\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006319209, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2130 - val_loss: 0.2504\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.25283 to 0.25036, saving model to folds7.hdf5\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006288428, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2182 - val_loss: 0.2580\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.25036\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to tf.Tensor(0.00062577974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2112 - val_loss: 0.2613\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.25036\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006227316, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2171 - val_loss: 0.2531\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.25036\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061969826, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2119 - val_loss: 0.2590\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.25036\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 00100: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006166797, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2174 - val_loss: 0.2495\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.25036 to 0.24949, saving model to folds7.hdf5\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 00101: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061367586, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2091 - val_loss: 0.2599\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.24949\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 00102: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061068666, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2100 - val_loss: 0.2510\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.24949\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 00103: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006077121, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2072 - val_loss: 0.2604\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.24949\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 00104: LearningRateScheduler reducing learning rate to tf.Tensor(0.00060475187, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2076 - val_loss: 0.2518\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.24949\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 00105: LearningRateScheduler reducing learning rate to tf.Tensor(0.00060180615, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2086 - val_loss: 0.2471\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.24949 to 0.24713, saving model to folds7.hdf5\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 00106: LearningRateScheduler reducing learning rate to tf.Tensor(0.00059887476, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2044 - val_loss: 0.2520\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.24713\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 00107: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005959577, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2087 - val_loss: 0.2491\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.24713\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 00108: LearningRateScheduler reducing learning rate to tf.Tensor(0.00059305475, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2071 - val_loss: 0.2473\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.24713\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 00109: LearningRateScheduler reducing learning rate to tf.Tensor(0.000590166, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2028 - val_loss: 0.2486\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.24713\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 00110: LearningRateScheduler reducing learning rate to tf.Tensor(0.00058729126, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2059 - val_loss: 0.2450\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.24713 to 0.24497, saving model to folds7.hdf5\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 00111: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005844306, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2043 - val_loss: 0.2444\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.24497 to 0.24435, saving model to folds7.hdf5\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 00112: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005815838, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2025 - val_loss: 0.2426\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.24435 to 0.24258, saving model to folds7.hdf5\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 00113: LearningRateScheduler reducing learning rate to tf.Tensor(0.000578751, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1990 - val_loss: 0.2470\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.24258\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 00114: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057593186, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1983 - val_loss: 0.2406\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.24258 to 0.24063, saving model to folds7.hdf5\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 00115: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057312654, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1972 - val_loss: 0.2435\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.24063\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 00116: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057033484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1988 - val_loss: 0.2443\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.24063\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 00117: LearningRateScheduler reducing learning rate to tf.Tensor(0.00056755677, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2030 - val_loss: 0.2723\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.24063\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 00118: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005647922, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2026 - val_loss: 0.2426\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.24063\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 00119: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005620411, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1957 - val_loss: 0.2473\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.24063\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 00120: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055930344, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 47ms/step - loss: 0.1964 - val_loss: 0.2460\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.24063\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 00121: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055657903, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1955 - val_loss: 0.2444\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.24063\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 00122: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055386795, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 52ms/step - loss: 0.1939 - val_loss: 0.2400\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.24063 to 0.24000, saving model to folds7.hdf5\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 00123: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005511701, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1946 - val_loss: 0.2441\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.24000\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 00124: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005484854, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1908 - val_loss: 0.2395\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.24000 to 0.23952, saving model to folds7.hdf5\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 00125: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005458137, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1908 - val_loss: 0.2382\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.23952 to 0.23825, saving model to folds7.hdf5\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 00126: LearningRateScheduler reducing learning rate to tf.Tensor(0.00054315507, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1936 - val_loss: 0.2438\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.23825\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 00127: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005405093, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1949 - val_loss: 0.2383\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.23825\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 00128: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005378765, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1882 - val_loss: 0.2361\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.23825 to 0.23606, saving model to folds7.hdf5\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 00129: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005352565, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1877 - val_loss: 0.2379\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.23606\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 00130: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005326493, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1902 - val_loss: 0.2426\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.23606\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 00131: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005300548, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1890 - val_loss: 0.2437\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.23606\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 00132: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005274729, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1888 - val_loss: 0.2379\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.23606\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 00133: LearningRateScheduler reducing learning rate to tf.Tensor(0.00052490365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1932 - val_loss: 0.2350\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.23606 to 0.23501, saving model to folds7.hdf5\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 00134: LearningRateScheduler reducing learning rate to tf.Tensor(0.00052234676, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1855 - val_loss: 0.2365\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.23501\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 00135: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005198025, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1846 - val_loss: 0.2341\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.23501 to 0.23409, saving model to folds7.hdf5\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 00136: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005172705, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1836 - val_loss: 0.2372\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.23409\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 00137: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051475083, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1854 - val_loss: 0.2367\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.23409\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 00138: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051224354, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1839 - val_loss: 0.2346\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.23409\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 00139: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005097484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1814 - val_loss: 0.2352\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.23409\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 00140: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005072654, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1831 - val_loss: 0.2327\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.23409 to 0.23265, saving model to folds7.hdf5\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 00141: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005047946, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1808 - val_loss: 0.2380\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.23265\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 00142: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005023357, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1806 - val_loss: 0.2327\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.23265\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 00143: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049988885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1819 - val_loss: 0.2320\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.23265 to 0.23202, saving model to folds7.hdf5\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 00144: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004974539, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1793 - val_loss: 0.2362\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.23202\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 00145: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004950308, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1813 - val_loss: 0.2347\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.23202\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 00146: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004926195, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1792 - val_loss: 0.2341\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.23202\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 00147: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049022, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1792 - val_loss: 0.2352\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.23202\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 00148: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048783212, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1773 - val_loss: 0.2391\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.23202\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 00149: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048545588, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1771 - val_loss: 0.2349\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.23202\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 00150: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048309125, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1782 - val_loss: 0.2389\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.23202\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 00151: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048073815, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1786 - val_loss: 0.2372\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.23202\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 00152: LearningRateScheduler reducing learning rate to tf.Tensor(0.00047839645, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1761 - val_loss: 0.2344\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.23202\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 00153: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004760662, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1782 - val_loss: 0.2302\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.23202 to 0.23022, saving model to folds7.hdf5\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 00154: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004737473, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1782 - val_loss: 0.2317\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.23022\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 00155: LearningRateScheduler reducing learning rate to tf.Tensor(0.00047143968, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1738 - val_loss: 0.2295\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.23022 to 0.22951, saving model to folds7.hdf5\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 00156: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004691433, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1726 - val_loss: 0.2268\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.22951 to 0.22676, saving model to folds7.hdf5\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 00157: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046685815, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1741 - val_loss: 0.2303\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.22676\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 00158: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046458407, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1727 - val_loss: 0.2292\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.22676\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 00159: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046232107, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1736 - val_loss: 0.2289\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.22676\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 00160: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046006907, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1713 - val_loss: 0.2344\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.22676\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 00161: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045782814, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1762 - val_loss: 0.2296\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.22676\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 00162: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045559806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1698 - val_loss: 0.2328\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.22676\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 00163: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045337883, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1697 - val_loss: 0.2294\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.22676\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 00164: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045117046, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1692 - val_loss: 0.2283\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.22676\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 00165: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044897277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1716 - val_loss: 0.2371\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.22676\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 00166: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044678585, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1723 - val_loss: 0.2283\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.22676\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 00167: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004446096, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1683 - val_loss: 0.2293\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.22676\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 00168: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004424439, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1670 - val_loss: 0.2358\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.22676\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 00169: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044028874, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 52ms/step - loss: 0.1689 - val_loss: 0.2315\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.22676\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 00170: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043814414, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1694 - val_loss: 0.2257\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.22676 to 0.22574, saving model to folds7.hdf5\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 00171: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043600993, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1659 - val_loss: 0.2290\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.22574\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 00172: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043388613, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1669 - val_loss: 0.2299\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.22574\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 00173: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004317727, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1657 - val_loss: 0.2310\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.22574\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 00174: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004296695, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1686 - val_loss: 0.2249\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.22574 to 0.22490, saving model to folds7.hdf5\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 00175: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004275766, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1637 - val_loss: 0.2302\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.22490\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 00176: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042549393, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1653 - val_loss: 0.2282\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.22490\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 00177: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042342133, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1656 - val_loss: 0.2278\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.22490\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 00178: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042135885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1651 - val_loss: 0.2250\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.22490\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 00179: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041930642, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1633 - val_loss: 0.2282\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.22490\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 00180: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041726397, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1627 - val_loss: 0.2271\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.22490\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 00181: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041523148, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1630 - val_loss: 0.2277\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.22490\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 00182: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041320888, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1677 - val_loss: 0.2239\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.22490 to 0.22391, saving model to folds7.hdf5\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 00183: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041119618, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1612 - val_loss: 0.2249\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.22391\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 00184: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040919325, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1608 - val_loss: 0.2267\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.22391\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 00185: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040720004, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1603 - val_loss: 0.2249\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.22391\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 00186: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004052166, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1620 - val_loss: 0.2285\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.22391\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 00187: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004032428, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1625 - val_loss: 0.2222\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.22391 to 0.22224, saving model to folds7.hdf5\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 00188: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004012786, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1581 - val_loss: 0.2264\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.22224\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 00189: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039932402, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1601 - val_loss: 0.2269\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.22224\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 00190: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039737887, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1606 - val_loss: 0.2244\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.22224\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 00191: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039544326, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1606 - val_loss: 0.2274\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.22224\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 00192: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039351705, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1591 - val_loss: 0.2227\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.22224\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 00193: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039160028, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1550 - val_loss: 0.2243\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.22224\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 00194: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038969278, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1569 - val_loss: 0.2234\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.22224\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 00195: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003877946, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1600 - val_loss: 0.2216\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.22224 to 0.22157, saving model to folds7.hdf5\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 00196: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038590565, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1555 - val_loss: 0.2220\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.22157\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 00197: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003840259, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1568 - val_loss: 0.2237\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.22157\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 00198: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038215535, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1572 - val_loss: 0.2264\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.22157\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 00199: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038029387, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1557 - val_loss: 0.2222\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.22157\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 00200: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037844144, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1549 - val_loss: 0.2286\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.22157\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 00201: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037659804, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1596 - val_loss: 0.2224\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.22157\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 00202: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037476368, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1545 - val_loss: 0.2237\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.22157\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 00203: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037293817, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1557 - val_loss: 0.2233\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.22157\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 00204: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003711216, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1541 - val_loss: 0.2247\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.22157\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 00205: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003693139, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1573 - val_loss: 0.2214\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.22157 to 0.22143, saving model to folds7.hdf5\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 00206: LearningRateScheduler reducing learning rate to tf.Tensor(0.000367515, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1531 - val_loss: 0.2249\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.22143\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 00207: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036572482, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1561 - val_loss: 0.2244\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.22143\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 00208: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003639434, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1569 - val_loss: 0.2222\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.22143\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 00209: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036217063, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1523 - val_loss: 0.2207\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.22143 to 0.22067, saving model to folds7.hdf5\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 00210: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036040647, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1514 - val_loss: 0.2207\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.22067\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 00211: LearningRateScheduler reducing learning rate to tf.Tensor(0.00035865093, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1515 - val_loss: 0.2233\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.22067\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 00212: LearningRateScheduler reducing learning rate to tf.Tensor(0.000356904, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1508 - val_loss: 0.2205\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.22067 to 0.22051, saving model to folds7.hdf5\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 00213: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003551655, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1503 - val_loss: 0.2236\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.22051\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 00214: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003534355, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1519 - val_loss: 0.2238\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.22051\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 00215: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003517139, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 4s 53ms/step - loss: 0.1499 - val_loss: 0.2210\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.22051\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 00216: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003500007, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1506 - val_loss: 0.2211\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.22051\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 00217: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034829587, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1511 - val_loss: 0.2251\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.22051\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 00218: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034659932, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1519 - val_loss: 0.2207\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.22051\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 00219: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034491107, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1499 - val_loss: 0.2212\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.22051\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 00220: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034323102, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1496 - val_loss: 0.2218\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.22051\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 00221: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034155912, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1503 - val_loss: 0.2213\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.22051\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 00222: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033989537, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1494 - val_loss: 0.2203\n",
      "\n",
      "Epoch 00222: val_loss improved from 0.22051 to 0.22029, saving model to folds7.hdf5\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 00223: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033823974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1477 - val_loss: 0.2210\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.22029\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 00224: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003365922, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1482 - val_loss: 0.2210\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.22029\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 00225: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033495267, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1479 - val_loss: 0.2205\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.22029\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 00226: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003333211, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1479 - val_loss: 0.2189\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.22029 to 0.21893, saving model to folds7.hdf5\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 00227: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033169755, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1476 - val_loss: 0.2213\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.21893\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 00228: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033008185, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1486 - val_loss: 0.2190\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.21893\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 00229: LearningRateScheduler reducing learning rate to tf.Tensor(0.000328474, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1469 - val_loss: 0.2202\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.21893\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 00230: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032687403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1469 - val_loss: 0.2250\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.21893\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 00231: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003252818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1465 - val_loss: 0.2185\n",
      "\n",
      "Epoch 00231: val_loss improved from 0.21893 to 0.21846, saving model to folds7.hdf5\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 00232: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032369737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1452 - val_loss: 0.2206\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.21846\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 00233: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032212064, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1455 - val_loss: 0.2217\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.21846\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 00234: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032055163, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1473 - val_loss: 0.2235\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.21846\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 00235: LearningRateScheduler reducing learning rate to tf.Tensor(0.00031899018, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1467 - val_loss: 0.2222\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.21846\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 00236: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003174364, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1462 - val_loss: 0.2191\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.21846\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 00237: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003158902, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1444 - val_loss: 0.2228\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.21846\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 00238: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003143515, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1438 - val_loss: 0.2196\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.21846\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 00239: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003128203, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1439 - val_loss: 0.2205\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.21846\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 00240: LearningRateScheduler reducing learning rate to tf.Tensor(0.00031129655, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1455 - val_loss: 0.2180\n",
      "\n",
      "Epoch 00240: val_loss improved from 0.21846 to 0.21799, saving model to folds7.hdf5\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 00241: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003097802, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1424 - val_loss: 0.2192\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.21799\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 00242: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003082713, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1431 - val_loss: 0.2194\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.21799\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 00243: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003067697, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1418 - val_loss: 0.2229\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.21799\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 00244: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030527546, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1432 - val_loss: 0.2203\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.21799\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 00245: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030378843, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1425 - val_loss: 0.2175\n",
      "\n",
      "Epoch 00245: val_loss improved from 0.21799 to 0.21754, saving model to folds7.hdf5\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 00246: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003023087, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1414 - val_loss: 0.2200\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.21754\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 00247: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030083617, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1434 - val_loss: 0.2215\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.21754\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 00248: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002993708, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1425 - val_loss: 0.2192\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.21754\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 00249: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029791257, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1411 - val_loss: 0.2181\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.21754\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 00250: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029646145, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1409 - val_loss: 0.2191\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.21754\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 00251: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029501738, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1399 - val_loss: 0.2188\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.21754\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 00252: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029358038, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1396 - val_loss: 0.2181\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.21754\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 00253: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029215033, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1407 - val_loss: 0.2184\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.21754\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 00254: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029072727, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1392 - val_loss: 0.2197\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.21754\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 00255: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028931117, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1401 - val_loss: 0.2202\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.21754\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 00256: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028790193, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1420 - val_loss: 0.2176\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.21754\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 00257: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028649953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1396 - val_loss: 0.2192\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.21754\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 00258: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028510403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1386 - val_loss: 0.2184\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.21754\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 00259: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002837153, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1410 - val_loss: 0.2171\n",
      "\n",
      "Epoch 00259: val_loss improved from 0.21754 to 0.21705, saving model to folds7.hdf5\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 00260: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002823333, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1403 - val_loss: 0.2190\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.21705\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 00261: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028095808, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1405 - val_loss: 0.2186\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.21705\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 00262: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027958953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1382 - val_loss: 0.2180\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.21705\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 00263: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027822764, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1378 - val_loss: 0.2202\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.21705\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 00264: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027687242, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 52ms/step - loss: 0.1395 - val_loss: 0.2183\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.21705\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 00265: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027552375, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1391 - val_loss: 0.2172\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.21705\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 00266: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002741817, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1370 - val_loss: 0.2181\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.21705\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 00267: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027284614, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1383 - val_loss: 0.2174\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.21705\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 00268: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027151714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 46ms/step - loss: 0.1365 - val_loss: 0.2183\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.21705\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 00269: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027019458, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1370 - val_loss: 0.2189\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.21705\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 00270: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026887844, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1373 - val_loss: 0.2190\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.21705\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 00271: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026756877, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1371 - val_loss: 0.2169\n",
      "\n",
      "Epoch 00271: val_loss improved from 0.21705 to 0.21692, saving model to folds7.hdf5\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 00272: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026626544, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1358 - val_loss: 0.2167\n",
      "\n",
      "Epoch 00272: val_loss improved from 0.21692 to 0.21674, saving model to folds7.hdf5\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 00273: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026496846, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1358 - val_loss: 0.2192\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.21674\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 00274: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026367782, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1360 - val_loss: 0.2188\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.21674\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 00275: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026239344, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1351 - val_loss: 0.2179\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.21674\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 00276: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026111532, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1359 - val_loss: 0.2212\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.21674\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 00277: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025984345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1421 - val_loss: 0.2192\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.21674\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 00278: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025857775, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1357 - val_loss: 0.2170\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.21674\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 00279: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002573182, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1359 - val_loss: 0.2173\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.21674\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 00280: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025606484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1344 - val_loss: 0.2195\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.21674\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 00281: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025481754, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1356 - val_loss: 0.2167\n",
      "\n",
      "Epoch 00281: val_loss improved from 0.21674 to 0.21670, saving model to folds7.hdf5\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 00282: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025357632, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1356 - val_loss: 0.2162\n",
      "\n",
      "Epoch 00282: val_loss improved from 0.21670 to 0.21615, saving model to folds7.hdf5\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 00283: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025234115, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1345 - val_loss: 0.2175\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.21615\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 00284: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025111204, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1337 - val_loss: 0.2169\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.21615\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 00285: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024988884, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1332 - val_loss: 0.2164\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.21615\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 00286: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024867163, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1326 - val_loss: 0.2187\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.21615\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 00287: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024746038, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1337 - val_loss: 0.2162\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.21615\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 00288: LearningRateScheduler reducing learning rate to tf.Tensor(0.000246255, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1337 - val_loss: 0.2176\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.21615\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 00289: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024505547, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1335 - val_loss: 0.2183\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.21615\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 00290: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024386184, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1343 - val_loss: 0.2166\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.21615\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 00291: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024267398, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1324 - val_loss: 0.2166\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.21615\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 00292: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024149191, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1323 - val_loss: 0.2171\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.21615\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 00293: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024031562, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1314 - val_loss: 0.2178\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.21615\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 00294: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023914504, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1320 - val_loss: 0.2170\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.21615\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 00295: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023798017, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1325 - val_loss: 0.2202\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.21615\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 00296: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023682097, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1336 - val_loss: 0.2174\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.21615\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 00297: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023566742, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1314 - val_loss: 0.2168\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.21615\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 00298: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023451951, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1321 - val_loss: 0.2162\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.21615\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 00299: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023337714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1310 - val_loss: 0.2164\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.21615\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 00300: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023224037, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1313 - val_loss: 0.2173\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.21615\n",
      "(50300, 80)\n",
      "--------------- > Fold 9 < ---------------\n",
      "CNN: (None, 72, 256)\n",
      "LSTM: (None, 80, 256)\n",
      "Com: (None, 152, 256)\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 28s 199ms/step - loss: 3.5675 - val_loss: 0.7980\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.79803, saving model to folds8.hdf5\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.7675 - val_loss: 0.6506\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.79803 to 0.65059, saving model to folds8.hdf5\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.6177 - val_loss: 0.5680\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65059 to 0.56804, saving model to folds8.hdf5\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.5612 - val_loss: 0.5028\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.56804 to 0.50276, saving model to folds8.hdf5\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.5095 - val_loss: 0.4777\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.50276 to 0.47768, saving model to folds8.hdf5\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.4782 - val_loss: 0.4765\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47768 to 0.47649, saving model to folds8.hdf5\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4592 - val_loss: 0.4590\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.47649 to 0.45901, saving model to folds8.hdf5\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4583 - val_loss: 0.4224\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.45901 to 0.42244, saving model to folds8.hdf5\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4282 - val_loss: 0.4110\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.42244 to 0.41101, saving model to folds8.hdf5\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4190 - val_loss: 0.4265\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.41101\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4092 - val_loss: 0.4076\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.41101 to 0.40764, saving model to folds8.hdf5\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3994 - val_loss: 0.3842\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.40764 to 0.38416, saving model to folds8.hdf5\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3864 - val_loss: 0.4009\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.38416\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3880 - val_loss: 0.3785\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.38416 to 0.37848, saving model to folds8.hdf5\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3803 - val_loss: 0.3787\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.37848\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3770 - val_loss: 0.3875\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.37848\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 46ms/step - loss: 0.3733 - val_loss: 0.4070\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.37848\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3739 - val_loss: 0.3922\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.37848\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3784 - val_loss: 0.3601\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.37848 to 0.36012, saving model to folds8.hdf5\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3484 - val_loss: 0.3521\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.36012 to 0.35211, saving model to folds8.hdf5\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3468 - val_loss: 0.3482\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.35211 to 0.34818, saving model to folds8.hdf5\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3418 - val_loss: 0.3557\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.34818\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3417 - val_loss: 0.3490\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.34818\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3324 - val_loss: 0.3567\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.34818\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3389 - val_loss: 0.3323\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.34818 to 0.33230, saving model to folds8.hdf5\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 50ms/step - loss: 0.3322 - val_loss: 0.3933\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33230\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3420 - val_loss: 0.3312\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.33230 to 0.33117, saving model to folds8.hdf5\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3303 - val_loss: 0.3523\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33117\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3198 - val_loss: 0.3280\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.33117 to 0.32801, saving model to folds8.hdf5\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3205 - val_loss: 0.3397\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.32801\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3307 - val_loss: 0.3243\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.32801 to 0.32431, saving model to folds8.hdf5\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3055 - val_loss: 0.3213\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.32431 to 0.32125, saving model to folds8.hdf5\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3031 - val_loss: 0.3220\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.32125\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3013 - val_loss: 0.3314\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.32125\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3060 - val_loss: 0.3215\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.32125\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3035 - val_loss: 0.3229\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.32125\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.3031 - val_loss: 0.3166\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.32125 to 0.31663, saving model to folds8.hdf5\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2990 - val_loss: 0.3205\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.31663\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2962 - val_loss: 0.3168\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.31663\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2953 - val_loss: 0.3073\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.31663 to 0.30734, saving model to folds8.hdf5\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2954 - val_loss: 0.3128\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.30734\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2835 - val_loss: 0.3036\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.30734 to 0.30361, saving model to folds8.hdf5\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2875 - val_loss: 0.3039\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.30361\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2892 - val_loss: 0.3280\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.30361\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2915 - val_loss: 0.3085\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.30361\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2792 - val_loss: 0.3132\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.30361\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2754 - val_loss: 0.2909\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.30361 to 0.29093, saving model to folds8.hdf5\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2762 - val_loss: 0.2959\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.29093\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2748 - val_loss: 0.3016\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.29093\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2738 - val_loss: 0.2894\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.29093 to 0.28938, saving model to folds8.hdf5\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2687 - val_loss: 0.2911\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.28938\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2663 - val_loss: 0.2873\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.28938 to 0.28727, saving model to folds8.hdf5\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2645 - val_loss: 0.3151\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.28727\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2652 - val_loss: 0.2904\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.28727\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2658 - val_loss: 0.2798\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.28727 to 0.27978, saving model to folds8.hdf5\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2569 - val_loss: 0.2960\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.27978\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2615 - val_loss: 0.2840\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.27978\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2588 - val_loss: 0.2965\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.27978\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2621 - val_loss: 0.2916\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.27978\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2557 - val_loss: 0.2794\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.27978 to 0.27935, saving model to folds8.hdf5\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2534 - val_loss: 0.2762\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.27935 to 0.27620, saving model to folds8.hdf5\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2547 - val_loss: 0.2857\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.27620\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007387921, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2536 - val_loss: 0.2908\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.27620\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to tf.Tensor(0.00073519343, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2514 - val_loss: 0.2795\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.27620\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007316123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2506 - val_loss: 0.2820\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.27620\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007280487, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2471 - val_loss: 0.2765\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.27620\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007245024, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2523 - val_loss: 0.2755\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.27620 to 0.27555, saving model to folds8.hdf5\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007209733, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2420 - val_loss: 0.2716\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.27555 to 0.27156, saving model to folds8.hdf5\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071746146, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 45ms/step - loss: 0.2476 - val_loss: 0.2838\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.27156\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007139667, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2516 - val_loss: 0.3045\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.27156\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071048894, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2513 - val_loss: 0.2723\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.27156\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007070282, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2501 - val_loss: 0.2886\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.27156\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007035842, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 52ms/step - loss: 0.2423 - val_loss: 0.2695\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.27156 to 0.26954, saving model to folds8.hdf5\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to tf.Tensor(0.00070015714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2386 - val_loss: 0.2818\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.26954\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006967467, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2486 - val_loss: 0.2775\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.26954\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to tf.Tensor(0.00069335283, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2381 - val_loss: 0.2633\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.26954 to 0.26329, saving model to folds8.hdf5\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006899755, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2317 - val_loss: 0.2639\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.26329\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068661466, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2328 - val_loss: 0.2708\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.26329\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068327016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2328 - val_loss: 0.2660\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.26329\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067994196, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2310 - val_loss: 0.2603\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.26329 to 0.26031, saving model to folds8.hdf5\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067663, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2277 - val_loss: 0.2577\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.26031 to 0.25766, saving model to folds8.hdf5\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006733342, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2253 - val_loss: 0.2662\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.25766\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067005435, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2282 - val_loss: 0.2661\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.25766\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006667905, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2276 - val_loss: 0.2644\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.25766\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006635426, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2266 - val_loss: 0.2557\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.25766 to 0.25571, saving model to folds8.hdf5\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006603105, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2249 - val_loss: 0.2717\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.25571\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006570942, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2273 - val_loss: 0.2559\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.25571\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065389345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2235 - val_loss: 0.2553\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.25571 to 0.25526, saving model to folds8.hdf5\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065070833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2200 - val_loss: 0.2540\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.25526 to 0.25395, saving model to folds8.hdf5\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to tf.Tensor(0.00064753875, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2206 - val_loss: 0.2559\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.25395\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006443846, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2186 - val_loss: 0.2522\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.25395 to 0.25216, saving model to folds8.hdf5\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006412458, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2172 - val_loss: 0.2525\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.25216\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063812226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2199 - val_loss: 0.2554\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.25216\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063501403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2185 - val_loss: 0.2527\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.25216\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006319209, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2123 - val_loss: 0.2499\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.25216 to 0.24993, saving model to folds8.hdf5\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006288428, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2165 - val_loss: 0.2522\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.24993\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to tf.Tensor(0.00062577974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2135 - val_loss: 0.2543\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.24993\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006227316, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2098 - val_loss: 0.2490\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.24993 to 0.24899, saving model to folds8.hdf5\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061969826, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2109 - val_loss: 0.2641\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.24899\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 00100: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006166797, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2139 - val_loss: 0.2483\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.24899 to 0.24833, saving model to folds8.hdf5\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 00101: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061367586, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2097 - val_loss: 0.2488\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.24833\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 00102: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061068666, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2106 - val_loss: 0.2549\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.24833\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 00103: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006077121, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2103 - val_loss: 0.2485\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.24833\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 00104: LearningRateScheduler reducing learning rate to tf.Tensor(0.00060475187, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2070 - val_loss: 0.2445\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.24833 to 0.24453, saving model to folds8.hdf5\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 00105: LearningRateScheduler reducing learning rate to tf.Tensor(0.00060180615, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2066 - val_loss: 0.2546\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.24453\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 00106: LearningRateScheduler reducing learning rate to tf.Tensor(0.00059887476, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2134 - val_loss: 0.2442\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.24453 to 0.24418, saving model to folds8.hdf5\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 00107: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005959577, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2056 - val_loss: 0.2447\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.24418\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 00108: LearningRateScheduler reducing learning rate to tf.Tensor(0.00059305475, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2030 - val_loss: 0.2446\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.24418\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 00109: LearningRateScheduler reducing learning rate to tf.Tensor(0.000590166, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2018 - val_loss: 0.2406\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.24418 to 0.24056, saving model to folds8.hdf5\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 00110: LearningRateScheduler reducing learning rate to tf.Tensor(0.00058729126, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2017 - val_loss: 0.2443\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.24056\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 00111: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005844306, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2035 - val_loss: 0.2490\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.24056\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 00112: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005815838, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 52ms/step - loss: 0.2037 - val_loss: 0.2399\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.24056 to 0.23991, saving model to folds8.hdf5\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 00113: LearningRateScheduler reducing learning rate to tf.Tensor(0.000578751, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1978 - val_loss: 0.2462\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.23991\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 00114: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057593186, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2058 - val_loss: 0.2420\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.23991\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 00115: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057312654, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1997 - val_loss: 0.2442\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.23991\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 00116: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057033484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1976 - val_loss: 0.2433\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.23991\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 00117: LearningRateScheduler reducing learning rate to tf.Tensor(0.00056755677, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1952 - val_loss: 0.2399\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.23991 to 0.23988, saving model to folds8.hdf5\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 00118: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005647922, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1957 - val_loss: 0.2391\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.23988 to 0.23913, saving model to folds8.hdf5\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 00119: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005620411, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1943 - val_loss: 0.2580\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.23913\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 00120: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055930344, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2063 - val_loss: 0.2364\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.23913 to 0.23643, saving model to folds8.hdf5\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 00121: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055657903, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.1932 - val_loss: 0.2376\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.23643\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 00122: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055386795, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1925 - val_loss: 0.2386\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.23643\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 00123: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005511701, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1914 - val_loss: 0.2383\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.23643\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 00124: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005484854, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1911 - val_loss: 0.2349\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.23643 to 0.23494, saving model to folds8.hdf5\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 00125: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005458137, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1905 - val_loss: 0.2510\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.23494\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 00126: LearningRateScheduler reducing learning rate to tf.Tensor(0.00054315507, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1954 - val_loss: 0.2358\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.23494\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 00127: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005405093, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1882 - val_loss: 0.2371\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.23494\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 00128: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005378765, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1913 - val_loss: 0.2344\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.23494 to 0.23442, saving model to folds8.hdf5\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 00129: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005352565, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1895 - val_loss: 0.2436\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.23442\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 00130: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005326493, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1949 - val_loss: 0.2342\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.23442 to 0.23418, saving model to folds8.hdf5\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 00131: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005300548, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1869 - val_loss: 0.2337\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.23418 to 0.23368, saving model to folds8.hdf5\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 00132: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005274729, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1866 - val_loss: 0.2344\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.23368\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 00133: LearningRateScheduler reducing learning rate to tf.Tensor(0.00052490365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1884 - val_loss: 0.2367\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.23368\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 00134: LearningRateScheduler reducing learning rate to tf.Tensor(0.00052234676, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1858 - val_loss: 0.2363\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.23368\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 00135: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005198025, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1884 - val_loss: 0.2345\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.23368\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 00136: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005172705, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1866 - val_loss: 0.2336\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.23368 to 0.23362, saving model to folds8.hdf5\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 00137: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051475083, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1866 - val_loss: 0.2408\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.23362\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 00138: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051224354, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1866 - val_loss: 0.2346\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.23362\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 00139: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005097484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1820 - val_loss: 0.2382\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.23362\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 00140: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005072654, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1840 - val_loss: 0.2379\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.23362\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 00141: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005047946, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1840 - val_loss: 0.2335\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.23362 to 0.23346, saving model to folds8.hdf5\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 00142: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005023357, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1819 - val_loss: 0.2405\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.23346\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 00143: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049988885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1917 - val_loss: 0.2317\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.23346 to 0.23168, saving model to folds8.hdf5\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 00144: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004974539, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1785 - val_loss: 0.2304\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.23168 to 0.23045, saving model to folds8.hdf5\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 00145: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004950308, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1794 - val_loss: 0.2341\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.23045\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 00146: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004926195, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1788 - val_loss: 0.2302\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.23045 to 0.23023, saving model to folds8.hdf5\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 00147: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049022, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1759 - val_loss: 0.2308\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.23023\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 00148: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048783212, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1788 - val_loss: 0.2314\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.23023\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 00149: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048545588, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1785 - val_loss: 0.2334\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.23023\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 00150: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048309125, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1775 - val_loss: 0.2366\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.23023\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 00151: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048073815, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1775 - val_loss: 0.2351\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.23023\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 00152: LearningRateScheduler reducing learning rate to tf.Tensor(0.00047839645, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1789 - val_loss: 0.2258\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.23023 to 0.22575, saving model to folds8.hdf5\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 00153: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004760662, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1767 - val_loss: 0.2305\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.22575\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 00154: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004737473, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1763 - val_loss: 0.2285\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.22575\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 00155: LearningRateScheduler reducing learning rate to tf.Tensor(0.00047143968, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1746 - val_loss: 0.2294\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.22575\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 00156: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004691433, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1746 - val_loss: 0.2322\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.22575\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 00157: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046685815, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1770 - val_loss: 0.2288\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.22575\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 00158: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046458407, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1715 - val_loss: 0.2293\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.22575\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 00159: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046232107, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1708 - val_loss: 0.2283\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.22575\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 00160: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046006907, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1724 - val_loss: 0.2295\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.22575\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 00161: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045782814, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1715 - val_loss: 0.2289\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.22575\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 00162: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045559806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1741 - val_loss: 0.2268\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.22575\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 00163: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045337883, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1703 - val_loss: 0.2272\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.22575\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 00164: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045117046, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1695 - val_loss: 0.2261\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.22575\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 00165: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044897277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1680 - val_loss: 0.2283\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.22575\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 00166: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044678585, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1716 - val_loss: 0.2286\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.22575\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 00167: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004446096, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1696 - val_loss: 0.2294\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.22575\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 00168: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004424439, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1700 - val_loss: 0.2281\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.22575\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 00169: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044028874, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 52ms/step - loss: 0.1677 - val_loss: 0.2259\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.22575\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 00170: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043814414, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1683 - val_loss: 0.2251\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.22575 to 0.22511, saving model to folds8.hdf5\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 00171: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043600993, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1670 - val_loss: 0.2257\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.22511\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 00172: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043388613, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1683 - val_loss: 0.2273\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.22511\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 00173: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004317727, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1674 - val_loss: 0.2254\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.22511\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 00174: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004296695, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1656 - val_loss: 0.2286\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.22511\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 00175: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004275766, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1667 - val_loss: 0.2250\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.22511 to 0.22502, saving model to folds8.hdf5\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 00176: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042549393, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1640 - val_loss: 0.2231\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.22502 to 0.22309, saving model to folds8.hdf5\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 00177: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042342133, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1623 - val_loss: 0.2234\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.22309\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 00178: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042135885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1629 - val_loss: 0.2258\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.22309\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 00179: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041930642, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1638 - val_loss: 0.2242\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.22309\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 00180: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041726397, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 45ms/step - loss: 0.1674 - val_loss: 0.2270\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.22309\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 00181: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041523148, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1668 - val_loss: 0.2261\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.22309\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 00182: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041320888, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1636 - val_loss: 0.2250\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.22309\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 00183: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041119618, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1637 - val_loss: 0.2239\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.22309\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 00184: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040919325, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1613 - val_loss: 0.2244\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.22309\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 00185: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040720004, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1614 - val_loss: 0.2229\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.22309 to 0.22291, saving model to folds8.hdf5\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 00186: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004052166, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1580 - val_loss: 0.2254\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.22291\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 00187: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004032428, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 45ms/step - loss: 0.1630 - val_loss: 0.2228\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.22291 to 0.22283, saving model to folds8.hdf5\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 00188: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004012786, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1626 - val_loss: 0.2308\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.22283\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 00189: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039932402, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1664 - val_loss: 0.2214\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.22283 to 0.22143, saving model to folds8.hdf5\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 00190: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039737887, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1572 - val_loss: 0.2235\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.22143\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 00191: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039544326, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1610 - val_loss: 0.2236\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.22143\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 00192: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039351705, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1566 - val_loss: 0.2220\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.22143\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 00193: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039160028, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1590 - val_loss: 0.2223\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.22143\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 00194: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038969278, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1580 - val_loss: 0.2260\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.22143\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 00195: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003877946, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1601 - val_loss: 0.2224\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.22143\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 00196: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038590565, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1580 - val_loss: 0.2226\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.22143\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 00197: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003840259, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1555 - val_loss: 0.2228\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.22143\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 00198: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038215535, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1564 - val_loss: 0.2222\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.22143\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 00199: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038029387, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1550 - val_loss: 0.2236\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.22143\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 00200: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037844144, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1562 - val_loss: 0.2323\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.22143\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 00201: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037659804, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1582 - val_loss: 0.2217\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.22143\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 00202: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037476368, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1550 - val_loss: 0.2217\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.22143\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 00203: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037293817, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1559 - val_loss: 0.2208\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.22143 to 0.22082, saving model to folds8.hdf5\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 00204: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003711216, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1544 - val_loss: 0.2220\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.22082\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 00205: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003693139, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1543 - val_loss: 0.2208\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.22082 to 0.22081, saving model to folds8.hdf5\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 00206: LearningRateScheduler reducing learning rate to tf.Tensor(0.000367515, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1520 - val_loss: 0.2216\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.22081\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 00207: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036572482, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1528 - val_loss: 0.2202\n",
      "\n",
      "Epoch 00207: val_loss improved from 0.22081 to 0.22023, saving model to folds8.hdf5\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 00208: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003639434, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1523 - val_loss: 0.2221\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.22023\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 00209: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036217063, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1556 - val_loss: 0.2200\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.22023 to 0.22003, saving model to folds8.hdf5\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 00210: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036040647, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1522 - val_loss: 0.2277\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.22003\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 00211: LearningRateScheduler reducing learning rate to tf.Tensor(0.00035865093, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1545 - val_loss: 0.2215\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.22003\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 00212: LearningRateScheduler reducing learning rate to tf.Tensor(0.000356904, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1509 - val_loss: 0.2214\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.22003\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 00213: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003551655, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1517 - val_loss: 0.2217\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.22003\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 00214: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003534355, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 52ms/step - loss: 0.1509 - val_loss: 0.2192\n",
      "\n",
      "Epoch 00214: val_loss improved from 0.22003 to 0.21924, saving model to folds8.hdf5\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 00215: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003517139, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1511 - val_loss: 0.2229\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.21924\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 00216: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003500007, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1530 - val_loss: 0.2216\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.21924\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 00217: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034829587, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1502 - val_loss: 0.2222\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.21924\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 00218: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034659932, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1518 - val_loss: 0.2187\n",
      "\n",
      "Epoch 00218: val_loss improved from 0.21924 to 0.21867, saving model to folds8.hdf5\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 00219: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034491107, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1485 - val_loss: 0.2186\n",
      "\n",
      "Epoch 00219: val_loss improved from 0.21867 to 0.21855, saving model to folds8.hdf5\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 00220: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034323102, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1486 - val_loss: 0.2203\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.21855\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 00221: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034155912, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1519 - val_loss: 0.2223\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.21855\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 00222: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033989537, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1487 - val_loss: 0.2194\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.21855\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 00223: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033823974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1485 - val_loss: 0.2217\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.21855\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 00224: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003365922, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1471 - val_loss: 0.2219\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.21855\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 00225: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033495267, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1512 - val_loss: 0.2197\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.21855\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 00226: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003333211, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1469 - val_loss: 0.2206\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.21855\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 00227: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033169755, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1495 - val_loss: 0.2222\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.21855\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 00228: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033008185, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1494 - val_loss: 0.2199\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.21855\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 00229: LearningRateScheduler reducing learning rate to tf.Tensor(0.000328474, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1476 - val_loss: 0.2188\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.21855\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 00230: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032687403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 46ms/step - loss: 0.1471 - val_loss: 0.2198\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.21855\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 00231: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003252818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1469 - val_loss: 0.2209\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.21855\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 00232: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032369737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1468 - val_loss: 0.2193\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.21855\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 00233: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032212064, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1453 - val_loss: 0.2201\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.21855\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 00234: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032055163, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1457 - val_loss: 0.2184\n",
      "\n",
      "Epoch 00234: val_loss improved from 0.21855 to 0.21843, saving model to folds8.hdf5\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 00235: LearningRateScheduler reducing learning rate to tf.Tensor(0.00031899018, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1465 - val_loss: 0.2209\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.21843\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 00236: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003174364, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1445 - val_loss: 0.2200\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.21843\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 00237: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003158902, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1466 - val_loss: 0.2190\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.21843\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 00238: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003143515, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1435 - val_loss: 0.2197\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.21843\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 00239: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003128203, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1442 - val_loss: 0.2193\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.21843\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 00240: LearningRateScheduler reducing learning rate to tf.Tensor(0.00031129655, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1436 - val_loss: 0.2186\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.21843\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 00241: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003097802, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1444 - val_loss: 0.2201\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.21843\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 00242: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003082713, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1437 - val_loss: 0.2188\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.21843\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 00243: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003067697, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1415 - val_loss: 0.2195\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.21843\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 00244: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030527546, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1430 - val_loss: 0.2194\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.21843\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 00245: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030378843, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1429 - val_loss: 0.2221\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.21843\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 00246: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003023087, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1437 - val_loss: 0.2193\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.21843\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 00247: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030083617, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1434 - val_loss: 0.2188\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.21843\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 00248: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002993708, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1428 - val_loss: 0.2224\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.21843\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 00249: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029791257, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1440 - val_loss: 0.2180\n",
      "\n",
      "Epoch 00249: val_loss improved from 0.21843 to 0.21801, saving model to folds8.hdf5\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 00250: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029646145, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1425 - val_loss: 0.2199\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.21801\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 00251: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029501738, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1424 - val_loss: 0.2196\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.21801\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 00252: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029358038, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1427 - val_loss: 0.2180\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.21801\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 00253: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029215033, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1411 - val_loss: 0.2192\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.21801\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 00254: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029072727, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1404 - val_loss: 0.2175\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.21801 to 0.21750, saving model to folds8.hdf5\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 00255: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028931117, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1391 - val_loss: 0.2179\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.21750\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 00256: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028790193, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1398 - val_loss: 0.2186\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.21750\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 00257: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028649953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1398 - val_loss: 0.2204\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.21750\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 00258: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028510403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1405 - val_loss: 0.2190\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.21750\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 00259: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002837153, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1396 - val_loss: 0.2195\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.21750\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 00260: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002823333, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1394 - val_loss: 0.2177\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.21750\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 00261: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028095808, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1373 - val_loss: 0.2206\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.21750\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 00262: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027958953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1397 - val_loss: 0.2186\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.21750\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 00263: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027822764, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1387 - val_loss: 0.2210\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.21750\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 00264: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027687242, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1395 - val_loss: 0.2197\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.21750\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 00265: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027552375, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1397 - val_loss: 0.2186\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.21750\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 00266: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002741817, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 52ms/step - loss: 0.1377 - val_loss: 0.2178\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.21750\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 00267: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027284614, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1386 - val_loss: 0.2180\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.21750\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 00268: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027151714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1368 - val_loss: 0.2189\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.21750\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 00269: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027019458, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1378 - val_loss: 0.2178\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.21750\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 00270: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026887844, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1367 - val_loss: 0.2179\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.21750\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 00271: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026756877, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1389 - val_loss: 0.2176\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.21750\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 00272: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026626544, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1364 - val_loss: 0.2197\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.21750\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 00273: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026496846, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1364 - val_loss: 0.2160\n",
      "\n",
      "Epoch 00273: val_loss improved from 0.21750 to 0.21602, saving model to folds8.hdf5\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 00274: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026367782, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1360 - val_loss: 0.2177\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.21602\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 00275: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026239344, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1367 - val_loss: 0.2172\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.21602\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 00276: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026111532, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1351 - val_loss: 0.2173\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.21602\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 00277: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025984345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1351 - val_loss: 0.2182\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.21602\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 00278: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025857775, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1352 - val_loss: 0.2184\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.21602\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 00279: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002573182, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1352 - val_loss: 0.2168\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.21602\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 00280: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025606484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1351 - val_loss: 0.2179\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.21602\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 00281: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025481754, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1357 - val_loss: 0.2177\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.21602\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 00282: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025357632, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1350 - val_loss: 0.2193\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.21602\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 00283: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025234115, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1340 - val_loss: 0.2166\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.21602\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 00284: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025111204, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1338 - val_loss: 0.2175\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.21602\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 00285: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024988884, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1333 - val_loss: 0.2188\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.21602\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 00286: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024867163, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1344 - val_loss: 0.2175\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.21602\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 00287: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024746038, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1331 - val_loss: 0.2172\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.21602\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 00288: LearningRateScheduler reducing learning rate to tf.Tensor(0.000246255, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1335 - val_loss: 0.2157\n",
      "\n",
      "Epoch 00288: val_loss improved from 0.21602 to 0.21573, saving model to folds8.hdf5\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 00289: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024505547, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1331 - val_loss: 0.2168\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.21573\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 00290: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024386184, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1340 - val_loss: 0.2177\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.21573\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 00291: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024267398, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1330 - val_loss: 0.2165\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.21573\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 00292: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024149191, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1319 - val_loss: 0.2192\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.21573\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 00293: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024031562, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1344 - val_loss: 0.2181\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.21573\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 00294: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023914504, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1333 - val_loss: 0.2179\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.21573\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 00295: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023798017, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1327 - val_loss: 0.2165\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.21573\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 00296: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023682097, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1329 - val_loss: 0.2168\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.21573\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 00297: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023566742, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1313 - val_loss: 0.2177\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.21573\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 00298: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023451951, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1326 - val_loss: 0.2179\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.21573\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 00299: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023337714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1331 - val_loss: 0.2161\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.21573\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 00300: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023224037, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1319 - val_loss: 0.2170\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.21573\n",
      "(50300, 80)\n",
      "--------------- > Fold 10 < ---------------\n",
      "CNN: (None, 72, 256)\n",
      "LSTM: (None, 80, 256)\n",
      "Com: (None, 152, 256)\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 28s 209ms/step - loss: 3.9076 - val_loss: 0.8156\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.81559, saving model to folds9.hdf5\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.7892 - val_loss: 0.7168\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.81559 to 0.71682, saving model to folds9.hdf5\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.6167 - val_loss: 0.5561\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.71682 to 0.55606, saving model to folds9.hdf5\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.5416 - val_loss: 0.5102\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.55606 to 0.51020, saving model to folds9.hdf5\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.5102 - val_loss: 0.4972\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.51020 to 0.49716, saving model to folds9.hdf5\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4814 - val_loss: 0.4667\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.49716 to 0.46669, saving model to folds9.hdf5\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4676 - val_loss: 0.4428\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.46669 to 0.44278, saving model to folds9.hdf5\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.4372 - val_loss: 0.4427\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.44278 to 0.44270, saving model to folds9.hdf5\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4531 - val_loss: 0.4558\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.44270\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4281 - val_loss: 0.4447\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.44270\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4075 - val_loss: 0.4988\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.44270\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.4149 - val_loss: 0.4024\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.44270 to 0.40241, saving model to folds9.hdf5\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3988 - val_loss: 0.3993\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.40241 to 0.39935, saving model to folds9.hdf5\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3779 - val_loss: 0.4172\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.39935\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3887 - val_loss: 0.4122\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.39935\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3773 - val_loss: 0.3722\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.39935 to 0.37219, saving model to folds9.hdf5\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3661 - val_loss: 0.3667\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.37219 to 0.36672, saving model to folds9.hdf5\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3691 - val_loss: 0.3763\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.36672\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3672 - val_loss: 0.3548\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.36672 to 0.35476, saving model to folds9.hdf5\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3609 - val_loss: 0.3822\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.35476\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3513 - val_loss: 0.3444\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.35476 to 0.34442, saving model to folds9.hdf5\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3437 - val_loss: 0.3636\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.34442\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3403 - val_loss: 0.3737\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.34442\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3421 - val_loss: 0.3441\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.34442 to 0.34412, saving model to folds9.hdf5\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3352 - val_loss: 0.3609\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.34412\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3290 - val_loss: 0.3667\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.34412\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3269 - val_loss: 0.3793\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.34412\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3367 - val_loss: 0.3243\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.34412 to 0.32425, saving model to folds9.hdf5\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3205 - val_loss: 0.3572\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.32425\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3244 - val_loss: 0.3279\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.32425\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3367 - val_loss: 0.3467\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.32425\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3153 - val_loss: 0.3404\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.32425\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3063 - val_loss: 0.3261\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.32425\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3068 - val_loss: 0.3223\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.32425 to 0.32234, saving model to folds9.hdf5\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3022 - val_loss: 0.3256\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.32234\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3034 - val_loss: 0.3245\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.32234\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.3047 - val_loss: 0.3224\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.32234\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3058 - val_loss: 0.3672\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.32234\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.3058 - val_loss: 0.3211\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.32234 to 0.32114, saving model to folds9.hdf5\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2904 - val_loss: 0.3056\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.32114 to 0.30559, saving model to folds9.hdf5\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2835 - val_loss: 0.3104\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.30559\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.2986 - val_loss: 0.3138\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.30559\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2928 - val_loss: 0.2987\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.30559 to 0.29865, saving model to folds9.hdf5\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2875 - val_loss: 0.2999\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.29865\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2814 - val_loss: 0.3258\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.29865\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2815 - val_loss: 0.3362\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.29865\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2919 - val_loss: 0.3079\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.29865\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2762 - val_loss: 0.2972\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.29865 to 0.29721, saving model to folds9.hdf5\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2787 - val_loss: 0.2963\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.29721 to 0.29634, saving model to folds9.hdf5\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2728 - val_loss: 0.2996\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.29634\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2758 - val_loss: 0.2866\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.29634 to 0.28659, saving model to folds9.hdf5\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2696 - val_loss: 0.2885\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.28659\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2681 - val_loss: 0.2889\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.28659\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2701 - val_loss: 0.3036\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.28659\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2755 - val_loss: 0.2826\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.28659 to 0.28261, saving model to folds9.hdf5\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2602 - val_loss: 0.2855\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.28261\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2669 - val_loss: 0.2840\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.28261\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2684 - val_loss: 0.2865\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.28261\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2569 - val_loss: 0.2977\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.28261\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2594 - val_loss: 0.2831\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.28261\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2666 - val_loss: 0.2806\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.28261 to 0.28065, saving model to folds9.hdf5\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2552 - val_loss: 0.2819\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.28065\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007387921, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2530 - val_loss: 0.2960\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.28065\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to tf.Tensor(0.00073519343, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2678 - val_loss: 0.2792\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.28065 to 0.27924, saving model to folds9.hdf5\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007316123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2509 - val_loss: 0.2779\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.27924 to 0.27792, saving model to folds9.hdf5\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007280487, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2501 - val_loss: 0.2940\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.27792\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007245024, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2544 - val_loss: 0.2752\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.27792 to 0.27525, saving model to folds9.hdf5\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007209733, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2477 - val_loss: 0.2985\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.27525\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071746146, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2504 - val_loss: 0.2719\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.27525 to 0.27191, saving model to folds9.hdf5\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007139667, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2424 - val_loss: 0.2708\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.27191 to 0.27085, saving model to folds9.hdf5\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071048894, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2426 - val_loss: 0.2724\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.27085\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007070282, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2396 - val_loss: 0.2749\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.27085\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007035842, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2433 - val_loss: 0.2684\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.27085 to 0.26841, saving model to folds9.hdf5\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to tf.Tensor(0.00070015714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2396 - val_loss: 0.2696\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.26841\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006967467, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2384 - val_loss: 0.2702\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.26841\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to tf.Tensor(0.00069335283, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2419 - val_loss: 0.2762\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.26841\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006899755, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2348 - val_loss: 0.2613\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.26841 to 0.26130, saving model to folds9.hdf5\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068661466, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2319 - val_loss: 0.3004\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.26130\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068327016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2439 - val_loss: 0.2656\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.26130\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067994196, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2323 - val_loss: 0.2627\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.26130\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067663, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2294 - val_loss: 0.2625\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.26130\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006733342, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2324 - val_loss: 0.2685\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.26130\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067005435, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2296 - val_loss: 0.2612\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.26130 to 0.26123, saving model to folds9.hdf5\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006667905, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2288 - val_loss: 0.2672\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.26123\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006635426, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2295 - val_loss: 0.2700\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.26123\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006603105, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 4s 53ms/step - loss: 0.2295 - val_loss: 0.2569\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.26123 to 0.25693, saving model to folds9.hdf5\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006570942, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2247 - val_loss: 0.2640\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.25693\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065389345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2305 - val_loss: 0.2687\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.25693\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065070833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2262 - val_loss: 0.2628\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.25693\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to tf.Tensor(0.00064753875, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2205 - val_loss: 0.2797\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.25693\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006443846, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2259 - val_loss: 0.2548\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.25693 to 0.25481, saving model to folds9.hdf5\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006412458, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2196 - val_loss: 0.2609\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.25481\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063812226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2203 - val_loss: 0.2658\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.25481\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063501403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2191 - val_loss: 0.2538\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.25481 to 0.25381, saving model to folds9.hdf5\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006319209, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2156 - val_loss: 0.2648\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.25381\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006288428, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2187 - val_loss: 0.2548\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.25381\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to tf.Tensor(0.00062577974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2141 - val_loss: 0.2683\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.25381\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006227316, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2247 - val_loss: 0.2638\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.25381\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061969826, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2242 - val_loss: 0.2531\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.25381 to 0.25314, saving model to folds9.hdf5\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 00100: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006166797, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2121 - val_loss: 0.2515\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.25314 to 0.25153, saving model to folds9.hdf5\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 00101: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061367586, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.2150 - val_loss: 0.2675\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.25153\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 00102: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061068666, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2151 - val_loss: 0.2486\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.25153 to 0.24855, saving model to folds9.hdf5\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 00103: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006077121, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2080 - val_loss: 0.2538\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.24855\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 00104: LearningRateScheduler reducing learning rate to tf.Tensor(0.00060475187, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2087 - val_loss: 0.2478\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.24855 to 0.24780, saving model to folds9.hdf5\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 00105: LearningRateScheduler reducing learning rate to tf.Tensor(0.00060180615, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2070 - val_loss: 0.2627\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.24780\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 00106: LearningRateScheduler reducing learning rate to tf.Tensor(0.00059887476, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2108 - val_loss: 0.2592\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.24780\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 00107: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005959577, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2098 - val_loss: 0.2501\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.24780\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 00108: LearningRateScheduler reducing learning rate to tf.Tensor(0.00059305475, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2036 - val_loss: 0.2479\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.24780\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 00109: LearningRateScheduler reducing learning rate to tf.Tensor(0.000590166, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2035 - val_loss: 0.2457\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.24780 to 0.24574, saving model to folds9.hdf5\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 00110: LearningRateScheduler reducing learning rate to tf.Tensor(0.00058729126, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2066 - val_loss: 0.2503\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.24574\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 00111: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005844306, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2075 - val_loss: 0.2557\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.24574\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 00112: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005815838, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2047 - val_loss: 0.2492\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.24574\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 00113: LearningRateScheduler reducing learning rate to tf.Tensor(0.000578751, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2033 - val_loss: 0.2595\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.24574\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 00114: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057593186, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2110 - val_loss: 0.2449\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.24574 to 0.24486, saving model to folds9.hdf5\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 00115: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057312654, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1987 - val_loss: 0.2546\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.24486\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 00116: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057033484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2060 - val_loss: 0.2517\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.24486\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 00117: LearningRateScheduler reducing learning rate to tf.Tensor(0.00056755677, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 52ms/step - loss: 0.2037 - val_loss: 0.2640\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.24486\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 00118: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005647922, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.2023 - val_loss: 0.2453\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.24486\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 00119: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005620411, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2002 - val_loss: 0.2425\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.24486 to 0.24255, saving model to folds9.hdf5\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 00120: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055930344, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1980 - val_loss: 0.2411\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.24255 to 0.24108, saving model to folds9.hdf5\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 00121: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055657903, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1952 - val_loss: 0.2432\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.24108\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 00122: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055386795, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1947 - val_loss: 0.2431\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.24108\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 00123: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005511701, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1943 - val_loss: 0.2462\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.24108\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 00124: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005484854, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1930 - val_loss: 0.2439\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.24108\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 00125: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005458137, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.2051 - val_loss: 0.2470\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.24108\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 00126: LearningRateScheduler reducing learning rate to tf.Tensor(0.00054315507, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1965 - val_loss: 0.2382\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.24108 to 0.23819, saving model to folds9.hdf5\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 00127: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005405093, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1878 - val_loss: 0.2385\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.23819\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 00128: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005378765, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1892 - val_loss: 0.2411\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.23819\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 00129: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005352565, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1900 - val_loss: 0.2433\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.23819\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 00130: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005326493, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1903 - val_loss: 0.2397\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.23819\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 00131: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005300548, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1888 - val_loss: 0.2459\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.23819\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 00132: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005274729, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1905 - val_loss: 0.2401\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.23819\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 00133: LearningRateScheduler reducing learning rate to tf.Tensor(0.00052490365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1937 - val_loss: 0.2399\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.23819\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 00134: LearningRateScheduler reducing learning rate to tf.Tensor(0.00052234676, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1858 - val_loss: 0.2364\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.23819 to 0.23642, saving model to folds9.hdf5\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 00135: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005198025, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1891 - val_loss: 0.2384\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.23642\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 00136: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005172705, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1869 - val_loss: 0.2387\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.23642\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 00137: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051475083, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1834 - val_loss: 0.2342\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.23642 to 0.23422, saving model to folds9.hdf5\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 00138: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051224354, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1831 - val_loss: 0.2366\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.23422\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 00139: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005097484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1812 - val_loss: 0.2376\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.23422\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 00140: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005072654, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1839 - val_loss: 0.2365\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.23422\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 00141: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005047946, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1831 - val_loss: 0.2342\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.23422 to 0.23419, saving model to folds9.hdf5\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 00142: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005023357, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1857 - val_loss: 0.2375\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.23419\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 00143: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049988885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1845 - val_loss: 0.2396\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.23419\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 00144: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004974539, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1831 - val_loss: 0.2345\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.23419\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 00145: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004950308, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1798 - val_loss: 0.2363\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.23419\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 00146: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004926195, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1837 - val_loss: 0.2442\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.23419\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 00147: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049022, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1810 - val_loss: 0.2378\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.23419\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 00148: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048783212, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1775 - val_loss: 0.2447\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.23419\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 00149: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048545588, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1828 - val_loss: 0.2358\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.23419\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 00150: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048309125, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1777 - val_loss: 0.2381\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.23419\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 00151: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048073815, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 52ms/step - loss: 0.1793 - val_loss: 0.2363\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.23419\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 00152: LearningRateScheduler reducing learning rate to tf.Tensor(0.00047839645, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1817 - val_loss: 0.2381\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.23419\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 00153: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004760662, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1765 - val_loss: 0.2346\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.23419\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 00154: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004737473, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1791 - val_loss: 0.2326\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.23419 to 0.23259, saving model to folds9.hdf5\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 00155: LearningRateScheduler reducing learning rate to tf.Tensor(0.00047143968, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1758 - val_loss: 0.2376\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.23259\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 00156: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004691433, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1821 - val_loss: 0.2328\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.23259\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 00157: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046685815, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1752 - val_loss: 0.2345\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.23259\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 00158: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046458407, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1750 - val_loss: 0.2346\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.23259\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 00159: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046232107, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1734 - val_loss: 0.2327\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.23259\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 00160: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046006907, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1721 - val_loss: 0.2326\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.23259 to 0.23257, saving model to folds9.hdf5\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 00161: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045782814, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1754 - val_loss: 0.2333\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.23257\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 00162: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045559806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1736 - val_loss: 0.2324\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.23257 to 0.23242, saving model to folds9.hdf5\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 00163: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045337883, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1724 - val_loss: 0.2341\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.23242\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 00164: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045117046, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1750 - val_loss: 0.2309\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.23242 to 0.23093, saving model to folds9.hdf5\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 00165: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044897277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1701 - val_loss: 0.2307\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.23093 to 0.23071, saving model to folds9.hdf5\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 00166: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044678585, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1677 - val_loss: 0.2317\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.23071\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 00167: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004446096, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1684 - val_loss: 0.2373\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.23071\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 00168: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004424439, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1705 - val_loss: 0.2307\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.23071 to 0.23065, saving model to folds9.hdf5\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 00169: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044028874, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1679 - val_loss: 0.2302\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.23065 to 0.23025, saving model to folds9.hdf5\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 00170: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043814414, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1666 - val_loss: 0.2330\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.23025\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 00171: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043600993, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1696 - val_loss: 0.2324\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.23025\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 00172: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043388613, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1711 - val_loss: 0.2311\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.23025\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 00173: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004317727, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1689 - val_loss: 0.2291\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.23025 to 0.22912, saving model to folds9.hdf5\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 00174: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004296695, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1670 - val_loss: 0.2279\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.22912 to 0.22794, saving model to folds9.hdf5\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 00175: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004275766, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1659 - val_loss: 0.2304\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.22794\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 00176: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042549393, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1683 - val_loss: 0.2349\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.22794\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 00177: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042342133, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1679 - val_loss: 0.2290\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.22794\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 00178: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042135885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1650 - val_loss: 0.2304\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.22794\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 00179: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041930642, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1670 - val_loss: 0.2304\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.22794\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 00180: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041726397, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1636 - val_loss: 0.2283\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.22794\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 00181: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041523148, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1641 - val_loss: 0.2381\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.22794\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 00182: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041320888, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1670 - val_loss: 0.2275\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.22794 to 0.22746, saving model to folds9.hdf5\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 00183: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041119618, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1629 - val_loss: 0.2292\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.22746\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 00184: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040919325, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 47ms/step - loss: 0.1660 - val_loss: 0.2266\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.22746 to 0.22659, saving model to folds9.hdf5\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 00185: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040720004, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 52ms/step - loss: 0.1651 - val_loss: 0.2294\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.22659\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 00186: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004052166, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1628 - val_loss: 0.2248\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.22659 to 0.22482, saving model to folds9.hdf5\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 00187: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004032428, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1605 - val_loss: 0.2276\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.22482\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 00188: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004012786, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1606 - val_loss: 0.2264\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.22482\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 00189: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039932402, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1608 - val_loss: 0.2292\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.22482\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 00190: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039737887, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1629 - val_loss: 0.2286\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.22482\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 00191: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039544326, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1599 - val_loss: 0.2268\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.22482\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 00192: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039351705, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1589 - val_loss: 0.2262\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.22482\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 00193: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039160028, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1584 - val_loss: 0.2275\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.22482\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 00194: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038969278, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1588 - val_loss: 0.2266\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.22482\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 00195: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003877946, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1600 - val_loss: 0.2295\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.22482\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 00196: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038590565, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1605 - val_loss: 0.2270\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.22482\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 00197: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003840259, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1584 - val_loss: 0.2245\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.22482 to 0.22455, saving model to folds9.hdf5\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 00198: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038215535, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1570 - val_loss: 0.2268\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.22455\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 00199: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038029387, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1563 - val_loss: 0.2257\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.22455\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 00200: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037844144, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1561 - val_loss: 0.2260\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.22455\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 00201: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037659804, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1563 - val_loss: 0.2279\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.22455\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 00202: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037476368, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1568 - val_loss: 0.2283\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.22455\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 00203: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037293817, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1574 - val_loss: 0.2251\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.22455\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 00204: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003711216, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1559 - val_loss: 0.2251\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.22455\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 00205: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003693139, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1550 - val_loss: 0.2260\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.22455\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 00206: LearningRateScheduler reducing learning rate to tf.Tensor(0.000367515, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1582 - val_loss: 0.2259\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.22455\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 00207: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036572482, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1553 - val_loss: 0.2275\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.22455\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 00208: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003639434, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1543 - val_loss: 0.2283\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.22455\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 00209: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036217063, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1536 - val_loss: 0.2235\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.22455 to 0.22350, saving model to folds9.hdf5\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 00210: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036040647, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1529 - val_loss: 0.2263\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.22350\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 00211: LearningRateScheduler reducing learning rate to tf.Tensor(0.00035865093, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1535 - val_loss: 0.2244\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.22350\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 00212: LearningRateScheduler reducing learning rate to tf.Tensor(0.000356904, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 52ms/step - loss: 0.1543 - val_loss: 0.2264\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.22350\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 00213: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003551655, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1535 - val_loss: 0.2244\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.22350\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 00214: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003534355, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1523 - val_loss: 0.2265\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.22350\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 00215: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003517139, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1538 - val_loss: 0.2252\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.22350\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 00216: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003500007, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1512 - val_loss: 0.2285\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.22350\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 00217: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034829587, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1565 - val_loss: 0.2250\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.22350\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 00218: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034659932, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1533 - val_loss: 0.2256\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.22350\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 00219: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034491107, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1508 - val_loss: 0.2237\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.22350\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 00220: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034323102, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1495 - val_loss: 0.2238\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.22350\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 00221: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034155912, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1510 - val_loss: 0.2228\n",
      "\n",
      "Epoch 00221: val_loss improved from 0.22350 to 0.22284, saving model to folds9.hdf5\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 00222: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033989537, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1493 - val_loss: 0.2243\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.22284\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 00223: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033823974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1501 - val_loss: 0.2248\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.22284\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 00224: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003365922, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1510 - val_loss: 0.2253\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.22284\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 00225: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033495267, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1497 - val_loss: 0.2258\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.22284\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 00226: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003333211, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1508 - val_loss: 0.2228\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.22284 to 0.22281, saving model to folds9.hdf5\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 00227: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033169755, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1474 - val_loss: 0.2235\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.22281\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 00228: LearningRateScheduler reducing learning rate to tf.Tensor(0.00033008185, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1482 - val_loss: 0.2233\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.22281\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 00229: LearningRateScheduler reducing learning rate to tf.Tensor(0.000328474, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1502 - val_loss: 0.2266\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.22281\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 00230: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032687403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1509 - val_loss: 0.2255\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.22281\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 00231: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003252818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1489 - val_loss: 0.2225\n",
      "\n",
      "Epoch 00231: val_loss improved from 0.22281 to 0.22247, saving model to folds9.hdf5\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 00232: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032369737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1464 - val_loss: 0.2242\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.22247\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 00233: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032212064, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1461 - val_loss: 0.2252\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.22247\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 00234: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032055163, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1467 - val_loss: 0.2234\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.22247\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 00235: LearningRateScheduler reducing learning rate to tf.Tensor(0.00031899018, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1476 - val_loss: 0.2216\n",
      "\n",
      "Epoch 00235: val_loss improved from 0.22247 to 0.22164, saving model to folds9.hdf5\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 00236: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003174364, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1460 - val_loss: 0.2288\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.22164\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 00237: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003158902, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1484 - val_loss: 0.2236\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.22164\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 00238: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003143515, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1459 - val_loss: 0.2211\n",
      "\n",
      "Epoch 00238: val_loss improved from 0.22164 to 0.22113, saving model to folds9.hdf5\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 00239: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003128203, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1436 - val_loss: 0.2233\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.22113\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 00240: LearningRateScheduler reducing learning rate to tf.Tensor(0.00031129655, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1441 - val_loss: 0.2234\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.22113\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 00241: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003097802, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1464 - val_loss: 0.2238\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.22113\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 00242: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003082713, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1439 - val_loss: 0.2229\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.22113\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 00243: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003067697, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1440 - val_loss: 0.2221\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.22113\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 00244: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030527546, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1442 - val_loss: 0.2221\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.22113\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 00245: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030378843, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1441 - val_loss: 0.2232\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.22113\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 00246: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003023087, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1433 - val_loss: 0.2246\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.22113\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 00247: LearningRateScheduler reducing learning rate to tf.Tensor(0.00030083617, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1469 - val_loss: 0.2227\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.22113\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 00248: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002993708, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 45ms/step - loss: 0.1437 - val_loss: 0.2235\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.22113\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 00249: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029791257, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1437 - val_loss: 0.2232\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.22113\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 00250: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029646145, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1448 - val_loss: 0.2234\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.22113\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 00251: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029501738, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1420 - val_loss: 0.2244\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.22113\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 00252: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029358038, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1426 - val_loss: 0.2220\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.22113\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 00253: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029215033, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1448 - val_loss: 0.2218\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.22113\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 00254: LearningRateScheduler reducing learning rate to tf.Tensor(0.00029072727, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1417 - val_loss: 0.2248\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.22113\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 00255: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028931117, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1431 - val_loss: 0.2227\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.22113\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 00256: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028790193, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1410 - val_loss: 0.2207\n",
      "\n",
      "Epoch 00256: val_loss improved from 0.22113 to 0.22068, saving model to folds9.hdf5\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 00257: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028649953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1404 - val_loss: 0.2231\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.22068\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 00258: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028510403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1412 - val_loss: 0.2233\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.22068\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 00259: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002837153, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1413 - val_loss: 0.2230\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.22068\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 00260: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002823333, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1406 - val_loss: 0.2222\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.22068\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 00261: LearningRateScheduler reducing learning rate to tf.Tensor(0.00028095808, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1395 - val_loss: 0.2218\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.22068\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 00262: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027958953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1394 - val_loss: 0.2243\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.22068\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 00263: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027822764, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1392 - val_loss: 0.2219\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.22068\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 00264: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027687242, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 0.1397 - val_loss: 0.2212\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.22068\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 00265: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027552375, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1387 - val_loss: 0.2220\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.22068\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 00266: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002741817, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1395 - val_loss: 0.2226\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.22068\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 00267: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027284614, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1402 - val_loss: 0.2220\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.22068\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 00268: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027151714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1386 - val_loss: 0.2214\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.22068\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 00269: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027019458, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1384 - val_loss: 0.2235\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.22068\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 00270: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026887844, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 0.1390 - val_loss: 0.2239\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.22068\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 00271: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026756877, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1391 - val_loss: 0.2229\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.22068\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 00272: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026626544, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1384 - val_loss: 0.2245\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.22068\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 00273: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026496846, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1382 - val_loss: 0.2212\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.22068\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 00274: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026367782, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1376 - val_loss: 0.2219\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.22068\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 00275: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026239344, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1367 - val_loss: 0.2222\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.22068\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 00276: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026111532, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1374 - val_loss: 0.2220\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.22068\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 00277: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025984345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1375 - val_loss: 0.2209\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.22068\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 00278: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025857775, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1373 - val_loss: 0.2212\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.22068\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 00279: LearningRateScheduler reducing learning rate to tf.Tensor(0.0002573182, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1375 - val_loss: 0.2214\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.22068\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 00280: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025606484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1358 - val_loss: 0.2223\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.22068\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 00281: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025481754, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1357 - val_loss: 0.2209\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.22068\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 00282: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025357632, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1350 - val_loss: 0.2218\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.22068\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 00283: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025234115, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1356 - val_loss: 0.2205\n",
      "\n",
      "Epoch 00283: val_loss improved from 0.22068 to 0.22047, saving model to folds9.hdf5\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 00284: LearningRateScheduler reducing learning rate to tf.Tensor(0.00025111204, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1358 - val_loss: 0.2212\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.22047\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 00285: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024988884, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1349 - val_loss: 0.2210\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.22047\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 00286: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024867163, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1360 - val_loss: 0.2211\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.22047\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 00287: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024746038, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1344 - val_loss: 0.2213\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.22047\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 00288: LearningRateScheduler reducing learning rate to tf.Tensor(0.000246255, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1347 - val_loss: 0.2206\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.22047\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 00289: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024505547, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1334 - val_loss: 0.2196\n",
      "\n",
      "Epoch 00289: val_loss improved from 0.22047 to 0.21964, saving model to folds9.hdf5\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 00290: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024386184, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1342 - val_loss: 0.2205\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.21964\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 00291: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024267398, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1337 - val_loss: 0.2216\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.21964\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 00292: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024149191, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1331 - val_loss: 0.2218\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.21964\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 00293: LearningRateScheduler reducing learning rate to tf.Tensor(0.00024031562, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1340 - val_loss: 0.2228\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.21964\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 00294: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023914504, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1346 - val_loss: 0.2202\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.21964\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 00295: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023798017, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1339 - val_loss: 0.2210\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.21964\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 00296: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023682097, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 4s 52ms/step - loss: 0.1344 - val_loss: 0.2202\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.21964\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 00297: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023566742, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1331 - val_loss: 0.2209\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.21964\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 00298: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023451951, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1339 - val_loss: 0.2224\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.21964\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 00299: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023337714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.1321 - val_loss: 0.2215\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.21964\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 00300: LearningRateScheduler reducing learning rate to tf.Tensor(0.00023224037, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 0.1324 - val_loss: 0.2224\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.21964\n",
      "(50300, 80)\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 300\n",
    "BATCH_SIZE = 1024\n",
    "NUM_FOLDS = 10\n",
    "\n",
    "\n",
    "# detect and init the TPU\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "\n",
    "# instantiate a distribution strategy\n",
    "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "#GPU init\n",
    "#gpu_strategy = tf.distribute.get_strategy()\n",
    "\n",
    "#with gpu_strategy.scope():\n",
    "with tpu_strategy.scope():\n",
    "    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=2021)\n",
    "    test_preds = []\n",
    "    \n",
    "    def BiLSTM_model():\n",
    "        inputs = keras.layers.Input(shape=train.shape[-2:])\n",
    "        \n",
    "        x_CNN = inputs\n",
    "        x_LSTM = inputs\n",
    "\n",
    "        #CNN: 1024->512->256  \n",
    "        x_CNN = keras.layers.Conv1D(filters=1024, kernel_size=3, activation='relu')(x_CNN)\n",
    "        x_CNN = keras.layers.MaxPooling1D(pool_size=2,strides=1, padding='valid')(x_CNN)\n",
    "        \n",
    "        x_CNN = keras.layers.Conv1D(filters=512, kernel_size=3, activation='relu')(x_CNN)\n",
    "        x_CNN = keras.layers.MaxPooling1D(pool_size=2,strides=1, padding='valid')(x_CNN)\n",
    "    \n",
    "        x_CNN = keras.layers.Conv1D(filters=256, kernel_size=3, activation='relu')(x_CNN)\n",
    "        # x_CNN = keras.layers.MaxPooling1D(pool_size=2,strides=1, padding='valid')(x_CNN)\n",
    "\n",
    "        # x_CNN = keras.layers.Conv1D(filters=128, kernel_size=3, activation='relu')(x_CNN)\n",
    "        print('CNN:',x_CNN.shape)\n",
    "\n",
    "\n",
    "        #Bidirectional LSTM: 128\n",
    "        x_LSTM = keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True))(x_LSTM)\n",
    "        x_LSTM = keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True))(x_LSTM)\n",
    "        print('LSTM:',x_LSTM.shape)\n",
    "\n",
    "        x_Com = tf.keras.layers.concatenate([x_CNN,x_LSTM],axis=1)\n",
    "        print('Com:',x_Com.shape)\n",
    "\n",
    "        x_Com = keras.layers.Dense(128, activation='selu')(x_Com)\n",
    "        # keras.layers.Dropout(0.1)\n",
    "        #keep the output same\n",
    "        outputs = keras.layers.Flatten()(x_Com)\n",
    "        outputs = keras.layers.Dense(80)(outputs)\n",
    "        outputs = ScaleLayer()(outputs)\n",
    "        \n",
    "        model  = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(optimizer=\"adam\", loss=\"mae\")\n",
    "        return model\n",
    "        \n",
    "        \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n",
    "        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n",
    "        X_train, X_valid = train[train_idx], train[test_idx]\n",
    "        y_train, y_valid = targets[train_idx], targets[test_idx]\n",
    "\n",
    "        model = BiLSTM_model()\n",
    "        \n",
    "        scheduler = ExponentialDecay(1e-3, 40*((len(train)*0.8)/BATCH_SIZE), 1e-5)\n",
    "        lr = LearningRateScheduler(scheduler, verbose=1)\n",
    "        \n",
    "        #lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1)\n",
    "        #lr = WarmupExponentialDecay(lr_base=1e-3, decay=1e-5, warmup_epochs=30)\n",
    "        es = EarlyStopping(monitor=\"val_loss\", patience=60, verbose=1, mode=\"min\", restore_best_weights=True)\n",
    "    \n",
    "        checkpoint_filepath = f\"folds{fold}.hdf5\"\n",
    "        sv = keras.callbacks.ModelCheckpoint(\n",
    "            checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "            save_weights_only=False, mode='auto', save_freq='epoch',\n",
    "            options=None\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr, es, sv])\n",
    "        #model.save(f'Fold{fold+1} RNN Weights')\n",
    "        out = model.predict(test)\n",
    "        print(out.shape)\n",
    "        test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 33.018292,
     "end_time": "2021-10-13T01:35:21.359623",
     "exception": false,
     "start_time": "2021-10-13T01:34:48.341331",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Median method from [Chris Deotte](https://www.kaggle.com/cdeotte/ensemble-folds-with-median-0-153)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T01:36:27.279219Z",
     "iopub.status.busy": "2021-10-13T01:36:27.278529Z",
     "iopub.status.idle": "2021-10-13T01:37:07.057893Z",
     "shell.execute_reply": "2021-10-13T01:37:07.058596Z"
    },
    "papermill": {
     "duration": 72.689039,
     "end_time": "2021-10-13T01:37:07.058803",
     "exception": false,
     "start_time": "2021-10-13T01:35:54.369764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission[\"pressure\"] = sum(test_preds)/NUM_FOLDS\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# ENSEMBLE FOLDS WITH MEDIAN\n",
    "#取中位数\n",
    "submission[\"pressure\"] = np.median(np.vstack(test_preds),axis=0)\n",
    "submission.to_csv('submission_median.csv', index=False)\n",
    "\n",
    "\n",
    "# ENSEMBLE FOLDS WITH MEDIAN AND ROUND PREDICTIONS\n",
    "submission[\"pressure\"] =\\\n",
    "    np.round( (submission.pressure - pressure_min)/pressure_step ) * pressure_step + pressure_min\n",
    "submission.pressure = np.clip(submission.pressure, pressure_min, pressure_max)\n",
    "submission.to_csv('submission_median_round.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10052.861662,
   "end_time": "2021-10-13T01:37:43.526647",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-12T22:50:10.664985",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
