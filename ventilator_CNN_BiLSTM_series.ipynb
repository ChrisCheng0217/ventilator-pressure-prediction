{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b9253d7",
   "metadata": {
    "_cell_guid": "3e5a0bd1-3e22-4b2c-a565-68985e55f95e",
    "_uuid": "e331dbcc-0346-4019-9ff6-b890154a878b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-10-12T19:23:13.599903Z",
     "iopub.status.busy": "2021-10-12T19:23:13.599245Z",
     "iopub.status.idle": "2021-10-12T19:23:21.590410Z",
     "shell.execute_reply": "2021-10-12T19:23:21.589626Z",
     "shell.execute_reply.started": "2021-10-12T16:17:48.817572Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 8.018815,
     "end_time": "2021-10-12T19:23:21.590584",
     "exception": false,
     "start_time": "2021-10-12T19:23:13.571769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import optuna\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.preprocessing import RobustScaler, normalize\n",
    "from sklearn.model_selection import train_test_split, GroupKFold, KFold\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2adb28c9",
   "metadata": {
    "_cell_guid": "89eb257e-0ed2-4f8b-94d6-462a5e995eb1",
    "_uuid": "ca71d87d-6594-4f31-906d-0b53cd4c1374",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-10-12T19:23:21.628571Z",
     "iopub.status.busy": "2021-10-12T19:23:21.627866Z",
     "iopub.status.idle": "2021-10-12T19:23:36.624282Z",
     "shell.execute_reply": "2021-10-12T19:23:36.624827Z",
     "shell.execute_reply.started": "2021-10-12T16:17:56.169862Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 15.017213,
     "end_time": "2021-10-12T19:23:36.625021",
     "exception": false,
     "start_time": "2021-10-12T19:23:21.607808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "train = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\n",
    "test = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\n",
    "submission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n",
    "\n",
    "if DEBUG:\n",
    "    train = train[:80*1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89222693",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T19:23:36.662853Z",
     "iopub.status.busy": "2021-10-12T19:23:36.661689Z",
     "iopub.status.idle": "2021-10-12T19:23:36.744405Z",
     "shell.execute_reply": "2021-10-12T19:23:36.743756Z",
     "shell.execute_reply.started": "2021-10-12T16:18:12.243120Z"
    },
    "papermill": {
     "duration": 0.10254,
     "end_time": "2021-10-12T19:23:36.744580",
     "exception": false,
     "start_time": "2021-10-12T19:23:36.642040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_pressure = np.sort(train['pressure'].unique())\n",
    "pressure_min =  all_pressure[0].item()\n",
    "pressure_max = all_pressure[-1].item()\n",
    "pressure_step = (all_pressure[1] - all_pressure[0]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f77778a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T19:23:36.786582Z",
     "iopub.status.busy": "2021-10-12T19:23:36.785757Z",
     "iopub.status.idle": "2021-10-12T19:23:36.792970Z",
     "shell.execute_reply": "2021-10-12T19:23:36.792256Z",
     "shell.execute_reply.started": "2021-10-12T16:18:12.329206Z"
    },
    "papermill": {
     "duration": 0.031429,
     "end_time": "2021-10-12T19:23:36.793133",
     "exception": false,
     "start_time": "2021-10-12T19:23:36.761704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.895744294564641"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "64.8209917386395"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.07030214545121005"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pressure_min)\n",
    "display(pressure_max)\n",
    "display(pressure_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc595fb6",
   "metadata": {
    "papermill": {
     "duration": 0.017972,
     "end_time": "2021-10-12T19:23:36.829313",
     "exception": false,
     "start_time": "2021-10-12T19:23:36.811341",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Engineer Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944f5dd0",
   "metadata": {
    "papermill": {
     "duration": 0.018239,
     "end_time": "2021-10-12T19:23:36.866687",
     "exception": false,
     "start_time": "2021-10-12T19:23:36.848448",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## From [Ventilator: Feature engineering](https://www.kaggle.com/mistag/ventilator-feature-engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "672d0368",
   "metadata": {
    "_cell_guid": "13a36b46-7067-4b29-aad3-7e3b15e8415b",
    "_uuid": "dc41dbf2-f199-4b9d-bbd9-bf6084162b47",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-10-12T19:23:36.937875Z",
     "iopub.status.busy": "2021-10-12T19:23:36.914539Z",
     "iopub.status.idle": "2021-10-12T19:24:38.671307Z",
     "shell.execute_reply": "2021-10-12T19:24:38.670347Z",
     "shell.execute_reply.started": "2021-10-12T16:18:12.345801Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 61.786691,
     "end_time": "2021-10-12T19:24:38.671501",
     "exception": false,
     "start_time": "2021-10-12T19:23:36.884810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Feature engineering\n",
    "def add_features(df):\n",
    "    #time_step*u_in\n",
    "    df['area'] = df['time_step'] * df['u_in']\n",
    "    df['area'] = df.groupby('breath_id')['area'].cumsum()\n",
    "    \n",
    "    #sum of u_in\n",
    "    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n",
    "    \n",
    "    #shift +1 -1 +3 -3\n",
    "    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n",
    "    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n",
    "    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n",
    "    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n",
    "    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n",
    "    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n",
    "    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n",
    "    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n",
    "    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n",
    "    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n",
    "    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n",
    "    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n",
    "    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n",
    "    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n",
    "    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n",
    "    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n",
    "    df = df.fillna(0)\n",
    "         \n",
    "    df['u_in_first'] = df.groupby(['breath_id'])['u_in'].transform('first')\n",
    "    df['u_in_last'] = df.groupby(['breath_id'])['u_in'].transform('last')\n",
    "    \n",
    "    # max value of u_in and u_out for each breath\n",
    "    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n",
    "    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n",
    "   \n",
    "    # difference between consequitive values\n",
    "    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n",
    "    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n",
    "    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n",
    "    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n",
    "    \n",
    "    df.loc[train['time_step'] == 0, 'u_in_diff'] = 0\n",
    "    df.loc[train['time_step'] == 0, 'u_out_diff'] = 0\n",
    "    \n",
    "    # difference between the current value of u_in and the max value within the breath\n",
    "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
    "    # difference between the current value of u_in and the mean value within the breath\n",
    "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
    "    \n",
    "    # difference between consequitive values\n",
    "    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n",
    "    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n",
    "    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n",
    "    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n",
    "    \n",
    "    #u_in*u_out\n",
    "    df['cross']= df['u_in']*df['u_out']\n",
    "    \n",
    "    #time_step*u_out\n",
    "    df['cross2']= df['time_step']*df['u_out']\n",
    "    \n",
    "    df['R'] = df['R'].astype(str)\n",
    "    df['C'] = df['C'].astype(str)\n",
    "    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n",
    "    #one hot encoding\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "train = add_features(train)\n",
    "test = add_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d6f2d6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T19:24:38.714187Z",
     "iopub.status.busy": "2021-10-12T19:24:38.713222Z",
     "iopub.status.idle": "2021-10-12T19:24:38.717500Z",
     "shell.execute_reply": "2021-10-12T19:24:38.716869Z",
     "shell.execute_reply.started": "2021-10-12T16:19:11.091121Z"
    },
    "papermill": {
     "duration": 0.027269,
     "end_time": "2021-10-12T19:24:38.717641",
     "exception": false,
     "start_time": "2021-10-12T19:24:38.690372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4024000, 56)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ca3dfa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T19:24:38.757847Z",
     "iopub.status.busy": "2021-10-12T19:24:38.757183Z",
     "iopub.status.idle": "2021-10-12T19:24:39.831793Z",
     "shell.execute_reply": "2021-10-12T19:24:39.830924Z",
     "shell.execute_reply.started": "2021-10-12T16:19:11.099047Z"
    },
    "papermill": {
     "duration": 1.096034,
     "end_time": "2021-10-12T19:24:39.831989",
     "exception": false,
     "start_time": "2021-10-12T19:24:38.735955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "check_train_nan = train.isnull().sum().sum()\n",
    "check_test_nan = test.isnull().sum().sum()\n",
    "\n",
    "print(check_train_nan)\n",
    "print(check_test_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a4f1fdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T19:24:39.885714Z",
     "iopub.status.busy": "2021-10-12T19:24:39.884634Z",
     "iopub.status.idle": "2021-10-12T19:24:39.908064Z",
     "shell.execute_reply": "2021-10-12T19:24:39.908605Z",
     "shell.execute_reply.started": "2021-10-12T16:19:12.166133Z"
    },
    "papermill": {
     "duration": 0.055231,
     "end_time": "2021-10-12T19:24:39.908900",
     "exception": false,
     "start_time": "2021-10-12T19:24:39.853669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "      <th>pressure</th>\n",
       "      <th>area</th>\n",
       "      <th>u_in_cumsum</th>\n",
       "      <th>u_in_lag1</th>\n",
       "      <th>u_out_lag1</th>\n",
       "      <th>...</th>\n",
       "      <th>C_50</th>\n",
       "      <th>R__C_20__10</th>\n",
       "      <th>R__C_20__20</th>\n",
       "      <th>R__C_20__50</th>\n",
       "      <th>R__C_50__10</th>\n",
       "      <th>R__C_50__20</th>\n",
       "      <th>R__C_50__50</th>\n",
       "      <th>R__C_5__10</th>\n",
       "      <th>R__C_5__20</th>\n",
       "      <th>R__C_5__50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0</td>\n",
       "      <td>5.837492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033652</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0</td>\n",
       "      <td>5.907794</td>\n",
       "      <td>0.618632</td>\n",
       "      <td>18.466375</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067514</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>0</td>\n",
       "      <td>7.876254</td>\n",
       "      <td>2.138333</td>\n",
       "      <td>40.975653</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  breath_id  time_step       u_in  u_out  pressure      area  \\\n",
       "0   1          1   0.000000   0.083334      0  5.837492  0.000000   \n",
       "1   2          1   0.033652  18.383041      0  5.907794  0.618632   \n",
       "2   3          1   0.067514  22.509278      0  7.876254  2.138333   \n",
       "\n",
       "   u_in_cumsum  u_in_lag1  u_out_lag1  ...  C_50  R__C_20__10  R__C_20__20  \\\n",
       "0     0.083334   0.000000         0.0  ...     1            0            0   \n",
       "1    18.466375   0.083334         0.0  ...     1            0            0   \n",
       "2    40.975653  18.383041         0.0  ...     1            0            0   \n",
       "\n",
       "   R__C_20__50  R__C_50__10  R__C_50__20  R__C_50__50  R__C_5__10  R__C_5__20  \\\n",
       "0            1            0            0            0           0           0   \n",
       "1            1            0            0            0           0           0   \n",
       "2            1            0            0            0           0           0   \n",
       "\n",
       "   R__C_5__50  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "\n",
       "[3 rows x 57 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91f5e8c6",
   "metadata": {
    "_cell_guid": "01328860-fa2a-421c-9e5f-ea0048246f98",
    "_uuid": "346bf2c0-96d2-4da5-8837-c0f820294a85",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-10-12T19:24:41.037769Z",
     "iopub.status.busy": "2021-10-12T19:24:41.036344Z",
     "iopub.status.idle": "2021-10-12T19:24:41.595987Z",
     "shell.execute_reply": "2021-10-12T19:24:41.595237Z",
     "shell.execute_reply.started": "2021-10-12T16:19:12.195744Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.66713,
     "end_time": "2021-10-12T19:24:41.596161",
     "exception": false,
     "start_time": "2021-10-12T19:24:39.929031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = train[['pressure']].to_numpy().reshape(-1, 80)\n",
    "train.drop(['pressure', 'id', 'breath_id'], axis=1, inplace=True)\n",
    "test = test.drop(['id', 'breath_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a34f761d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T19:24:41.645434Z",
     "iopub.status.busy": "2021-10-12T19:24:41.644700Z",
     "iopub.status.idle": "2021-10-12T19:24:52.848008Z",
     "shell.execute_reply": "2021-10-12T19:24:52.847442Z",
     "shell.execute_reply.started": "2021-10-12T16:19:13.509897Z"
    },
    "papermill": {
     "duration": 11.230459,
     "end_time": "2021-10-12T19:24:52.848184",
     "exception": false,
     "start_time": "2021-10-12T19:24:41.617725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Normalise the dataset\n",
    "RS = RobustScaler()\n",
    "train = RS.fit_transform(train)\n",
    "test = RS.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5625f586",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T19:24:52.890163Z",
     "iopub.status.busy": "2021-10-12T19:24:52.889507Z",
     "iopub.status.idle": "2021-10-12T19:24:52.894379Z",
     "shell.execute_reply": "2021-10-12T19:24:52.893774Z",
     "shell.execute_reply.started": "2021-10-12T16:19:24.266882Z"
    },
    "papermill": {
     "duration": 0.027109,
     "end_time": "2021-10-12T19:24:52.894527",
     "exception": false,
     "start_time": "2021-10-12T19:24:52.867418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Reshape group to 80 timesteps for each breath ID\n",
    "train = train.reshape(-1, 80, train.shape[-1])\n",
    "test = test.reshape(-1, 80, train.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e5945e",
   "metadata": {
    "papermill": {
     "duration": 0.01882,
     "end_time": "2021-10-12T19:24:52.933542",
     "exception": false,
     "start_time": "2021-10-12T19:24:52.914722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba47db1",
   "metadata": {
    "papermill": {
     "duration": 0.019032,
     "end_time": "2021-10-12T19:24:52.971591",
     "exception": false,
     "start_time": "2021-10-12T19:24:52.952559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## From [Rescaling layer for discrete output in TensorFlow](https://www.kaggle.com/lucamassaron/rescaling-layer-for-discrete-output-in-tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccb2dd9",
   "metadata": {
    "papermill": {
     "duration": 0.020519,
     "end_time": "2021-10-12T19:24:53.011533",
     "exception": false,
     "start_time": "2021-10-12T19:24:52.991014",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Please notice the custom rounding round_with_gradients function since tf.round has no gradients and it won't be differentiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bc5d4f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T19:24:53.055543Z",
     "iopub.status.busy": "2021-10-12T19:24:53.054815Z",
     "iopub.status.idle": "2021-10-12T19:24:53.063863Z",
     "shell.execute_reply": "2021-10-12T19:24:53.064388Z",
     "shell.execute_reply.started": "2021-10-12T16:19:24.274243Z"
    },
    "papermill": {
     "duration": 0.032714,
     "end_time": "2021-10-12T19:24:53.064575",
     "exception": false,
     "start_time": "2021-10-12T19:24:53.031861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def round_with_gradients(x):\n",
    "    def grad(dy):\n",
    "        return dy\n",
    "    return tf.round(x), grad\n",
    "\n",
    "class ScaleLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(ScaleLayer, self).__init__()\n",
    "        self.min = tf.constant(pressure_min, dtype=np.float32)\n",
    "        self.max = tf.constant(pressure_max, dtype=np.float32)\n",
    "        self.step = tf.constant(pressure_step, dtype=np.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        steps = tf.math.divide(tf.math.add(inputs, -self.min), self.step)\n",
    "        int_steps = round_with_gradients(steps)\n",
    "        rescaled_steps = tf.math.add(tf.math.multiply(int_steps, self.step), self.min)\n",
    "        clipped = tf.clip_by_value(rescaled_steps, self.min, self.max)\n",
    "        return clipped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47eba90",
   "metadata": {
    "papermill": {
     "duration": 0.019704,
     "end_time": "2021-10-12T19:24:53.104362",
     "exception": false,
     "start_time": "2021-10-12T19:24:53.084658",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e7b941e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T19:24:53.182635Z",
     "iopub.status.busy": "2021-10-12T19:24:53.181763Z",
     "iopub.status.idle": "2021-10-12T20:09:07.134516Z",
     "shell.execute_reply": "2021-10-12T20:09:07.135264Z",
     "shell.execute_reply.started": "2021-10-12T16:19:24.288631Z"
    },
    "papermill": {
     "duration": 2654.011664,
     "end_time": "2021-10-12T20:09:07.135594",
     "exception": false,
     "start_time": "2021-10-12T19:24:53.123930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- > Fold 1 < ---------------\n",
      "(None, 1, 18432)\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 30s 219ms/step - loss: 6.9308 - val_loss: 3.0398\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.03985, saving model to folds0.hdf5\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0770 - val_loss: 3.0325\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.03985 to 3.03247, saving model to folds0.hdf5\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0735 - val_loss: 3.0331\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.03247\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0794 - val_loss: 3.0325\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.03247\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0620 - val_loss: 3.0332\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.03247\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0630 - val_loss: 3.0338\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.03247\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0748 - val_loss: 3.0348\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.03247\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0751 - val_loss: 3.0363\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.03247\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0639 - val_loss: 3.0333\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.03247\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0597 - val_loss: 3.0341\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.03247\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0801 - val_loss: 3.0327\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.03247\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0700 - val_loss: 3.0339\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.03247\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0747 - val_loss: 3.0337\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.03247\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0742 - val_loss: 3.0353\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.03247\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0596 - val_loss: 3.0352\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.03247\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0794 - val_loss: 3.0349\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.03247\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0787 - val_loss: 3.0336\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.03247\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0654 - val_loss: 3.0328\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.03247\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0722 - val_loss: 3.0374\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.03247\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0628 - val_loss: 3.0337\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.03247\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0732 - val_loss: 3.0338\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.03247\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0829 - val_loss: 3.0324\n",
      "\n",
      "Epoch 00022: val_loss improved from 3.03247 to 3.03244, saving model to folds0.hdf5\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0667 - val_loss: 3.0452\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.03244\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0732 - val_loss: 3.0326\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.03244\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0769 - val_loss: 3.0334\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.03244\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0867 - val_loss: 3.0331\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.03244\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0841 - val_loss: 3.0377\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.03244\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0686 - val_loss: 3.0336\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.03244\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0799 - val_loss: 3.0360\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.03244\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 3.0882 - val_loss: 3.0381\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.03244\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0829 - val_loss: 3.0400\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.03244\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0847 - val_loss: 3.0331\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.03244\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0746 - val_loss: 3.0359\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.03244\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0676 - val_loss: 3.0341\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.03244\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0822 - val_loss: 3.0320\n",
      "\n",
      "Epoch 00035: val_loss improved from 3.03244 to 3.03200, saving model to folds0.hdf5\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0711 - val_loss: 3.0334\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.03200\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0756 - val_loss: 3.0333\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.03200\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0806 - val_loss: 3.0352\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.03200\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0777 - val_loss: 3.0328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.03200\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0752 - val_loss: 3.0391\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3.03200\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0837 - val_loss: 3.0334\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 3.03200\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0895 - val_loss: 3.0342\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 3.03200\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 38ms/step - loss: 3.0916 - val_loss: 3.0360\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 3.03200\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0699 - val_loss: 3.0333\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3.03200\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0707 - val_loss: 3.0358\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 3.03200\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0837 - val_loss: 3.0336\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 3.03200\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0597 - val_loss: 3.0347\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 3.03200\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0794 - val_loss: 3.0354\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 3.03200\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0755 - val_loss: 3.0326\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 3.03200\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0738 - val_loss: 3.0347\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3.03200\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0770 - val_loss: 3.0357\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 3.03200\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0717 - val_loss: 3.0346\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 3.03200\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0612 - val_loss: 3.0335\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 3.03200\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0803 - val_loss: 3.0333\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 3.03200\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0805 - val_loss: 3.0357\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 3.03200\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0688 - val_loss: 3.0418\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 3.03200\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0685 - val_loss: 3.0350\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 3.03200\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0826 - val_loss: 3.0410\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 3.03200\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0785 - val_loss: 3.0397\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 3.03200\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0743 - val_loss: 3.0366\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 3.03200\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0798 - val_loss: 3.0331\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 3.03200\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0741 - val_loss: 3.0356\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 3.03200\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007387921, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0750 - val_loss: 3.0350\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 3.03200\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to tf.Tensor(0.00073519343, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0609 - val_loss: 3.0340\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 3.03200\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007316123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0786 - val_loss: 3.0329\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 3.03200\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007280487, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0632 - val_loss: 3.0337\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 3.03200\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007245024, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0789 - val_loss: 3.0357\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 3.03200\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007209733, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0623 - val_loss: 3.0342\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 3.03200\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071746146, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0741 - val_loss: 3.0378\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 3.03200\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007139667, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0705 - val_loss: 3.0326\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 3.03200\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071048894, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0761 - val_loss: 3.0365\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 3.03200\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007070282, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0831 - val_loss: 3.0326\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 3.03200\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007035842, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0723 - val_loss: 3.0386\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 3.03200\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to tf.Tensor(0.00070015714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0782 - val_loss: 3.0353\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 3.03200\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006967467, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0745 - val_loss: 3.0328\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 3.03200\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to tf.Tensor(0.00069335283, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0796 - val_loss: 3.0343\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 3.03200\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006899755, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0879 - val_loss: 3.0321\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 3.03200\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068661466, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0725 - val_loss: 3.0345\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 3.03200\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068327016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 46ms/step - loss: 3.0637 - val_loss: 3.0334\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 3.03200\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067994196, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0805 - val_loss: 3.0373\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 3.03200\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067663, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0806 - val_loss: 3.0354\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 3.03200\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006733342, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 3.0754 - val_loss: 3.0367\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 3.03200\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067005435, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0826 - val_loss: 3.0335\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 3.03200\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006667905, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0659 - val_loss: 3.0345\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 3.03200\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006635426, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0784 - val_loss: 3.0324\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 3.03200\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006603105, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0691 - val_loss: 3.0352\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 3.03200\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006570942, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0644 - val_loss: 3.0387\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 3.03200\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065389345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0757 - val_loss: 3.0335\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 3.03200\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065070833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0795 - val_loss: 3.0341\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 3.03200\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to tf.Tensor(0.00064753875, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0777 - val_loss: 3.0339\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 3.03200\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006443846, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0786 - val_loss: 3.0325\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 3.03200\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006412458, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0773 - val_loss: 3.0415\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 3.03200\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063812226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0702 - val_loss: 3.0340\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 3.03200\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063501403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0752 - val_loss: 3.0332\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 3.03200\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006319209, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0815 - val_loss: 3.0350\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 3.03200\n",
      "Epoch 00095: early stopping\n",
      "(50300, 1, 80)\n",
      "--------------- > Fold 2 < ---------------\n",
      "(None, 1, 18432)\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 29s 212ms/step - loss: 7.0470 - val_loss: 3.0908\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.09077, saving model to folds1.hdf5\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0729 - val_loss: 3.0816\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.09077 to 3.08163, saving model to folds1.hdf5\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0756 - val_loss: 3.0810\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.08163 to 3.08098, saving model to folds1.hdf5\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 37ms/step - loss: 3.0622 - val_loss: 3.0806\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.08098 to 3.08065, saving model to folds1.hdf5\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0692 - val_loss: 3.0817\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.08065\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0740 - val_loss: 3.0817\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.08065\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0564 - val_loss: 3.0803\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.08065 to 3.08028, saving model to folds1.hdf5\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0712 - val_loss: 3.0841\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.08028\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0659 - val_loss: 3.0815\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.08028\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0698 - val_loss: 3.0816\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.08028\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0664 - val_loss: 3.0813\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.08028\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0745 - val_loss: 3.0809\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.08028\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0722 - val_loss: 3.0822\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.08028\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0594 - val_loss: 3.0817\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.08028\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0701 - val_loss: 3.0850\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.08028\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0603 - val_loss: 3.0817\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.08028\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0745 - val_loss: 3.0809\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.08028\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 3.0770 - val_loss: 3.0814\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.08028\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0697 - val_loss: 3.0820\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.08028\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0678 - val_loss: 3.0815\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.08028\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0618 - val_loss: 3.0842\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.08028\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0765 - val_loss: 3.0817\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.08028\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0647 - val_loss: 3.0828\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.08028\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0720 - val_loss: 3.0869\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.08028\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0637 - val_loss: 3.0841\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.08028\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0641 - val_loss: 3.0824\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.08028\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0684 - val_loss: 3.0812\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.08028\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0829 - val_loss: 3.0824\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.08028\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0617 - val_loss: 3.0836\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.08028\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0857 - val_loss: 3.0857\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.08028\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0717 - val_loss: 3.0812\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.08028\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0672 - val_loss: 3.0820\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.08028\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0661 - val_loss: 3.0816\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.08028\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0649 - val_loss: 3.0811\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.08028\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0623 - val_loss: 3.0840\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.08028\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0677 - val_loss: 3.0819\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.08028\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0701 - val_loss: 3.0849\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.08028\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0709 - val_loss: 3.0830\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.08028\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0717 - val_loss: 3.0824\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.08028\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 3.0682 - val_loss: 3.0810\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3.08028\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0808 - val_loss: 3.0820\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 3.08028\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0695 - val_loss: 3.0817\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 3.08028\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0561 - val_loss: 3.0806\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 3.08028\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0689 - val_loss: 3.0825\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3.08028\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0645 - val_loss: 3.0805\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 3.08028\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0613 - val_loss: 3.0806\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 3.08028\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0677 - val_loss: 3.0823\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 3.08028\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0685 - val_loss: 3.0822\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 3.08028\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0616 - val_loss: 3.0826\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 3.08028\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0735 - val_loss: 3.0845\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3.08028\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0617 - val_loss: 3.0803\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 3.08028\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0606 - val_loss: 3.0811\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 3.08028\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0776 - val_loss: 3.0837\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 3.08028\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0705 - val_loss: 3.0809\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 3.08028\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0667 - val_loss: 3.0831\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 3.08028\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0714 - val_loss: 3.0831\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 3.08028\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0735 - val_loss: 3.0812\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 3.08028\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0732 - val_loss: 3.0803\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 3.08028\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0734 - val_loss: 3.0828\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 3.08028\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0730 - val_loss: 3.0826\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 3.08028\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0784 - val_loss: 3.0804\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 3.08028\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0733 - val_loss: 3.0859\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 3.08028\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007387921, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0742 - val_loss: 3.0819\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 3.08028\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to tf.Tensor(0.00073519343, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0646 - val_loss: 3.0806\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 3.08028\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007316123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0808 - val_loss: 3.0805\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 3.08028\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007280487, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0577 - val_loss: 3.0804\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 3.08028\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007245024, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0570 - val_loss: 3.0803\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 3.08028\n",
      "Epoch 00067: early stopping\n",
      "(50300, 1, 80)\n",
      "--------------- > Fold 3 < ---------------\n",
      "(None, 1, 18432)\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 29s 227ms/step - loss: 7.1408 - val_loss: 3.0820\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.08197, saving model to folds2.hdf5\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0651 - val_loss: 3.0694\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.08197 to 3.06935, saving model to folds2.hdf5\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0665 - val_loss: 3.0706\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.06935\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0694 - val_loss: 3.0701\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.06935\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0677 - val_loss: 3.0709\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.06935\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0707 - val_loss: 3.0709\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.06935\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0685 - val_loss: 3.0728\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.06935\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0660 - val_loss: 3.0728\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.06935\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0689 - val_loss: 3.0714\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.06935\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0732 - val_loss: 3.0706\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.06935\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0678 - val_loss: 3.0709\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.06935\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0592 - val_loss: 3.0702\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.06935\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0859 - val_loss: 3.0709\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.06935\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0710 - val_loss: 3.0717\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.06935\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0597 - val_loss: 3.0730\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.06935\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0730 - val_loss: 3.0726\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.06935\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0840 - val_loss: 3.0714\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.06935\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0642 - val_loss: 3.0698\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.06935\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0798 - val_loss: 3.0736\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.06935\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0803 - val_loss: 3.0712\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.06935\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0689 - val_loss: 3.0736\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.06935\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0713 - val_loss: 3.0714\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.06935\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0732 - val_loss: 3.0762\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.06935\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0733 - val_loss: 3.0730\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.06935\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0847 - val_loss: 3.0710\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.06935\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0732 - val_loss: 3.0697\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.06935\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0724 - val_loss: 3.0703\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.06935\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0681 - val_loss: 3.0747\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.06935\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0703 - val_loss: 3.0700\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.06935\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0628 - val_loss: 3.0751\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.06935\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0777 - val_loss: 3.0711\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.06935\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0700 - val_loss: 3.0703\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.06935\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0785 - val_loss: 3.0745\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.06935\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0605 - val_loss: 3.0712\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.06935\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0667 - val_loss: 3.0703\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.06935\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0697 - val_loss: 3.0736\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.06935\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0715 - val_loss: 3.0699\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.06935\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0625 - val_loss: 3.0707\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.06935\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0656 - val_loss: 3.0701\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.06935\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0771 - val_loss: 3.0705\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3.06935\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 40ms/step - loss: 3.0696 - val_loss: 3.0716\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 3.06935\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0724 - val_loss: 3.0711\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 3.06935\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0601 - val_loss: 3.0726\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 3.06935\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0688 - val_loss: 3.0710\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3.06935\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0648 - val_loss: 3.0713\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 3.06935\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0713 - val_loss: 3.0713\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 3.06935\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0685 - val_loss: 3.0701\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 3.06935\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0823 - val_loss: 3.0706\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 3.06935\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0718 - val_loss: 3.0698\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 3.06935\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0695 - val_loss: 3.0713\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3.06935\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0662 - val_loss: 3.0702\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 3.06935\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0773 - val_loss: 3.0721\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 3.06935\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0678 - val_loss: 3.0723\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 3.06935\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0623 - val_loss: 3.0705\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 3.06935\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0625 - val_loss: 3.0710\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 3.06935\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0769 - val_loss: 3.0712\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 3.06935\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0644 - val_loss: 3.0703\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 3.06935\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0601 - val_loss: 3.0708\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 3.06935\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0707 - val_loss: 3.0710\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 3.06935\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0739 - val_loss: 3.0705\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 3.06935\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0729 - val_loss: 3.0699\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 3.06935\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0765 - val_loss: 3.0699\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 3.06935\n",
      "Epoch 00062: early stopping\n",
      "(50300, 1, 80)\n",
      "--------------- > Fold 4 < ---------------\n",
      "(None, 1, 18432)\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 32s 237ms/step - loss: 7.2040 - val_loss: 3.0944\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.09441, saving model to folds3.hdf5\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0786 - val_loss: 3.0836\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.09441 to 3.08359, saving model to folds3.hdf5\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0629 - val_loss: 3.0836\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.08359\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0558 - val_loss: 3.0854\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.08359\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0695 - val_loss: 3.0835\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.08359 to 3.08353, saving model to folds3.hdf5\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0770 - val_loss: 3.0843\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.08353\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0720 - val_loss: 3.0851\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.08353\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0704 - val_loss: 3.0843\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.08353\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0621 - val_loss: 3.0854\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.08353\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0730 - val_loss: 3.0849\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.08353\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0703 - val_loss: 3.0840\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.08353\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0698 - val_loss: 3.0849\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.08353\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0706 - val_loss: 3.0857\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.08353\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0674 - val_loss: 3.0844\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.08353\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0758 - val_loss: 3.0847\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.08353\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0758 - val_loss: 3.0846\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.08353\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0682 - val_loss: 3.0851\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.08353\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0618 - val_loss: 3.0851\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.08353\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0742 - val_loss: 3.0859\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.08353\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0759 - val_loss: 3.0838\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.08353\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0708 - val_loss: 3.0844\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.08353\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0767 - val_loss: 3.0840\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.08353\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0647 - val_loss: 3.0847\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.08353\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0726 - val_loss: 3.0844\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.08353\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0670 - val_loss: 3.0846\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.08353\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0558 - val_loss: 3.0840\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.08353\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0687 - val_loss: 3.0845\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.08353\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0756 - val_loss: 3.0841\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.08353\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0697 - val_loss: 3.0847\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.08353\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0648 - val_loss: 3.0843\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.08353\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0701 - val_loss: 3.0846\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.08353\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0737 - val_loss: 3.0843\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.08353\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0688 - val_loss: 3.0860\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.08353\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0692 - val_loss: 3.0858\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.08353\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0686 - val_loss: 3.0844\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.08353\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0738 - val_loss: 3.0842\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.08353\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0671 - val_loss: 3.0848\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.08353\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0724 - val_loss: 3.0865\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.08353\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0752 - val_loss: 3.0862\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.08353\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0621 - val_loss: 3.0876\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3.08353\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0746 - val_loss: 3.0908\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 3.08353\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0554 - val_loss: 3.0864\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 3.08353\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0746 - val_loss: 3.0843\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 3.08353\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0613 - val_loss: 3.0850\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3.08353\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0701 - val_loss: 3.0858\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 3.08353\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0715 - val_loss: 3.0856\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 3.08353\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0723 - val_loss: 3.0849\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 3.08353\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0680 - val_loss: 3.0864\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 3.08353\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0740 - val_loss: 3.0851\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 3.08353\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 41ms/step - loss: 3.0706 - val_loss: 3.0873\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3.08353\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0782 - val_loss: 3.0845\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 3.08353\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0676 - val_loss: 3.0874\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 3.08353\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0721 - val_loss: 3.0843\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 3.08353\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0673 - val_loss: 3.0840\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 3.08353\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0666 - val_loss: 3.0844\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 3.08353\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0638 - val_loss: 3.0848\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 3.08353\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0675 - val_loss: 3.0856\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 3.08353\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0609 - val_loss: 3.0856\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 3.08353\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0702 - val_loss: 3.0846\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 3.08353\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0648 - val_loss: 3.0839\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 3.08353\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0690 - val_loss: 3.0852\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 3.08353\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0724 - val_loss: 3.0859\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 3.08353\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007387921, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0673 - val_loss: 3.0836\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 3.08353\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to tf.Tensor(0.00073519343, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 3.0554 - val_loss: 3.0843\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 3.08353\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007316123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0692 - val_loss: 3.0849\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 3.08353\n",
      "Epoch 00065: early stopping\n",
      "(50300, 1, 80)\n",
      "--------------- > Fold 5 < ---------------\n",
      "(None, 1, 18432)\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 30s 214ms/step - loss: 7.1378 - val_loss: 3.0896\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.08963, saving model to folds4.hdf5\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0597 - val_loss: 3.0791\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.08963 to 3.07911, saving model to folds4.hdf5\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0711 - val_loss: 3.0800\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.07911\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0723 - val_loss: 3.0808\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.07911\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 40ms/step - loss: 3.0721 - val_loss: 3.0792\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.07911\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0673 - val_loss: 3.0800\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.07911\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0629 - val_loss: 3.0792\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.07911\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0685 - val_loss: 3.0816\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.07911\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0600 - val_loss: 3.0806\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.07911\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0793 - val_loss: 3.0794\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.07911\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0697 - val_loss: 3.0823\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.07911\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0724 - val_loss: 3.0797\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.07911\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0705 - val_loss: 3.0814\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.07911\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0698 - val_loss: 3.0812\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.07911\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0743 - val_loss: 3.0812\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.07911\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0762 - val_loss: 3.0796\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.07911\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0756 - val_loss: 3.0806\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.07911\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0527 - val_loss: 3.0807\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.07911\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0648 - val_loss: 3.0803\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.07911\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0786 - val_loss: 3.0806\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.07911\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0764 - val_loss: 3.0824\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.07911\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0671 - val_loss: 3.0805\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.07911\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0729 - val_loss: 3.0805\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.07911\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0640 - val_loss: 3.0801\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.07911\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0668 - val_loss: 3.0870\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.07911\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0736 - val_loss: 3.0813\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.07911\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0669 - val_loss: 3.0820\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.07911\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0598 - val_loss: 3.0852\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.07911\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0792 - val_loss: 3.0817\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.07911\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0715 - val_loss: 3.0809\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.07911\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0717 - val_loss: 3.0798\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.07911\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0784 - val_loss: 3.0802\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.07911\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0729 - val_loss: 3.0817\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.07911\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0730 - val_loss: 3.0809\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.07911\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0755 - val_loss: 3.0793\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.07911\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0646 - val_loss: 3.0803\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.07911\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0702 - val_loss: 3.0840\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.07911\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0763 - val_loss: 3.0794\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.07911\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0645 - val_loss: 3.0844\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.07911\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0662 - val_loss: 3.0798\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3.07911\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0619 - val_loss: 3.0865\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 3.07911\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0694 - val_loss: 3.0798\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 3.07911\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0700 - val_loss: 3.0815\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 3.07911\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0702 - val_loss: 3.0819\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3.07911\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0801 - val_loss: 3.0813\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 3.07911\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0690 - val_loss: 3.0805\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 3.07911\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0700 - val_loss: 3.0793\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 3.07911\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0704 - val_loss: 3.0838\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 3.07911\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0753 - val_loss: 3.0820\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 3.07911\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0685 - val_loss: 3.0808\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3.07911\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0608 - val_loss: 3.0825\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 3.07911\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0651 - val_loss: 3.0794\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 3.07911\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0745 - val_loss: 3.0799\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 3.07911\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0632 - val_loss: 3.0805\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 3.07911\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0648 - val_loss: 3.0810\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 3.07911\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0702 - val_loss: 3.0824\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 3.07911\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0749 - val_loss: 3.0810\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 3.07911\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 3.0605 - val_loss: 3.0799\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 3.07911\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0661 - val_loss: 3.0798\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 3.07911\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0712 - val_loss: 3.0828\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 3.07911\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0670 - val_loss: 3.0806\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 3.07911\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0800 - val_loss: 3.0795\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 3.07911\n",
      "Epoch 00062: early stopping\n",
      "(50300, 1, 80)\n",
      "--------------- > Fold 6 < ---------------\n",
      "(None, 1, 18432)\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 30s 215ms/step - loss: 7.2093 - val_loss: 3.0776\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.07758, saving model to folds5.hdf5\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0849 - val_loss: 3.0671\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.07758 to 3.06707, saving model to folds5.hdf5\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0618 - val_loss: 3.0698\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.06707\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0680 - val_loss: 3.0670\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.06707 to 3.06705, saving model to folds5.hdf5\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 3.0694 - val_loss: 3.0684\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.06705\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0768 - val_loss: 3.0687\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.06705\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0886 - val_loss: 3.0687\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.06705\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0652 - val_loss: 3.0689\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.06705\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0612 - val_loss: 3.0675\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.06705\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0782 - val_loss: 3.0697\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.06705\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0590 - val_loss: 3.0691\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.06705\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0717 - val_loss: 3.0690\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.06705\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0781 - val_loss: 3.0693\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.06705\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0754 - val_loss: 3.0683\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.06705\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0721 - val_loss: 3.0687\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.06705\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0628 - val_loss: 3.0686\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.06705\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0709 - val_loss: 3.0693\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.06705\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0649 - val_loss: 3.0691\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.06705\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0689 - val_loss: 3.0690\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.06705\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0757 - val_loss: 3.0691\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.06705\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0650 - val_loss: 3.0694\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.06705\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0830 - val_loss: 3.0680\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.06705\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0618 - val_loss: 3.0698\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.06705\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 3.0600 - val_loss: 3.0730\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.06705\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0650 - val_loss: 3.0705\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.06705\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0684 - val_loss: 3.0692\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.06705\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0783 - val_loss: 3.0702\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.06705\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0713 - val_loss: 3.0700\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.06705\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0709 - val_loss: 3.0701\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.06705\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0713 - val_loss: 3.0690\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.06705\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0673 - val_loss: 3.0687\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.06705\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0733 - val_loss: 3.0707\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.06705\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0673 - val_loss: 3.0684\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.06705\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0811 - val_loss: 3.0699\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.06705\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0652 - val_loss: 3.0687\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.06705\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0709 - val_loss: 3.0687\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.06705\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0741 - val_loss: 3.0709\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.06705\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0723 - val_loss: 3.0699\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.06705\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0740 - val_loss: 3.0691\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.06705\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0733 - val_loss: 3.0690\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3.06705\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0620 - val_loss: 3.0692\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 3.06705\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0652 - val_loss: 3.0700\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 3.06705\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0644 - val_loss: 3.0684\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 3.06705\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0682 - val_loss: 3.0684\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3.06705\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0775 - val_loss: 3.0702\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 3.06705\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0605 - val_loss: 3.0686\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 3.06705\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0694 - val_loss: 3.0683\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 3.06705\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0571 - val_loss: 3.0679\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 3.06705\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0669 - val_loss: 3.0682\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 3.06705\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0859 - val_loss: 3.0691\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3.06705\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0606 - val_loss: 3.0685\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 3.06705\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0771 - val_loss: 3.0683\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 3.06705\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0606 - val_loss: 3.0702\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 3.06705\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0764 - val_loss: 3.0709\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 3.06705\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0731 - val_loss: 3.0692\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 3.06705\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0701 - val_loss: 3.0718\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 3.06705\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0618 - val_loss: 3.0689\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 3.06705\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0867 - val_loss: 3.0683\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 3.06705\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0650 - val_loss: 3.0714\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 3.06705\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 51ms/step - loss: 3.0693 - val_loss: 3.0694\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 3.06705\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0731 - val_loss: 3.0713\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 3.06705\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0776 - val_loss: 3.0694\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 3.06705\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007387921, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0644 - val_loss: 3.0688\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 3.06705\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to tf.Tensor(0.00073519343, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0719 - val_loss: 3.0689\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 3.06705\n",
      "Epoch 00064: early stopping\n",
      "(50300, 1, 80)\n",
      "--------------- > Fold 7 < ---------------\n",
      "(None, 1, 18432)\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 30s 218ms/step - loss: 7.2024 - val_loss: 3.1077\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.10769, saving model to folds6.hdf5\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0758 - val_loss: 3.0978\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.10769 to 3.09784, saving model to folds6.hdf5\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0636 - val_loss: 3.0979\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.09784\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0613 - val_loss: 3.0978\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.09784 to 3.09776, saving model to folds6.hdf5\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0706 - val_loss: 3.0990\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.09776\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0707 - val_loss: 3.0989\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.09776\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0639 - val_loss: 3.0984\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.09776\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 37ms/step - loss: 3.0616 - val_loss: 3.0979\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.09776\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0710 - val_loss: 3.0978\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.09776\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0662 - val_loss: 3.0984\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.09776\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 40ms/step - loss: 3.0554 - val_loss: 3.0983\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.09776\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0575 - val_loss: 3.0989\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.09776\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0732 - val_loss: 3.1003\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.09776\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0816 - val_loss: 3.0983\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.09776\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0578 - val_loss: 3.1004\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.09776\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0693 - val_loss: 3.0998\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.09776\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0656 - val_loss: 3.1039\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.09776\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0640 - val_loss: 3.0987\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.09776\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0726 - val_loss: 3.1006\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.09776\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0709 - val_loss: 3.0985\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.09776\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0628 - val_loss: 3.0987\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.09776\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0661 - val_loss: 3.0985\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.09776\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0659 - val_loss: 3.0983\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.09776\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0633 - val_loss: 3.1011\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.09776\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0620 - val_loss: 3.0992\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.09776\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0697 - val_loss: 3.0986\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.09776\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0742 - val_loss: 3.1019\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.09776\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0585 - val_loss: 3.0991\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.09776\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0644 - val_loss: 3.1008\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.09776\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0666 - val_loss: 3.0986\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.09776\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0680 - val_loss: 3.1023\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.09776\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0732 - val_loss: 3.1035\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.09776\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0686 - val_loss: 3.1011\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.09776\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0716 - val_loss: 3.0983\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.09776\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0603 - val_loss: 3.0988\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.09776\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0795 - val_loss: 3.0989\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.09776\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 3.0690 - val_loss: 3.0993\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.09776\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0685 - val_loss: 3.1004\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.09776\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0734 - val_loss: 3.0990\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.09776\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0720 - val_loss: 3.1002\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3.09776\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0740 - val_loss: 3.0983\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 3.09776\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0642 - val_loss: 3.0996\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 3.09776\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 3.0614 - val_loss: 3.1001\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 3.09776\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0642 - val_loss: 3.0989\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3.09776\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0584 - val_loss: 3.0997\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 3.09776\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0648 - val_loss: 3.0989\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 3.09776\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0779 - val_loss: 3.0996\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 3.09776\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0659 - val_loss: 3.0984\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 3.09776\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0674 - val_loss: 3.0992\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 3.09776\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0649 - val_loss: 3.0986\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3.09776\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0674 - val_loss: 3.0999\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 3.09776\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0694 - val_loss: 3.0981\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 3.09776\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0682 - val_loss: 3.0996\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 3.09776\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0554 - val_loss: 3.1000\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 3.09776\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0641 - val_loss: 3.0977\n",
      "\n",
      "Epoch 00055: val_loss improved from 3.09776 to 3.09766, saving model to folds6.hdf5\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 3.0668 - val_loss: 3.1017\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 3.09766\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 3.0623 - val_loss: 3.1012\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 3.09766\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0770 - val_loss: 3.0986\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 3.09766\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0679 - val_loss: 3.0993\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 3.09766\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0672 - val_loss: 3.0989\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 3.09766\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0550 - val_loss: 3.0984\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 3.09766\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0721 - val_loss: 3.1011\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 3.09766\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007387921, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0660 - val_loss: 3.0990\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 3.09766\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to tf.Tensor(0.00073519343, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0689 - val_loss: 3.0980\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 3.09766\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007316123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0605 - val_loss: 3.0997\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 3.09766\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007280487, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0653 - val_loss: 3.0986\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 3.09766\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007245024, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0676 - val_loss: 3.0977\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 3.09766\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007209733, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0623 - val_loss: 3.0979\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 3.09766\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071746146, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0601 - val_loss: 3.0974\n",
      "\n",
      "Epoch 00069: val_loss improved from 3.09766 to 3.09742, saving model to folds6.hdf5\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007139667, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0719 - val_loss: 3.1002\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 3.09742\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to tf.Tensor(0.00071048894, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0670 - val_loss: 3.0982\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 3.09742\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007070282, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0609 - val_loss: 3.0988\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 3.09742\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007035842, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0780 - val_loss: 3.0982\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 3.09742\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to tf.Tensor(0.00070015714, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0691 - val_loss: 3.1008\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 3.09742\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006967467, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0677 - val_loss: 3.0993\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 3.09742\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to tf.Tensor(0.00069335283, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0686 - val_loss: 3.0987\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 3.09742\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006899755, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0641 - val_loss: 3.0996\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 3.09742\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068661466, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0671 - val_loss: 3.0991\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 3.09742\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to tf.Tensor(0.00068327016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0740 - val_loss: 3.0994\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 3.09742\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067994196, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0535 - val_loss: 3.0984\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 3.09742\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067663, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0664 - val_loss: 3.0993\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 3.09742\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006733342, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0667 - val_loss: 3.0996\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 3.09742\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067005435, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0660 - val_loss: 3.0984\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 3.09742\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006667905, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0684 - val_loss: 3.0980\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 3.09742\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006635426, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0673 - val_loss: 3.0999\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 3.09742\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006603105, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0603 - val_loss: 3.0977\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 3.09742\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006570942, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0684 - val_loss: 3.0982\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 3.09742\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065389345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0597 - val_loss: 3.0984\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 3.09742\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to tf.Tensor(0.00065070833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0688 - val_loss: 3.0977\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 3.09742\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to tf.Tensor(0.00064753875, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0581 - val_loss: 3.1000\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 3.09742\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006443846, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0711 - val_loss: 3.0981\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 3.09742\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006412458, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0635 - val_loss: 3.0988\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 3.09742\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063812226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 3.0719 - val_loss: 3.0994\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 3.09742\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to tf.Tensor(0.00063501403, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0743 - val_loss: 3.0980\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 3.09742\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006319209, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0579 - val_loss: 3.0995\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 3.09742\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006288428, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0636 - val_loss: 3.0989\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 3.09742\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to tf.Tensor(0.00062577974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0751 - val_loss: 3.0987\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 3.09742\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006227316, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0725 - val_loss: 3.0981\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 3.09742\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061969826, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0677 - val_loss: 3.0990\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 3.09742\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 00100: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006166797, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 3.0699 - val_loss: 3.0976\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 3.09742\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 00101: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061367586, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0571 - val_loss: 3.0986\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 3.09742\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 00102: LearningRateScheduler reducing learning rate to tf.Tensor(0.00061068666, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0677 - val_loss: 3.0994\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 3.09742\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 00103: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006077121, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0650 - val_loss: 3.0984\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 3.09742\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 00104: LearningRateScheduler reducing learning rate to tf.Tensor(0.00060475187, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0585 - val_loss: 3.0979\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 3.09742\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 00105: LearningRateScheduler reducing learning rate to tf.Tensor(0.00060180615, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0647 - val_loss: 3.0983\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 3.09742\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 00106: LearningRateScheduler reducing learning rate to tf.Tensor(0.00059887476, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0615 - val_loss: 3.0980\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 3.09742\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 00107: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005959577, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0680 - val_loss: 3.0989\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 3.09742\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 00108: LearningRateScheduler reducing learning rate to tf.Tensor(0.00059305475, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0681 - val_loss: 3.1018\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 3.09742\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 00109: LearningRateScheduler reducing learning rate to tf.Tensor(0.000590166, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0722 - val_loss: 3.1007\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 3.09742\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 00110: LearningRateScheduler reducing learning rate to tf.Tensor(0.00058729126, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0630 - val_loss: 3.0989\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 3.09742\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 00111: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005844306, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0704 - val_loss: 3.0989\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 3.09742\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 00112: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005815838, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0642 - val_loss: 3.0994\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 3.09742\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 00113: LearningRateScheduler reducing learning rate to tf.Tensor(0.000578751, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0704 - val_loss: 3.0992\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 3.09742\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 00114: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057593186, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 3.0751 - val_loss: 3.0994\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 3.09742\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 00115: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057312654, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0654 - val_loss: 3.1014\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 3.09742\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 00116: LearningRateScheduler reducing learning rate to tf.Tensor(0.00057033484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0585 - val_loss: 3.0973\n",
      "\n",
      "Epoch 00116: val_loss improved from 3.09742 to 3.09728, saving model to folds6.hdf5\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 00117: LearningRateScheduler reducing learning rate to tf.Tensor(0.00056755677, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0627 - val_loss: 3.0985\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 3.09728\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 00118: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005647922, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0627 - val_loss: 3.0999\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 3.09728\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 00119: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005620411, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0677 - val_loss: 3.0985\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 3.09728\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 00120: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055930344, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0607 - val_loss: 3.0992\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 3.09728\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 00121: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055657903, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0529 - val_loss: 3.0973\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 3.09728\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 00122: LearningRateScheduler reducing learning rate to tf.Tensor(0.00055386795, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0561 - val_loss: 3.0986\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 3.09728\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 00123: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005511701, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0670 - val_loss: 3.0986\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 3.09728\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 00124: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005484854, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0653 - val_loss: 3.0984\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 3.09728\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 00125: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005458137, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0677 - val_loss: 3.0993\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 3.09728\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 00126: LearningRateScheduler reducing learning rate to tf.Tensor(0.00054315507, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 3.0766 - val_loss: 3.0984\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 3.09728\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 00127: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005405093, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0745 - val_loss: 3.0991\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 3.09728\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 00128: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005378765, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0716 - val_loss: 3.1008\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 3.09728\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 00129: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005352565, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0644 - val_loss: 3.0982\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 3.09728\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 00130: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005326493, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0474 - val_loss: 3.0978\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 3.09728\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 00131: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005300548, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0652 - val_loss: 3.0977\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 3.09728\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 00132: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005274729, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0645 - val_loss: 3.0987\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 3.09728\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 00133: LearningRateScheduler reducing learning rate to tf.Tensor(0.00052490365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 3.0656 - val_loss: 3.0991\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 3.09728\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 00134: LearningRateScheduler reducing learning rate to tf.Tensor(0.00052234676, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0658 - val_loss: 3.0975\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 3.09728\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 00135: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005198025, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 3.0615 - val_loss: 3.0973\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 3.09728\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 00136: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005172705, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0644 - val_loss: 3.0982\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 3.09728\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 00137: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051475083, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 37ms/step - loss: 3.0634 - val_loss: 3.0986\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 3.09728\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 00138: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051224354, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 3.0698 - val_loss: 3.0980\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 3.09728\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 00139: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005097484, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0609 - val_loss: 3.0988\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 3.09728\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 00140: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005072654, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0785 - val_loss: 3.0979\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 3.09728\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 00141: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005047946, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 3.0640 - val_loss: 3.0985\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 3.09728\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 00142: LearningRateScheduler reducing learning rate to tf.Tensor(0.0005023357, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0662 - val_loss: 3.0975\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 3.09728\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 00143: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049988885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0674 - val_loss: 3.0988\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 3.09728\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 00144: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004974539, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0698 - val_loss: 3.0980\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 3.09728\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 00145: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004950308, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0738 - val_loss: 3.0988\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 3.09728\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 00146: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004926195, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 44ms/step - loss: 3.0587 - val_loss: 3.0989\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 3.09728\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 00147: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049022, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0711 - val_loss: 3.0982\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 3.09728\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 00148: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048783212, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0505 - val_loss: 3.0970\n",
      "\n",
      "Epoch 00148: val_loss improved from 3.09728 to 3.09696, saving model to folds6.hdf5\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 00149: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048545588, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0696 - val_loss: 3.0976\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 3.09696\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 00150: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048309125, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0585 - val_loss: 3.1004\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 3.09696\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 00151: LearningRateScheduler reducing learning rate to tf.Tensor(0.00048073815, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0655 - val_loss: 3.0984\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 3.09696\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 00152: LearningRateScheduler reducing learning rate to tf.Tensor(0.00047839645, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0720 - val_loss: 3.0976\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 3.09696\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 00153: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004760662, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0708 - val_loss: 3.0977\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 3.09696\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 00154: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004737473, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0649 - val_loss: 3.0983\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 3.09696\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 00155: LearningRateScheduler reducing learning rate to tf.Tensor(0.00047143968, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0590 - val_loss: 3.0990\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 3.09696\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 00156: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004691433, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0563 - val_loss: 3.0981\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 3.09696\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 00157: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046685815, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0604 - val_loss: 3.0983\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 3.09696\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 00158: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046458407, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0592 - val_loss: 3.0981\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 3.09696\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 00159: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046232107, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 37ms/step - loss: 3.0685 - val_loss: 3.0987\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 3.09696\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 00160: LearningRateScheduler reducing learning rate to tf.Tensor(0.00046006907, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0679 - val_loss: 3.0980\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 3.09696\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 00161: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045782814, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0609 - val_loss: 3.0969\n",
      "\n",
      "Epoch 00161: val_loss improved from 3.09696 to 3.09691, saving model to folds6.hdf5\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 00162: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045559806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0619 - val_loss: 3.0977\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 3.09691\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 00163: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045337883, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0686 - val_loss: 3.0975\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 3.09691\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 00164: LearningRateScheduler reducing learning rate to tf.Tensor(0.00045117046, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0684 - val_loss: 3.0982\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 3.09691\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 00165: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044897277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0717 - val_loss: 3.0978\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 3.09691\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 00166: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044678585, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0601 - val_loss: 3.0975\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 3.09691\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 00167: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004446096, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0589 - val_loss: 3.0976\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 3.09691\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 00168: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004424439, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0681 - val_loss: 3.0991\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 3.09691\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 00169: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044028874, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0570 - val_loss: 3.1010\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 3.09691\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 00170: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043814414, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0617 - val_loss: 3.0971\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 3.09691\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 00171: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043600993, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0691 - val_loss: 3.0973\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 3.09691\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 00172: LearningRateScheduler reducing learning rate to tf.Tensor(0.00043388613, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0591 - val_loss: 3.0976\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 3.09691\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 00173: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004317727, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0619 - val_loss: 3.0981\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 3.09691\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 00174: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004296695, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0645 - val_loss: 3.0988\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 3.09691\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 00175: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004275766, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0664 - val_loss: 3.0983\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 3.09691\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 00176: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042549393, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0644 - val_loss: 3.0984\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 3.09691\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 00177: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042342133, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0571 - val_loss: 3.0973\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 3.09691\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 00178: LearningRateScheduler reducing learning rate to tf.Tensor(0.00042135885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0640 - val_loss: 3.0985\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 3.09691\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 00179: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041930642, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0660 - val_loss: 3.0984\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 3.09691\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 00180: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041726397, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0523 - val_loss: 3.0974\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 3.09691\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 00181: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041523148, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0672 - val_loss: 3.0971\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 3.09691\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 00182: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041320888, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 3.0673 - val_loss: 3.1001\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 3.09691\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 00183: LearningRateScheduler reducing learning rate to tf.Tensor(0.00041119618, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0652 - val_loss: 3.0989\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 3.09691\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 00184: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040919325, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0668 - val_loss: 3.0992\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 3.09691\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 00185: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040720004, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0629 - val_loss: 3.0981\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 3.09691\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 00186: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004052166, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0609 - val_loss: 3.0971\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 3.09691\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 00187: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004032428, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0780 - val_loss: 3.0984\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 3.09691\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 00188: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004012786, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0759 - val_loss: 3.0981\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 3.09691\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 00189: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039932402, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0631 - val_loss: 3.0976\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 3.09691\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 00190: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039737887, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 38ms/step - loss: 3.0630 - val_loss: 3.0977\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 3.09691\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 00191: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039544326, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0594 - val_loss: 3.0980\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 3.09691\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 00192: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039351705, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0584 - val_loss: 3.0984\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 3.09691\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 00193: LearningRateScheduler reducing learning rate to tf.Tensor(0.00039160028, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0674 - val_loss: 3.0998\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 3.09691\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 00194: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038969278, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0663 - val_loss: 3.0972\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 3.09691\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 00195: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003877946, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0593 - val_loss: 3.0980\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 3.09691\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 00196: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038590565, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0648 - val_loss: 3.0972\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 3.09691\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 00197: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003840259, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0681 - val_loss: 3.0978\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 3.09691\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 00198: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038215535, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0584 - val_loss: 3.0975\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 3.09691\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 00199: LearningRateScheduler reducing learning rate to tf.Tensor(0.00038029387, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0782 - val_loss: 3.0980\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 3.09691\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 00200: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037844144, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0699 - val_loss: 3.0981\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 3.09691\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 00201: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037659804, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0621 - val_loss: 3.0980\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 3.09691\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 00202: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037476368, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0690 - val_loss: 3.0971\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 3.09691\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 00203: LearningRateScheduler reducing learning rate to tf.Tensor(0.00037293817, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0762 - val_loss: 3.0980\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 3.09691\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 00204: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003711216, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0714 - val_loss: 3.0973\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 3.09691\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 00205: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003693139, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0674 - val_loss: 3.0979\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 3.09691\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 00206: LearningRateScheduler reducing learning rate to tf.Tensor(0.000367515, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0694 - val_loss: 3.0977\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 3.09691\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 00207: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036572482, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0708 - val_loss: 3.0978\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 3.09691\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 00208: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003639434, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0823 - val_loss: 3.1005\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 3.09691\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 00209: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036217063, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0701 - val_loss: 3.0973\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 3.09691\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 00210: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036040647, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0720 - val_loss: 3.0974\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 3.09691\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 00211: LearningRateScheduler reducing learning rate to tf.Tensor(0.00035865093, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0653 - val_loss: 3.0995\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 3.09691\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 00212: LearningRateScheduler reducing learning rate to tf.Tensor(0.000356904, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0659 - val_loss: 3.0976\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 3.09691\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 00213: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003551655, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0671 - val_loss: 3.0983\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 3.09691\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 00214: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003534355, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0644 - val_loss: 3.0978\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 3.09691\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 00215: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003517139, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0542 - val_loss: 3.0975\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 3.09691\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 00216: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003500007, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0798 - val_loss: 3.0975\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 3.09691\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 00217: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034829587, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0608 - val_loss: 3.0974\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 3.09691\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 00218: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034659932, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 41ms/step - loss: 3.0653 - val_loss: 3.0979\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 3.09691\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 00219: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034491107, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0705 - val_loss: 3.0976\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 3.09691\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 00220: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034323102, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 41ms/step - loss: 3.0629 - val_loss: 3.0970\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 3.09691\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 00221: LearningRateScheduler reducing learning rate to tf.Tensor(0.00034155912, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 3.0545 - val_loss: 3.0975\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 3.09691\n",
      "Epoch 00221: early stopping\n",
      "(50300, 1, 80)\n",
      "--------------- > Fold 8 < ---------------\n",
      "(None, 1, 18432)\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 30s 217ms/step - loss: 7.2021 - val_loss: 3.0719\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.07191, saving model to folds7.hdf5\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0830 - val_loss: 3.0597\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.07191 to 3.05973, saving model to folds7.hdf5\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0704 - val_loss: 3.0602\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.05973\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0667 - val_loss: 3.0598\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.05973\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0736 - val_loss: 3.0612\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.05973\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0664 - val_loss: 3.0601\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.05973\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0682 - val_loss: 3.0635\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.05973\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0683 - val_loss: 3.0608\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.05973\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0671 - val_loss: 3.0614\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.05973\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0556 - val_loss: 3.0612\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.05973\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0769 - val_loss: 3.0607\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.05973\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0724 - val_loss: 3.0624\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.05973\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 40ms/step - loss: 3.0731 - val_loss: 3.0611\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.05973\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0707 - val_loss: 3.0623\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.05973\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0709 - val_loss: 3.0602\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.05973\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0727 - val_loss: 3.0604\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.05973\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0817 - val_loss: 3.0622\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.05973\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0730 - val_loss: 3.0607\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.05973\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0677 - val_loss: 3.0632\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.05973\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0638 - val_loss: 3.0609\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.05973\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0745 - val_loss: 3.0612\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.05973\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0712 - val_loss: 3.0623\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.05973\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0710 - val_loss: 3.0609\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.05973\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0675 - val_loss: 3.0607\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.05973\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0677 - val_loss: 3.0626\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.05973\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0729 - val_loss: 3.0668\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.05973\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0654 - val_loss: 3.0621\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.05973\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 3.0690 - val_loss: 3.0609\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.05973\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0641 - val_loss: 3.0633\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.05973\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0809 - val_loss: 3.0623\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.05973\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0667 - val_loss: 3.0617\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.05973\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0585 - val_loss: 3.0627\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.05973\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0754 - val_loss: 3.0614\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.05973\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0751 - val_loss: 3.0612\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.05973\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0724 - val_loss: 3.0625\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.05973\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0805 - val_loss: 3.0613\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.05973\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0579 - val_loss: 3.0609\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.05973\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0630 - val_loss: 3.0624\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.05973\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 3.0830 - val_loss: 3.0633\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.05973\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0784 - val_loss: 3.0623\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3.05973\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0629 - val_loss: 3.0609\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 3.05973\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0843 - val_loss: 3.0627\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 3.05973\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0798 - val_loss: 3.0613\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 3.05973\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0728 - val_loss: 3.0610\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3.05973\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0720 - val_loss: 3.0622\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 3.05973\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0626 - val_loss: 3.0624\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 3.05973\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0681 - val_loss: 3.0605\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 3.05973\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0594 - val_loss: 3.0620\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 3.05973\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0695 - val_loss: 3.0629\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 3.05973\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0742 - val_loss: 3.0604\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3.05973\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0644 - val_loss: 3.0604\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 3.05973\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0807 - val_loss: 3.0638\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 3.05973\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0642 - val_loss: 3.0605\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 3.05973\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0747 - val_loss: 3.0613\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 3.05973\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0707 - val_loss: 3.0633\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 3.05973\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0777 - val_loss: 3.0618\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 3.05973\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0657 - val_loss: 3.0622\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 3.05973\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0741 - val_loss: 3.0616\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 3.05973\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0641 - val_loss: 3.0606\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 3.05973\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 3.0785 - val_loss: 3.0617\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 3.05973\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 3.0728 - val_loss: 3.0627\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 3.05973\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0702 - val_loss: 3.0620\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 3.05973\n",
      "Epoch 00062: early stopping\n",
      "(50300, 1, 80)\n",
      "--------------- > Fold 9 < ---------------\n",
      "(None, 1, 18432)\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 29s 213ms/step - loss: 7.0582 - val_loss: 3.0675\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.06755, saving model to folds8.hdf5\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0817 - val_loss: 3.0591\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.06755 to 3.05906, saving model to folds8.hdf5\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0682 - val_loss: 3.0593\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.05906\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0750 - val_loss: 3.0597\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.05906\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0703 - val_loss: 3.0597\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.05906\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0630 - val_loss: 3.0600\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.05906\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0600 - val_loss: 3.0598\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.05906\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0678 - val_loss: 3.0613\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.05906\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0706 - val_loss: 3.0595\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.05906\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 38ms/step - loss: 3.0720 - val_loss: 3.0609\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.05906\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0740 - val_loss: 3.0610\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.05906\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0785 - val_loss: 3.0607\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.05906\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0743 - val_loss: 3.0604\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.05906\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0686 - val_loss: 3.0594\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.05906\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0708 - val_loss: 3.0604\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.05906\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0766 - val_loss: 3.0604\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.05906\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0761 - val_loss: 3.0601\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.05906\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0745 - val_loss: 3.0600\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.05906\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0792 - val_loss: 3.0604\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.05906\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0815 - val_loss: 3.0623\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.05906\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0741 - val_loss: 3.0605\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.05906\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0618 - val_loss: 3.0595\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.05906\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0740 - val_loss: 3.0614\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.05906\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0749 - val_loss: 3.0600\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.05906\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0640 - val_loss: 3.0615\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.05906\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0690 - val_loss: 3.0593\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.05906\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0760 - val_loss: 3.0601\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.05906\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0701 - val_loss: 3.0630\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.05906\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0712 - val_loss: 3.0617\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.05906\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0566 - val_loss: 3.0628\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.05906\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0776 - val_loss: 3.0596\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.05906\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0768 - val_loss: 3.0616\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.05906\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0713 - val_loss: 3.0594\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.05906\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0735 - val_loss: 3.0603\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.05906\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0633 - val_loss: 3.0610\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.05906\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0730 - val_loss: 3.0619\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.05906\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0804 - val_loss: 3.0600\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.05906\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0636 - val_loss: 3.0602\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.05906\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0749 - val_loss: 3.0616\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.05906\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0708 - val_loss: 3.0604\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3.05906\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0765 - val_loss: 3.0604\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 3.05906\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0742 - val_loss: 3.0610\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 3.05906\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0735 - val_loss: 3.0601\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 3.05906\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0724 - val_loss: 3.0618\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3.05906\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0664 - val_loss: 3.0607\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 3.05906\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0723 - val_loss: 3.0596\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 3.05906\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0775 - val_loss: 3.0602\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 3.05906\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0746 - val_loss: 3.0596\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 3.05906\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0856 - val_loss: 3.0621\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 3.05906\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0666 - val_loss: 3.0602\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3.05906\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0687 - val_loss: 3.0599\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 3.05906\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 3.0694 - val_loss: 3.0602\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 3.05906\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0734 - val_loss: 3.0599\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 3.05906\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0801 - val_loss: 3.0639\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 3.05906\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0697 - val_loss: 3.0596\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 3.05906\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0672 - val_loss: 3.0594\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 3.05906\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0825 - val_loss: 3.0603\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 3.05906\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0666 - val_loss: 3.0616\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 3.05906\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0692 - val_loss: 3.0608\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 3.05906\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0758 - val_loss: 3.0614\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 3.05906\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0692 - val_loss: 3.0631\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 3.05906\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0747 - val_loss: 3.0620\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 3.05906\n",
      "Epoch 00062: early stopping\n",
      "(50300, 1, 80)\n",
      "--------------- > Fold 10 < ---------------\n",
      "(None, 1, 18432)\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 29s 214ms/step - loss: 6.9913 - val_loss: 3.0680\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.06803, saving model to folds9.hdf5\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to tf.Tensor(0.000995129, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0745 - val_loss: 3.0597\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.06803 to 3.05974, saving model to folds9.hdf5\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009902818, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0698 - val_loss: 3.0600\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.05974\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009854581, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0688 - val_loss: 3.0591\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.05974 to 3.05909, saving model to folds9.hdf5\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to tf.Tensor(0.000980658, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 37ms/step - loss: 3.0707 - val_loss: 3.0608\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.05909\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to tf.Tensor(0.00097588124, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0632 - val_loss: 3.0601\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.05909\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009711277, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0754 - val_loss: 3.0595\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.05909\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009663974, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0601 - val_loss: 3.0598\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.05909\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009616901, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0714 - val_loss: 3.0605\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.05909\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009570057, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0657 - val_loss: 3.0603\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.05909\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.00095234415, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0688 - val_loss: 3.0600\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.05909\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009477053, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0551 - val_loss: 3.0609\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.05909\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009430891, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0699 - val_loss: 3.0599\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.05909\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009384953, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0679 - val_loss: 3.0609\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.05909\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009339239, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0668 - val_loss: 3.0608\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.05909\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009293747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0693 - val_loss: 3.0617\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.05909\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009248478, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0775 - val_loss: 3.0600\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.05909\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.00092034286, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0626 - val_loss: 3.0625\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.05909\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091585994, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0813 - val_loss: 3.0601\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.05909\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.00091139873, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0756 - val_loss: 3.0611\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.05909\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090695935, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0693 - val_loss: 3.0616\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.05909\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.00090254156, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0595 - val_loss: 3.0611\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.05909\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008981453, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0697 - val_loss: 3.0607\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.05909\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008937704, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0604 - val_loss: 3.0598\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.05909\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008894169, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0740 - val_loss: 3.0616\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.05909\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088508456, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0780 - val_loss: 3.0611\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.05909\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to tf.Tensor(0.00088077335, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0652 - val_loss: 3.0611\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.05909\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008764831, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0678 - val_loss: 3.0602\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.05909\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to tf.Tensor(0.00087221374, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0679 - val_loss: 3.0613\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.05909\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008679653, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0766 - val_loss: 3.0602\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.05909\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to tf.Tensor(0.00086373737, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0749 - val_loss: 3.0603\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.05909\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008595301, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0734 - val_loss: 3.0608\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.05909\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to tf.Tensor(0.00085534336, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0638 - val_loss: 3.0616\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.05909\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to tf.Tensor(0.000851177, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0624 - val_loss: 3.0641\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.05909\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to tf.Tensor(0.00084703095, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0825 - val_loss: 3.0610\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.05909\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008429051, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0716 - val_loss: 3.0608\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.05909\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to tf.Tensor(0.00083879934, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0779 - val_loss: 3.0593\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.05909\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008347136, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0670 - val_loss: 3.0618\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.05909\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008306477, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0716 - val_loss: 3.0593\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.05909\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008266016, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0722 - val_loss: 3.0610\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3.05909\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to tf.Tensor(0.00082257524, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0815 - val_loss: 3.0634\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 3.05909\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008185685, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0756 - val_loss: 3.0602\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 3.05909\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081458123, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0700 - val_loss: 3.0615\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 3.05909\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to tf.Tensor(0.00081061345, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0732 - val_loss: 3.0599\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3.05909\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to tf.Tensor(0.000806665, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0763 - val_loss: 3.0604\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 3.05909\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080273574, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0672 - val_loss: 3.0611\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 3.05909\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007988256, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0764 - val_loss: 3.0605\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 3.05909\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007949346, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0653 - val_loss: 3.0623\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 3.05909\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007910624, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0599 - val_loss: 3.0601\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 3.05909\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007872092, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 3.0715 - val_loss: 3.0603\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3.05909\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007833747, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0650 - val_loss: 3.0617\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 3.05909\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077955885, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0676 - val_loss: 3.0599\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 3.05909\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077576167, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0693 - val_loss: 3.0626\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 3.05909\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to tf.Tensor(0.00077198294, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 3s 45ms/step - loss: 3.0682 - val_loss: 3.0615\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 3.05909\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007682226, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0694 - val_loss: 3.0611\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 3.05909\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007644806, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0709 - val_loss: 3.0606\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 3.05909\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007607569, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0727 - val_loss: 3.0628\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 3.05909\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007570512, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.0625 - val_loss: 3.0608\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 3.05909\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to tf.Tensor(0.00075336365, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0580 - val_loss: 3.0597\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 3.05909\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to tf.Tensor(0.000749694, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0657 - val_loss: 3.0595\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 3.05909\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007460423, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0757 - val_loss: 3.0625\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 3.05909\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to tf.Tensor(0.00074240833, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0735 - val_loss: 3.0605\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 3.05909\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to tf.Tensor(0.0007387921, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0646 - val_loss: 3.0603\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 3.05909\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to tf.Tensor(0.00073519343, shape=(), dtype=float32).\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.0745 - val_loss: 3.0624\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 3.05909\n",
      "Epoch 00064: early stopping\n",
      "(50300, 1, 80)\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 300\n",
    "BATCH_SIZE = 1024\n",
    "NUM_FOLDS = 10\n",
    "\n",
    "\n",
    "# detect and init the TPU\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "\n",
    "# instantiate a distribution strategy\n",
    "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "#GPU init\n",
    "#gpu_strategy = tf.distribute.get_strategy()\n",
    "\n",
    "#with gpu_strategy.scope():\n",
    "with tpu_strategy.scope():\n",
    "    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=2021)\n",
    "    test_preds = []\n",
    "    \n",
    "    def BiLSTM_model():\n",
    "        inputs = keras.layers.Input(shape=train.shape[-2:])\n",
    "        x = inputs\n",
    "        #CNN: 1024->512->256  Bidirectional LSTM: 128\n",
    "        x = keras.layers.Conv1D(filters=1024, kernel_size=3, activation='relu')(x)\n",
    "        x = keras.layers.MaxPooling1D(pool_size=2,strides=1, padding='valid')(x)\n",
    "        #x = keras.layers.BatchNormalization()(x)\n",
    "        x = keras.layers.Conv1D(filters=512, kernel_size=3, activation='relu')(x)\n",
    "        x = keras.layers.MaxPooling1D(pool_size=2,strides=1, padding='valid')(x)\n",
    "        #x = keras.layers.BatchNormalization()(x)\n",
    "        x = keras.layers.Conv1D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "        #x = keras.layers.BatchNormalization()(x)\n",
    "        #none, 74, 256\n",
    "        x = keras.layers.Flatten()(x)\n",
    "        #加一个残差conca和x \n",
    "        x = tf.expand_dims(x, axis=1)\n",
    "        print(x.shape)\n",
    "        x = keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True))(x)\n",
    "        x = keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True))(x)\n",
    "        x = keras.layers.Dense(128, activation='selu')(x)\n",
    "        # keras.layers.Dropout(0.1)\n",
    "        #keep the output same\n",
    "        outputs = keras.layers.Dense(80)(x)\n",
    "        outputs = ScaleLayer()(outputs)\n",
    "        \n",
    "        model  = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(optimizer=\"adam\", loss=\"mae\")\n",
    "        return model\n",
    "        \n",
    "        \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n",
    "        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n",
    "        X_train, X_valid = train[train_idx], train[test_idx]\n",
    "        y_train, y_valid = targets[train_idx], targets[test_idx]\n",
    "\n",
    "        model = BiLSTM_model()\n",
    "        \n",
    "        scheduler = ExponentialDecay(1e-3, 40*((len(train)*0.8)/BATCH_SIZE), 1e-5)\n",
    "        lr = LearningRateScheduler(scheduler, verbose=1)\n",
    "        \n",
    "        #lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1)\n",
    "        #lr = WarmupExponentialDecay(lr_base=1e-3, decay=1e-5, warmup_epochs=30)\n",
    "        es = EarlyStopping(monitor=\"val_loss\", patience=60, verbose=1, mode=\"min\", restore_best_weights=True)\n",
    "    \n",
    "        checkpoint_filepath = f\"folds{fold}.hdf5\"\n",
    "        sv = keras.callbacks.ModelCheckpoint(\n",
    "            checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "            save_weights_only=False, mode='auto', save_freq='epoch',\n",
    "            options=None\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr, es, sv])\n",
    "        #model.save(f'Fold{fold+1} RNN Weights')\n",
    "        out = model.predict(test)\n",
    "        print(out.shape)\n",
    "        test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3554724d",
   "metadata": {
    "papermill": {
     "duration": 7.282839,
     "end_time": "2021-10-12T20:09:21.730651",
     "exception": false,
     "start_time": "2021-10-12T20:09:14.447812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Median method from [Chris Deotte](https://www.kaggle.com/cdeotte/ensemble-folds-with-median-0-153)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8008bdbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T20:09:36.467764Z",
     "iopub.status.busy": "2021-10-12T20:09:36.467090Z",
     "iopub.status.idle": "2021-10-12T20:10:15.602643Z",
     "shell.execute_reply": "2021-10-12T20:10:15.603290Z",
     "shell.execute_reply.started": "2021-10-12T16:21:48.123624Z"
    },
    "papermill": {
     "duration": 46.433059,
     "end_time": "2021-10-12T20:10:15.603525",
     "exception": false,
     "start_time": "2021-10-12T20:09:29.170466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission[\"pressure\"] = sum(test_preds)/NUM_FOLDS\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# ENSEMBLE FOLDS WITH MEDIAN\n",
    "#取中位数\n",
    "submission[\"pressure\"] = np.median(np.vstack(test_preds),axis=0)\n",
    "submission.to_csv('submission_median.csv', index=False)\n",
    "\n",
    "\n",
    "# ENSEMBLE FOLDS WITH MEDIAN AND ROUND PREDICTIONS\n",
    "submission[\"pressure\"] =\\\n",
    "    np.round( (submission.pressure - pressure_min)/pressure_step ) * pressure_step + pressure_min\n",
    "submission.pressure = np.clip(submission.pressure, pressure_min, pressure_max)\n",
    "submission.to_csv('submission_median_round.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2841.439262,
   "end_time": "2021-10-12T20:10:25.871401",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-12T19:23:04.432139",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
